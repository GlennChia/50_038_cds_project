{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, TfidfTransformer\n",
    "\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.metrics import f1_score, hamming_loss, make_scorer, accuracy_score\n",
    "\n",
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from skmultilearn.model_selection.measures import get_combination_wise_output_matrix\n",
    "from skmultilearn.model_selection import iterative_train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker</th>\n",
       "      <th>headline</th>\n",
       "      <th>description</th>\n",
       "      <th>duration</th>\n",
       "      <th>tags</th>\n",
       "      <th>transcript</th>\n",
       "      <th>WC</th>\n",
       "      <th>clean_transcript</th>\n",
       "      <th>clean_transcript_string</th>\n",
       "      <th>squash_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Al Gore</td>\n",
       "      <td>Averting the climate crisis</td>\n",
       "      <td>With the same humor and humanity he exuded in ...</td>\n",
       "      <td>0:16:17</td>\n",
       "      <td>cars,alternative energy,culture,politics,scien...</td>\n",
       "      <td>0:14\\r\\r\\rThank you so much, Chris.\\rAnd it's ...</td>\n",
       "      <td>2281.0</td>\n",
       "      <td>[thank, chris, truly, great, honor, opportunit...</td>\n",
       "      <td>thank chris truly great honor opportunity come...</td>\n",
       "      <td>culture,politics,science,climate change,enviro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Amy Smith</td>\n",
       "      <td>Simple designs to save a life</td>\n",
       "      <td>Fumes from indoor cooking fires kill more than...</td>\n",
       "      <td>0:15:06</td>\n",
       "      <td>MacArthur grant,simplicity,industrial design,a...</td>\n",
       "      <td>0:11\\r\\r\\rIn terms of invention,\\rI'd like to ...</td>\n",
       "      <td>2687.0</td>\n",
       "      <td>[term, invention, like, tell, tale, favorite, ...</td>\n",
       "      <td>term invention like tell tale favorite project...</td>\n",
       "      <td>invention,engineering,design,global issues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ashraf Ghani</td>\n",
       "      <td>How to rebuild a broken state</td>\n",
       "      <td>Ashraf Ghani's passionate and powerful 10-minu...</td>\n",
       "      <td>0:18:45</td>\n",
       "      <td>corruption,poverty,economics,investment,milita...</td>\n",
       "      <td>0:12\\r\\r\\rA public, Dewey long ago observed,\\r...</td>\n",
       "      <td>2506.0</td>\n",
       "      <td>[public, dewey, long, ago, observe, constitute...</td>\n",
       "      <td>public dewey long ago observe constitute discu...</td>\n",
       "      <td>poverty,economics,culture,politics,policy,glob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Burt Rutan</td>\n",
       "      <td>The real future of space exploration</td>\n",
       "      <td>In this passionate talk, legendary spacecraft ...</td>\n",
       "      <td>0:19:37</td>\n",
       "      <td>aircraft,flight,industrial design,NASA,rocket ...</td>\n",
       "      <td>0:11\\r\\r\\rI want to start off by saying, Houst...</td>\n",
       "      <td>3092.0</td>\n",
       "      <td>[want, start, say, houston, problem, enter, se...</td>\n",
       "      <td>want start say houston problem enter second ge...</td>\n",
       "      <td>invention,engineering,entrepreneur,design,busi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chris Bangle</td>\n",
       "      <td>Great cars are great art</td>\n",
       "      <td>American designer Chris Bangle explains his ph...</td>\n",
       "      <td>0:20:04</td>\n",
       "      <td>cars,industrial design,transportation,inventio...</td>\n",
       "      <td>0:12\\r\\r\\rWhat I want to talk about is, as bac...</td>\n",
       "      <td>3781.0</td>\n",
       "      <td>[want, talk, background, idea, car, art, actua...</td>\n",
       "      <td>want talk background idea car art actually mea...</td>\n",
       "      <td>invention,design,technology,business,art</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        speaker                              headline  \\\n",
       "0       Al Gore           Averting the climate crisis   \n",
       "1     Amy Smith         Simple designs to save a life   \n",
       "2  Ashraf Ghani         How to rebuild a broken state   \n",
       "3    Burt Rutan  The real future of space exploration   \n",
       "4  Chris Bangle              Great cars are great art   \n",
       "\n",
       "                                         description duration  \\\n",
       "0  With the same humor and humanity he exuded in ...  0:16:17   \n",
       "1  Fumes from indoor cooking fires kill more than...  0:15:06   \n",
       "2  Ashraf Ghani's passionate and powerful 10-minu...  0:18:45   \n",
       "3  In this passionate talk, legendary spacecraft ...  0:19:37   \n",
       "4  American designer Chris Bangle explains his ph...  0:20:04   \n",
       "\n",
       "                                                tags  \\\n",
       "0  cars,alternative energy,culture,politics,scien...   \n",
       "1  MacArthur grant,simplicity,industrial design,a...   \n",
       "2  corruption,poverty,economics,investment,milita...   \n",
       "3  aircraft,flight,industrial design,NASA,rocket ...   \n",
       "4  cars,industrial design,transportation,inventio...   \n",
       "\n",
       "                                          transcript      WC  \\\n",
       "0  0:14\\r\\r\\rThank you so much, Chris.\\rAnd it's ...  2281.0   \n",
       "1  0:11\\r\\r\\rIn terms of invention,\\rI'd like to ...  2687.0   \n",
       "2  0:12\\r\\r\\rA public, Dewey long ago observed,\\r...  2506.0   \n",
       "3  0:11\\r\\r\\rI want to start off by saying, Houst...  3092.0   \n",
       "4  0:12\\r\\r\\rWhat I want to talk about is, as bac...  3781.0   \n",
       "\n",
       "                                    clean_transcript  \\\n",
       "0  [thank, chris, truly, great, honor, opportunit...   \n",
       "1  [term, invention, like, tell, tale, favorite, ...   \n",
       "2  [public, dewey, long, ago, observe, constitute...   \n",
       "3  [want, start, say, houston, problem, enter, se...   \n",
       "4  [want, talk, background, idea, car, art, actua...   \n",
       "\n",
       "                             clean_transcript_string  \\\n",
       "0  thank chris truly great honor opportunity come...   \n",
       "1  term invention like tell tale favorite project...   \n",
       "2  public dewey long ago observe constitute discu...   \n",
       "3  want start say houston problem enter second ge...   \n",
       "4  want talk background idea car art actually mea...   \n",
       "\n",
       "                                         squash_tags  \n",
       "0  culture,politics,science,climate change,enviro...  \n",
       "1         invention,engineering,design,global issues  \n",
       "2  poverty,economics,culture,politics,policy,glob...  \n",
       "3  invention,engineering,entrepreneur,design,busi...  \n",
       "4           invention,design,technology,business,art  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_DIR = \"../../data/processed/\"\n",
    "INPUT_FILE_NAME = 'cleaned_squashed1.parquet'\n",
    "df = pd.read_parquet(DATA_DIR + INPUT_FILE_NAME)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2382 entries, 0 to 2381\n",
      "Data columns (total 10 columns):\n",
      "speaker                    2382 non-null object\n",
      "headline                   2382 non-null object\n",
      "description                2382 non-null object\n",
      "duration                   2382 non-null object\n",
      "tags                       2382 non-null object\n",
      "transcript                 2382 non-null object\n",
      "WC                         2382 non-null float64\n",
      "clean_transcript           2382 non-null object\n",
      "clean_transcript_string    2382 non-null object\n",
      "squash_tags                2382 non-null object\n",
      "dtypes: float64(1), object(9)\n",
      "memory usage: 186.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df = df.dropna(subset=['squash_tags'])\n",
    "df = df.reset_index(drop=True)\n",
    "df.iloc[:,:10].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['clean_transcript_string']\n",
    "labels = df[['squash_tags']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "y = []\n",
    "for index, row in labels.iterrows():\n",
    "    y.append(set(row['squash_tags'].split(',')))\n",
    "    \n",
    "mlb = MultiLabelBinarizer()\n",
    "encoded_y = mlb.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0]\n",
      "100\n",
      "[('climate change', 'culture', 'environment', 'global issues', 'politics', 'science', 'sustainability', 'technology'), ('design', 'engineering', 'global issues', 'invention'), ('business', 'culture', 'economics', 'entrepreneur', 'global development', 'global issues', 'policy', 'politics', 'poverty'), ('business', 'design', 'engineering', 'entrepreneur', 'invention'), ('art', 'business', 'design', 'invention', 'technology'), ('biodiversity', 'biology', 'biotech', 'ecology', 'entrepreneur', 'genetics', 'invention', 'oceans', 'science', 'technology'), ('computers', 'entertainment', 'media', 'music', 'performance', 'technology'), ('architecture', 'cities', 'collaboration', 'culture', 'design'), ('business', 'education', 'innovation', 'invention', 'robots', 'science', 'social change', 'sustainability', 'technology'), ('culture', 'disease', 'food', 'global issues', 'health', 'health care', 'science')]\n"
     ]
    }
   ],
   "source": [
    "print(encoded_y[0])\n",
    "print(len(encoded_y[0]))\n",
    "print(mlb.inverse_transform(encoded_y)[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skmultilearn.model_selection import iterative_train_test_split\n",
    "\n",
    "X_train, y_train, X_test, y_test = iterative_train_test_split(X.values.reshape(len(X.values), 1), encoded_y, test_size = 0.2)\n",
    "X_train = pd.DataFrame(X_train)[0]\n",
    "X_test = pd.DataFrame(X_test)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[112  38  73  83  61 160  48  52  46 137  55 115 256 102  88  65  41 122\n",
      " 144 109  82 135 375  70  35 316  56  42 122 159  37  84 228  48 121  49\n",
      "  74  42  52  40 139  47  46 377  61  54  53 173 100  99 132  71  76  40\n",
      "  64 161  59 101  42  81  76  49  40  49  66 120  42  51  44  95  86  66\n",
      "  55  40  37  76  66  42  69  53  34 138  56  42  76  40  44 399 149 159\n",
      "  41  88  54 532  49  61  79  85  48  46]\n",
      "[ 35  10  21  25  15  44   8  11  14  37  15  33  73  33  25  16  14  41\n",
      "  41  27  23  39  95  19  17  84  16  10  32  47  14  23  57  12  34  15\n",
      "  22   7  14  15  42  12  12 106  22  17  18  53  30  36  32  28  30  10\n",
      "  22  51  18  35  16  26  23  11  13  17  20  34  17  13  17  24  20  18\n",
      "  18   9  15  22  19  18  19  14  15  45  14   9  28  12  11 123  49  43\n",
      "  15  24  20 163  16  19  29  30  21  16]\n"
     ]
    }
   ],
   "source": [
    "print(y_train.sum(axis=0))\n",
    "print(y_test.sum(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gridsearch for the best single model for all labels\n",
    "\n",
    "### References \n",
    "http://scikit.ml/api/skmultilearn.problem_transform.br.html\n",
    "\n",
    "https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "\n",
    "http://scikit.ml/stratification.html\n",
    "\n",
    "https://stackoverflow.com/questions/12632992/gridsearch-for-an-estimator-inside-a-onevsrestclassifier/12637528#12637528"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: \n",
    "# 1. Check if TfidfTransformer use_idf=False is the same as Countvectorizer? or there are other metrics to suppress\n",
    "# 2. Get scoring function to work, hamming? -- kinda done\n",
    "# 3. Balanced class labels\n",
    "# 4. Set better param ranges\n",
    "# 5. Remove vectorizer step once we decide on which is better, then use sparse csr and hopefully it trains faster\n",
    "\n",
    "# param_range = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "param_range = [1, 2, 3, 4, 5]\n",
    "param_range_lr = [1.0, 0.5, 0.1]\n",
    "\n",
    "# Set params, comment out as see fit\n",
    "\n",
    "vectorizer_params = {\n",
    "#     'vectorizer__min_df': np.linspace(0.005, 0.05, 5),\n",
    "#     'vectorizer__ngram_range': [(1, 1), (1, 2)], # This shit blows up your memory\n",
    "#     'tfidf__norm': ('l1', 'l2'),\n",
    "    'tfidf__use_idf': [True, False],\n",
    "}\n",
    "\n",
    "lr_params = {\n",
    "    'clf__classifier': [LogisticRegression()],\n",
    "        'clf__classifier__penalty': ['l1', 'l2'],\n",
    "        'clf__classifier__C': param_range_lr,\n",
    "        'clf__classifier__solver': ['liblinear'],\n",
    "        'clf__classifier__class_weight': ['balanced'],\n",
    "}\n",
    "\n",
    "svc_params = {\n",
    "    'clf__classifier': [SVC()],\n",
    "        'clf__classifier__kernel': ['linear', 'rbf'],\n",
    "        'clf__classifier__C': param_range, # np.logspace(-1, 2, 10),\n",
    "        'clf__classifier__gamma': ['auto'], # np.logspace(-1, 1, 10)\n",
    "        'clf__classifier__probability': [True],\n",
    "        'clf__classifier__class_weight': ['balanced'],\n",
    "}\n",
    "\n",
    "rf_params = {\n",
    "    'clf__classifier': [RandomForestClassifier()],\n",
    "        'clf__classifier__criterion': ['gini', 'entropy'],\n",
    "        'clf__classifier__min_samples_leaf': param_range,\n",
    "        'clf__classifier__max_depth': param_range,\n",
    "        'clf__classifier__min_samples_split': param_range[1:],\n",
    "        'clf__classifier__n_estimators': [10],\n",
    "        'clf__classifier__class_weight': ['balanced'],\n",
    "}\n",
    "\n",
    "mnb_params = {\n",
    "    'clf__classifier': [MultinomialNB()],\n",
    "        'clf__classifier__alpha': [0.7, 1.0],\n",
    "}\n",
    "\n",
    "## Stack params\n",
    "parameters = [\n",
    "    {**vectorizer_params, **lr_params},\n",
    "#     {**vectorizer_params, **svc_params},\n",
    "#     {**vectorizer_params, **rf_params},\n",
    "#     {**vectorizer_params, **mnb_params}\n",
    "]\n",
    "\n",
    "br_pipeline = Pipeline([('vectorizer', CountVectorizer()),\n",
    "                        ('tfidf', TfidfTransformer()),\n",
    "                        ('clf', BinaryRelevance()),\n",
    "                       ]\n",
    "                      )\n",
    "\n",
    "# Gridsearch settings\n",
    "# scoring = make_scorer(f1_score, average='micro') # possible scorings 'f1_micro' 'f1_macro'\n",
    "# scoring = 'f1_micro'\n",
    "# scoring = make_scorer(hamming_loss)\n",
    "# scoring = 'neg_log_loss'\n",
    "scoring = 'f1_samples'\n",
    "folds = 3\n",
    "njobs = -1\n",
    "\n",
    "br_model = GridSearchCV(br_pipeline, parameters, scoring=scoring, cv=folds, n_jobs=njobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'clf__classifier': LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='warn', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
      "                   warm_start=False), 'clf__classifier__C': 1.0, 'clf__classifier__class_weight': 'balanced', 'clf__classifier__penalty': 'l2', 'clf__classifier__solver': 'liblinear', 'tfidf__use_idf': False} 0.38711631250803646\n",
      "Wall time: 12min 14s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_clf__classifier</th>\n",
       "      <th>param_clf__classifier__C</th>\n",
       "      <th>param_clf__classifier__class_weight</th>\n",
       "      <th>param_clf__classifier__penalty</th>\n",
       "      <th>param_clf__classifier__solver</th>\n",
       "      <th>param_tfidf__use_idf</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>111.470159</td>\n",
       "      <td>6.446176</td>\n",
       "      <td>35.510447</td>\n",
       "      <td>1.481652</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight='balanc...</td>\n",
       "      <td>1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>True</td>\n",
       "      <td>{'clf__classifier': LogisticRegression(C=1.0, ...</td>\n",
       "      <td>0.345882</td>\n",
       "      <td>0.357421</td>\n",
       "      <td>0.377387</td>\n",
       "      <td>0.360222</td>\n",
       "      <td>0.013015</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>111.614353</td>\n",
       "      <td>7.337566</td>\n",
       "      <td>36.533854</td>\n",
       "      <td>1.216782</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight='balanc...</td>\n",
       "      <td>1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>False</td>\n",
       "      <td>{'clf__classifier': LogisticRegression(C=1.0, ...</td>\n",
       "      <td>0.335754</td>\n",
       "      <td>0.330314</td>\n",
       "      <td>0.371690</td>\n",
       "      <td>0.345914</td>\n",
       "      <td>0.018354</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>91.772715</td>\n",
       "      <td>7.854513</td>\n",
       "      <td>34.705964</td>\n",
       "      <td>3.954210</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight='balanc...</td>\n",
       "      <td>1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>True</td>\n",
       "      <td>{'clf__classifier': LogisticRegression(C=1.0, ...</td>\n",
       "      <td>0.379193</td>\n",
       "      <td>0.407101</td>\n",
       "      <td>0.361440</td>\n",
       "      <td>0.382576</td>\n",
       "      <td>0.018789</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101.763127</td>\n",
       "      <td>5.900635</td>\n",
       "      <td>35.298412</td>\n",
       "      <td>2.738021</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight='balanc...</td>\n",
       "      <td>1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>False</td>\n",
       "      <td>{'clf__classifier': LogisticRegression(C=1.0, ...</td>\n",
       "      <td>0.383596</td>\n",
       "      <td>0.383091</td>\n",
       "      <td>0.394667</td>\n",
       "      <td>0.387116</td>\n",
       "      <td>0.005341</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>111.945456</td>\n",
       "      <td>3.176044</td>\n",
       "      <td>34.163979</td>\n",
       "      <td>1.421262</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight='balanc...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>balanced</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>True</td>\n",
       "      <td>{'clf__classifier': LogisticRegression(C=1.0, ...</td>\n",
       "      <td>0.324174</td>\n",
       "      <td>0.329758</td>\n",
       "      <td>0.359938</td>\n",
       "      <td>0.337949</td>\n",
       "      <td>0.015708</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>112.323486</td>\n",
       "      <td>9.113564</td>\n",
       "      <td>34.014516</td>\n",
       "      <td>0.654730</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight='balanc...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>balanced</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>False</td>\n",
       "      <td>{'clf__classifier': LogisticRegression(C=1.0, ...</td>\n",
       "      <td>0.312190</td>\n",
       "      <td>0.299764</td>\n",
       "      <td>0.360455</td>\n",
       "      <td>0.324130</td>\n",
       "      <td>0.026171</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>96.165212</td>\n",
       "      <td>5.961420</td>\n",
       "      <td>34.389342</td>\n",
       "      <td>2.365571</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight='balanc...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>balanced</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>True</td>\n",
       "      <td>{'clf__classifier': LogisticRegression(C=1.0, ...</td>\n",
       "      <td>0.381965</td>\n",
       "      <td>0.402569</td>\n",
       "      <td>0.366082</td>\n",
       "      <td>0.383538</td>\n",
       "      <td>0.014933</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>99.175079</td>\n",
       "      <td>4.030367</td>\n",
       "      <td>35.096197</td>\n",
       "      <td>0.715753</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight='balanc...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>balanced</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>False</td>\n",
       "      <td>{'clf__classifier': LogisticRegression(C=1.0, ...</td>\n",
       "      <td>0.374150</td>\n",
       "      <td>0.365378</td>\n",
       "      <td>0.394179</td>\n",
       "      <td>0.377900</td>\n",
       "      <td>0.012051</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>97.681648</td>\n",
       "      <td>0.635577</td>\n",
       "      <td>32.685025</td>\n",
       "      <td>0.959675</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight='balanc...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>True</td>\n",
       "      <td>{'clf__classifier': LogisticRegression(C=1.0, ...</td>\n",
       "      <td>0.239478</td>\n",
       "      <td>0.238232</td>\n",
       "      <td>0.268744</td>\n",
       "      <td>0.248813</td>\n",
       "      <td>0.014097</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>99.262824</td>\n",
       "      <td>6.947729</td>\n",
       "      <td>33.324450</td>\n",
       "      <td>1.467823</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight='balanc...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>False</td>\n",
       "      <td>{'clf__classifier': LogisticRegression(C=1.0, ...</td>\n",
       "      <td>0.219493</td>\n",
       "      <td>0.212393</td>\n",
       "      <td>0.275166</td>\n",
       "      <td>0.235675</td>\n",
       "      <td>0.028063</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>86.885954</td>\n",
       "      <td>8.125521</td>\n",
       "      <td>30.268065</td>\n",
       "      <td>4.471381</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight='balanc...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>True</td>\n",
       "      <td>{'clf__classifier': LogisticRegression(C=1.0, ...</td>\n",
       "      <td>0.372603</td>\n",
       "      <td>0.400384</td>\n",
       "      <td>0.376296</td>\n",
       "      <td>0.383088</td>\n",
       "      <td>0.012317</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>68.280090</td>\n",
       "      <td>1.486914</td>\n",
       "      <td>22.332694</td>\n",
       "      <td>0.571280</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight='balanc...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>False</td>\n",
       "      <td>{'clf__classifier': LogisticRegression(C=1.0, ...</td>\n",
       "      <td>0.352854</td>\n",
       "      <td>0.335643</td>\n",
       "      <td>0.387314</td>\n",
       "      <td>0.358601</td>\n",
       "      <td>0.021478</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0      111.470159      6.446176        35.510447        1.481652   \n",
       "1      111.614353      7.337566        36.533854        1.216782   \n",
       "2       91.772715      7.854513        34.705964        3.954210   \n",
       "3      101.763127      5.900635        35.298412        2.738021   \n",
       "4      111.945456      3.176044        34.163979        1.421262   \n",
       "5      112.323486      9.113564        34.014516        0.654730   \n",
       "6       96.165212      5.961420        34.389342        2.365571   \n",
       "7       99.175079      4.030367        35.096197        0.715753   \n",
       "8       97.681648      0.635577        32.685025        0.959675   \n",
       "9       99.262824      6.947729        33.324450        1.467823   \n",
       "10      86.885954      8.125521        30.268065        4.471381   \n",
       "11      68.280090      1.486914        22.332694        0.571280   \n",
       "\n",
       "                                param_clf__classifier  \\\n",
       "0   LogisticRegression(C=1.0, class_weight='balanc...   \n",
       "1   LogisticRegression(C=1.0, class_weight='balanc...   \n",
       "2   LogisticRegression(C=1.0, class_weight='balanc...   \n",
       "3   LogisticRegression(C=1.0, class_weight='balanc...   \n",
       "4   LogisticRegression(C=1.0, class_weight='balanc...   \n",
       "5   LogisticRegression(C=1.0, class_weight='balanc...   \n",
       "6   LogisticRegression(C=1.0, class_weight='balanc...   \n",
       "7   LogisticRegression(C=1.0, class_weight='balanc...   \n",
       "8   LogisticRegression(C=1.0, class_weight='balanc...   \n",
       "9   LogisticRegression(C=1.0, class_weight='balanc...   \n",
       "10  LogisticRegression(C=1.0, class_weight='balanc...   \n",
       "11  LogisticRegression(C=1.0, class_weight='balanc...   \n",
       "\n",
       "   param_clf__classifier__C param_clf__classifier__class_weight  \\\n",
       "0                         1                            balanced   \n",
       "1                         1                            balanced   \n",
       "2                         1                            balanced   \n",
       "3                         1                            balanced   \n",
       "4                       0.5                            balanced   \n",
       "5                       0.5                            balanced   \n",
       "6                       0.5                            balanced   \n",
       "7                       0.5                            balanced   \n",
       "8                       0.1                            balanced   \n",
       "9                       0.1                            balanced   \n",
       "10                      0.1                            balanced   \n",
       "11                      0.1                            balanced   \n",
       "\n",
       "   param_clf__classifier__penalty param_clf__classifier__solver  \\\n",
       "0                              l1                     liblinear   \n",
       "1                              l1                     liblinear   \n",
       "2                              l2                     liblinear   \n",
       "3                              l2                     liblinear   \n",
       "4                              l1                     liblinear   \n",
       "5                              l1                     liblinear   \n",
       "6                              l2                     liblinear   \n",
       "7                              l2                     liblinear   \n",
       "8                              l1                     liblinear   \n",
       "9                              l1                     liblinear   \n",
       "10                             l2                     liblinear   \n",
       "11                             l2                     liblinear   \n",
       "\n",
       "   param_tfidf__use_idf                                             params  \\\n",
       "0                  True  {'clf__classifier': LogisticRegression(C=1.0, ...   \n",
       "1                 False  {'clf__classifier': LogisticRegression(C=1.0, ...   \n",
       "2                  True  {'clf__classifier': LogisticRegression(C=1.0, ...   \n",
       "3                 False  {'clf__classifier': LogisticRegression(C=1.0, ...   \n",
       "4                  True  {'clf__classifier': LogisticRegression(C=1.0, ...   \n",
       "5                 False  {'clf__classifier': LogisticRegression(C=1.0, ...   \n",
       "6                  True  {'clf__classifier': LogisticRegression(C=1.0, ...   \n",
       "7                 False  {'clf__classifier': LogisticRegression(C=1.0, ...   \n",
       "8                  True  {'clf__classifier': LogisticRegression(C=1.0, ...   \n",
       "9                 False  {'clf__classifier': LogisticRegression(C=1.0, ...   \n",
       "10                 True  {'clf__classifier': LogisticRegression(C=1.0, ...   \n",
       "11                False  {'clf__classifier': LogisticRegression(C=1.0, ...   \n",
       "\n",
       "    split0_test_score  split1_test_score  split2_test_score  mean_test_score  \\\n",
       "0            0.345882           0.357421           0.377387         0.360222   \n",
       "1            0.335754           0.330314           0.371690         0.345914   \n",
       "2            0.379193           0.407101           0.361440         0.382576   \n",
       "3            0.383596           0.383091           0.394667         0.387116   \n",
       "4            0.324174           0.329758           0.359938         0.337949   \n",
       "5            0.312190           0.299764           0.360455         0.324130   \n",
       "6            0.381965           0.402569           0.366082         0.383538   \n",
       "7            0.374150           0.365378           0.394179         0.377900   \n",
       "8            0.239478           0.238232           0.268744         0.248813   \n",
       "9            0.219493           0.212393           0.275166         0.235675   \n",
       "10           0.372603           0.400384           0.376296         0.383088   \n",
       "11           0.352854           0.335643           0.387314         0.358601   \n",
       "\n",
       "    std_test_score  rank_test_score  \n",
       "0         0.013015                6  \n",
       "1         0.018354                8  \n",
       "2         0.018789                4  \n",
       "3         0.005341                1  \n",
       "4         0.015708                9  \n",
       "5         0.026171               10  \n",
       "6         0.014933                2  \n",
       "7         0.012051                5  \n",
       "8         0.014097               11  \n",
       "9         0.028063               12  \n",
       "10        0.012317                3  \n",
       "11        0.021478                7  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "br_model.fit(X_train,y_train)\n",
    "print(br_model.best_params_, br_model.best_score_)\n",
    "pd.DataFrame(br_model.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary relevance best model's f1-score 0.1306289367302811\n"
     ]
    }
   ],
   "source": [
    "y_pred_prob = br_model.predict_proba(X_test)\n",
    "t = 0.1 # threshold value\n",
    "y_pred_new = (y_pred_prob >= t).astype(int)\n",
    "score = f1_score(y_test, y_pred_new, average=\"micro\")\n",
    "print(f\"Binary relevance best model's f1-score {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OneVsRest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: \n",
    "# 1. Check if TfidfTransformer use_idf=False is the same as Countvectorizer? or there are other metrics to suppress\n",
    "# 2. Use proper scoring function - ideally, predicting relevant labels should be more important than predicting irrelevant ones\n",
    "# 3. Balanced class labels\n",
    "# 4. Set better param ranges\n",
    "\n",
    "# param_range = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "param_range = [1, 2, 3, 4, 5]\n",
    "param_range_lr = [1.0, 0.5, 0.1]\n",
    "\n",
    "# Set params, comment out as see fit\n",
    "\n",
    "vectorizer_params = {\n",
    "#     'vectorizer__min_df': np.linspace(0.005, 0.05, 5),\n",
    "#     'vectorizer__ngram_range': [(1, 1), (1, 2)], # This shit blows up your memory\n",
    "#     'tfidf__norm': ('l1', 'l2'),\n",
    "    'tfidf__use_idf': [True, False],\n",
    "}\n",
    "\n",
    "lr_params = {\n",
    "    'clf__estimator': [LogisticRegression()],\n",
    "        'clf__estimator__penalty': ['l1', 'l2'],\n",
    "        'clf__estimator__C': param_range_lr,\n",
    "        'clf__estimator__solver': ['liblinear'],\n",
    "        'clf__estimator__class_weight': ['balanced'],\n",
    "}\n",
    "\n",
    "svc_params = {\n",
    "    'clf__estimator': [SVC()],\n",
    "        'clf__estimator__kernel': ['linear', 'rbf'],\n",
    "        'clf__estimator__C': param_range, # np.logspace(-1, 2, 10),\n",
    "        'clf__estimator__gamma': ['auto'], # np.logspace(-1, 1, 10)\n",
    "        'clf__estimator__probability': [True],\n",
    "        'clf__estimator__class_weight': ['balanced'],\n",
    "}\n",
    "\n",
    "rf_params = {\n",
    "    'clf__estimator': [RandomForestClassifier()],\n",
    "        'clf__estimator__criterion': ['gini', 'entropy'],\n",
    "        'clf__estimator__min_samples_leaf': param_range,\n",
    "        'clf__estimator__max_depth': param_range,\n",
    "        'clf__estimator__min_samples_split': param_range[1:],\n",
    "        'clf__estimator__n_estimators': [10],\n",
    "        'clf__estimator__class_weight': ['balanced'],\n",
    "}\n",
    "\n",
    "mnb_params = {\n",
    "    'clf__estimator': [MultinomialNB()],\n",
    "        'clf__estimator__alpha': [0.7, 1.0],\n",
    "}\n",
    "\n",
    "## Stack params\n",
    "parameters = [\n",
    "#     {**vectorizer_params, **lr_params},\n",
    "#     {**vectorizer_params, **svc_params},\n",
    "#     {**vectorizer_params, **rf_params},\n",
    "    {**vectorizer_params, **mnb_params}\n",
    "]\n",
    "\n",
    "ovr_pipeline = Pipeline([('vectorizer', CountVectorizer()),\n",
    "                         ('tfidf', TfidfTransformer()),\n",
    "                         ('clf', OneVsRestClassifier(LogisticRegression())),\n",
    "                        ]\n",
    "                       )\n",
    "\n",
    "# Gridsearch settings\n",
    "# scoring = make_scorer(f1_score, average='micro') # possible scorings 'f1_micro' 'f1_macro'\n",
    "scoring = 'f1_micro'\n",
    "# scoring = make_scorer(hamming_loss) # hamming gives equal weighting to both relevant and irrelevant?\n",
    "# maybe use precision somewhere\n",
    "folds = 3\n",
    "njobs = -1\n",
    "\n",
    "ovr_model = GridSearchCV(ovr_pipeline, parameters, scoring=scoring, cv=folds, n_jobs=njobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'clf__estimator': MultinomialNB(alpha=0.7, class_prior=None, fit_prior=True), 'clf__estimator__alpha': 0.7, 'tfidf__use_idf': True} 0.0\n",
      "Wall time: 17.3 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_clf__estimator</th>\n",
       "      <th>param_clf__estimator__alpha</th>\n",
       "      <th>param_tfidf__use_idf</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.235401</td>\n",
       "      <td>0.245698</td>\n",
       "      <td>1.569807</td>\n",
       "      <td>0.213995</td>\n",
       "      <td>MultinomialNB(alpha=0.7, class_prior=None, fit...</td>\n",
       "      <td>0.7</td>\n",
       "      <td>True</td>\n",
       "      <td>{'clf__estimator': MultinomialNB(alpha=0.7, cl...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.178484</td>\n",
       "      <td>0.325424</td>\n",
       "      <td>1.532880</td>\n",
       "      <td>0.138228</td>\n",
       "      <td>MultinomialNB(alpha=0.7, class_prior=None, fit...</td>\n",
       "      <td>0.7</td>\n",
       "      <td>False</td>\n",
       "      <td>{'clf__estimator': MultinomialNB(alpha=0.7, cl...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.883495</td>\n",
       "      <td>0.666608</td>\n",
       "      <td>1.407283</td>\n",
       "      <td>0.233621</td>\n",
       "      <td>MultinomialNB(alpha=0.7, class_prior=None, fit...</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>{'clf__estimator': MultinomialNB(alpha=0.7, cl...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.945858</td>\n",
       "      <td>0.022153</td>\n",
       "      <td>1.061989</td>\n",
       "      <td>0.068123</td>\n",
       "      <td>MultinomialNB(alpha=0.7, class_prior=None, fit...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>{'clf__estimator': MultinomialNB(alpha=0.7, cl...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       4.235401      0.245698         1.569807        0.213995   \n",
       "1       4.178484      0.325424         1.532880        0.138228   \n",
       "2       3.883495      0.666608         1.407283        0.233621   \n",
       "3       2.945858      0.022153         1.061989        0.068123   \n",
       "\n",
       "                                param_clf__estimator  \\\n",
       "0  MultinomialNB(alpha=0.7, class_prior=None, fit...   \n",
       "1  MultinomialNB(alpha=0.7, class_prior=None, fit...   \n",
       "2  MultinomialNB(alpha=0.7, class_prior=None, fit...   \n",
       "3  MultinomialNB(alpha=0.7, class_prior=None, fit...   \n",
       "\n",
       "  param_clf__estimator__alpha param_tfidf__use_idf  \\\n",
       "0                         0.7                 True   \n",
       "1                         0.7                False   \n",
       "2                           1                 True   \n",
       "3                           1                False   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'clf__estimator': MultinomialNB(alpha=0.7, cl...                0.0   \n",
       "1  {'clf__estimator': MultinomialNB(alpha=0.7, cl...                0.0   \n",
       "2  {'clf__estimator': MultinomialNB(alpha=0.7, cl...                0.0   \n",
       "3  {'clf__estimator': MultinomialNB(alpha=0.7, cl...                0.0   \n",
       "\n",
       "   split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "0                0.0                0.0              0.0             0.0   \n",
       "1                0.0                0.0              0.0             0.0   \n",
       "2                0.0                0.0              0.0             0.0   \n",
       "3                0.0                0.0              0.0             0.0   \n",
       "\n",
       "   rank_test_score  \n",
       "0                1  \n",
       "1                1  \n",
       "2                1  \n",
       "3                1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "ovr_model.fit(X_train,y_train)\n",
    "print(ovr_model.best_params_, ovr_model.best_score_)\n",
    "pd.DataFrame(ovr_model.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One vs Rest best model's f1-score 0.020272631946871723\n"
     ]
    }
   ],
   "source": [
    "y_pred_prob = ovr_model.predict_proba(X_test)\n",
    "t = 0.1 # threshold value\n",
    "y_pred_new = (y_pred_prob >= t).astype(int)\n",
    "score = f1_score(y_test, y_pred_new, average=\"micro\")\n",
    "print(f\"One vs Rest best model's f1-score {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gridsearch best model for each tag\n",
    "\n",
    "https://stackoverflow.com/questions/38555650/try-multiple-estimator-in-one-grid-search\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_range = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "param_range = [1, 2, 3, 4, 5]\n",
    "param_range_lr = [1.0, 0.5, 0.1]\n",
    "\n",
    "# Set params, comment out as see fit\n",
    "\n",
    "vectorizer_params = {\n",
    "#     'vectorizer__min_df': np.linspace(0.005, 0.05, 5),\n",
    "#     'vectorizer__ngram_range': [(1, 1), (1, 2)], # This shit blows up your memory\n",
    "#     'tfidf__norm': ('l1', 'l2'),\n",
    "    'tfidf__use_idf': [True, False],\n",
    "}\n",
    "\n",
    "# Add any Binary classification model setting here.\n",
    "# Also add to general parameters to be passed into pipeline below if want to use new model.\n",
    "\n",
    "lr_params = {\n",
    "    'clf': [LogisticRegression()],\n",
    "        'clf__penalty': ['l1', 'l2'],\n",
    "        'clf__C': param_range_lr,\n",
    "        'clf__solver': ['liblinear'],\n",
    "        'clf__class_weight': ['balanced'],\n",
    "}\n",
    "\n",
    "svc_params = {\n",
    "    'clf': [SVC()],\n",
    "        'clf__kernel': ['linear', 'rbf'],\n",
    "        'clf__C': param_range, # np.logspace(-1, 2, 10),\n",
    "        'clf__gamma': ['auto'], # np.logspace(-1, 1, 10)\n",
    "        'clf__probability': [True],\n",
    "        'clf__class_weight': ['balanced'],\n",
    "}\n",
    "\n",
    "rf_params = {\n",
    "    'clf': [RandomForestClassifier()],\n",
    "        'clf__criterion': ['gini', 'entropy'],\n",
    "#         'clf__min_samples_leaf': param_range,\n",
    "#         'clf__max_depth': param_range,\n",
    "        'clf__min_samples_split': param_range[1:],\n",
    "        'clf__n_estimators': [15],\n",
    "        'clf__class_weight': ['balanced'],\n",
    "}\n",
    "\n",
    "mnb_params = {\n",
    "    'clf': [MultinomialNB()],\n",
    "        'clf__alpha': [0.7, 1.0],\n",
    "}\n",
    "\n",
    "## Stack params\n",
    "parameters = [\n",
    "#     {**vectorizer_params, **lr_params},\n",
    "#     {**vectorizer_params, **svc_params},\n",
    "    {**vectorizer_params, **rf_params},\n",
    "#     {**vectorizer_params, **mnb_params}\n",
    "]\n",
    "\n",
    "per_tag_pipe = Pipeline([('vectorizer', CountVectorizer()), \n",
    "                  ('tfidf', TfidfTransformer()), \n",
    "                  ('clf', LogisticRegression())])\n",
    "\n",
    "# scoring = make_scorer(hamming_loss)\n",
    "scoring = 'f1'\n",
    "# scoring = 'f1_micro'\n",
    "# scoring = 'balanced_accuracy'\n",
    "# scoring = 'precision'\n",
    "folds = 3\n",
    "njobs = -1\n",
    "\n",
    "per_tag_model = GridSearchCV(per_tag_pipe, parameters, scoring=scoring, cv=folds, n_jobs=njobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['activism', 'adventure', 'africa', 'animals', 'architecture', 'art', 'beauty', 'big problems', 'biodiversity', 'biology', 'biotech', 'brain', 'business', 'children', 'cities', 'climate change', 'cognitive science', 'collaboration', 'communication', 'community', 'computers', 'creativity', 'culture', 'data', 'demo', 'design', 'disease', 'ecology', 'economics', 'education', 'energy', 'engineering', 'entertainment', 'entrepreneur', 'environment', 'evolution', 'exploration', 'family', 'film', 'food', 'future', 'genetics', 'global development', 'global issues', 'government', 'green', 'happiness', 'health', 'health care', 'history', 'humanity', 'humor', 'identity', 'illness', 'inequality', 'innovation', 'internet', 'invention', 'language', 'leadership', 'life', 'live music', 'math', 'media', 'medical research', 'medicine', 'mental health', 'mind', 'motivation', 'music', 'nature', 'neuroscience', 'oceans', 'parenting', 'peace', 'performance', 'personal growth', 'philosophy', 'photography', 'physics', 'policy', 'politics', 'potential', 'poverty', 'psychology', 'religion', 'robots', 'science', 'social change', 'society', 'space', 'storytelling', 'sustainability', 'technology', 'violence', 'visualizations', 'war', 'women', 'work', 'writing']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "93"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags = [tag for tag in mlb.inverse_transform(np.ones(shape=(1, 100)))[0]]\n",
    "print(tags)\n",
    "tags.index('technology')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing storytelling\n",
      "tag 91: storytelling best model {'clf': RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "                       min_impurity_split=None, min_samples_leaf=1,\n",
      "                       min_samples_split=3, min_weight_fraction_leaf=0.0,\n",
      "                       n_estimators=15, n_jobs=None, oob_score=False,\n",
      "                       random_state=None, verbose=0, warm_start=False), 'clf__class_weight': 'balanced', 'clf__criterion': 'gini', 'clf__min_samples_split': 3, 'clf__n_estimators': 15, 'tfidf__use_idf': True}\n",
      "tag 91: storytelling counts - predicted: 31, actual: 24\n",
      "tag 91: storytelling test f1-score is 0.14545454545454548\n",
      "tag 91: storytelling test accuracy is 0.9182608695652174\n",
      "--------------------------\n",
      "Processing sustainability\n",
      "tag 92: sustainability best model {'clf': RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "                       min_impurity_split=None, min_samples_leaf=1,\n",
      "                       min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                       n_estimators=15, n_jobs=None, oob_score=False,\n",
      "                       random_state=None, verbose=0, warm_start=False), 'clf__class_weight': 'balanced', 'clf__criterion': 'gini', 'clf__min_samples_split': 2, 'clf__n_estimators': 15, 'tfidf__use_idf': True}\n",
      "tag 92: sustainability counts - predicted: 26, actual: 20\n",
      "tag 92: sustainability test f1-score is 0.2173913043478261\n",
      "tag 92: sustainability test accuracy is 0.9373913043478261\n",
      "--------------------------\n",
      "Processing technology\n",
      "tag 93: technology best model {'clf': RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "                       criterion='entropy', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "                       min_impurity_split=None, min_samples_leaf=1,\n",
      "                       min_samples_split=5, min_weight_fraction_leaf=0.0,\n",
      "                       n_estimators=15, n_jobs=None, oob_score=False,\n",
      "                       random_state=None, verbose=0, warm_start=False), 'clf__class_weight': 'balanced', 'clf__criterion': 'entropy', 'clf__min_samples_split': 5, 'clf__n_estimators': 15, 'tfidf__use_idf': True}\n",
      "tag 93: technology counts - predicted: 439, actual: 163\n",
      "tag 93: technology test f1-score is 0.49833887043189373\n",
      "tag 93: technology test accuracy is 0.4747826086956522\n",
      "--------------------------\n",
      "Processing violence\n",
      "tag 94: violence best model {'clf': RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "                       min_impurity_split=None, min_samples_leaf=1,\n",
      "                       min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                       n_estimators=15, n_jobs=None, oob_score=False,\n",
      "                       random_state=None, verbose=0, warm_start=False), 'clf__class_weight': 'balanced', 'clf__criterion': 'gini', 'clf__min_samples_split': 2, 'clf__n_estimators': 15, 'tfidf__use_idf': True}\n",
      "tag 94: violence counts - predicted: 12, actual: 16\n",
      "tag 94: violence test f1-score is 0.07142857142857144\n",
      "tag 94: violence test accuracy is 0.9547826086956521\n",
      "--------------------------\n"
     ]
    }
   ],
   "source": [
    "for index in range(91, 95): #range(len(tags))\n",
    "    print(f\"Processing {tags[index]}\")\n",
    "    per_tag_model.fit(X_train, y_train[:, index])\n",
    "#     display(pd.DataFrame(per_tag_model.cv_results_))\n",
    "    t = 0.2 #threshold value\n",
    "    prediction_prob = per_tag_model.predict_proba(X_test)\n",
    "    prediction = (prediction_prob[:, 1] >= t).astype(int)\n",
    "    # save model or model params somewhere\n",
    "    print(f'tag {index}: {tags[index]} best model {per_tag_model.best_params_}')\n",
    "    print(f'tag {index}: {tags[index]} counts - predicted: {sum(prediction)}, actual: {sum(y_test[:, index])}')\n",
    "    print(f'tag {index}: {tags[index]} test f1-score is {f1_score(y_test[:, index], prediction, average=\"binary\")}')\n",
    "    print(f'tag {index}: {tags[index]} test accuracy is {accuracy_score(y_test[:, index], prediction)}')\n",
    "    print('--------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
