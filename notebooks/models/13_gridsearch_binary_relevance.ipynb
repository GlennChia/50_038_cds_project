{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, TfidfTransformer\n",
    "\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.metrics import f1_score, hamming_loss, make_scorer, accuracy_score\n",
    "\n",
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from skmultilearn.model_selection.measures import get_combination_wise_output_matrix\n",
    "from skmultilearn.model_selection import iterative_train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker</th>\n",
       "      <th>headline</th>\n",
       "      <th>description</th>\n",
       "      <th>duration</th>\n",
       "      <th>tags</th>\n",
       "      <th>transcript</th>\n",
       "      <th>WC</th>\n",
       "      <th>clean_transcript</th>\n",
       "      <th>clean_transcript_string</th>\n",
       "      <th>squash_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Al Gore</td>\n",
       "      <td>Averting the climate crisis</td>\n",
       "      <td>With the same humor and humanity he exuded in ...</td>\n",
       "      <td>0:16:17</td>\n",
       "      <td>cars,alternative energy,culture,politics,scien...</td>\n",
       "      <td>0:14\\r\\r\\rThank you so much, Chris.\\rAnd it's ...</td>\n",
       "      <td>2281.0</td>\n",
       "      <td>[thank, chris, truly, great, honor, opportunit...</td>\n",
       "      <td>thank chris truly great honor opportunity come...</td>\n",
       "      <td>culture,politics,science,climate change,enviro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Amy Smith</td>\n",
       "      <td>Simple designs to save a life</td>\n",
       "      <td>Fumes from indoor cooking fires kill more than...</td>\n",
       "      <td>0:15:06</td>\n",
       "      <td>MacArthur grant,simplicity,industrial design,a...</td>\n",
       "      <td>0:11\\r\\r\\rIn terms of invention,\\rI'd like to ...</td>\n",
       "      <td>2687.0</td>\n",
       "      <td>[term, invention, like, tell, tale, favorite, ...</td>\n",
       "      <td>term invention like tell tale favorite project...</td>\n",
       "      <td>invention,engineering,design,global issues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ashraf Ghani</td>\n",
       "      <td>How to rebuild a broken state</td>\n",
       "      <td>Ashraf Ghani's passionate and powerful 10-minu...</td>\n",
       "      <td>0:18:45</td>\n",
       "      <td>corruption,poverty,economics,investment,milita...</td>\n",
       "      <td>0:12\\r\\r\\rA public, Dewey long ago observed,\\r...</td>\n",
       "      <td>2506.0</td>\n",
       "      <td>[public, dewey, long, ago, observe, constitute...</td>\n",
       "      <td>public dewey long ago observe constitute discu...</td>\n",
       "      <td>poverty,economics,culture,politics,policy,glob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Burt Rutan</td>\n",
       "      <td>The real future of space exploration</td>\n",
       "      <td>In this passionate talk, legendary spacecraft ...</td>\n",
       "      <td>0:19:37</td>\n",
       "      <td>aircraft,flight,industrial design,NASA,rocket ...</td>\n",
       "      <td>0:11\\r\\r\\rI want to start off by saying, Houst...</td>\n",
       "      <td>3092.0</td>\n",
       "      <td>[want, start, say, houston, problem, enter, se...</td>\n",
       "      <td>want start say houston problem enter second ge...</td>\n",
       "      <td>invention,engineering,entrepreneur,design,busi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chris Bangle</td>\n",
       "      <td>Great cars are great art</td>\n",
       "      <td>American designer Chris Bangle explains his ph...</td>\n",
       "      <td>0:20:04</td>\n",
       "      <td>cars,industrial design,transportation,inventio...</td>\n",
       "      <td>0:12\\r\\r\\rWhat I want to talk about is, as bac...</td>\n",
       "      <td>3781.0</td>\n",
       "      <td>[want, talk, background, idea, car, art, actua...</td>\n",
       "      <td>want talk background idea car art actually mea...</td>\n",
       "      <td>invention,design,technology,business,art</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        speaker                              headline  \\\n",
       "0       Al Gore           Averting the climate crisis   \n",
       "1     Amy Smith         Simple designs to save a life   \n",
       "2  Ashraf Ghani         How to rebuild a broken state   \n",
       "3    Burt Rutan  The real future of space exploration   \n",
       "4  Chris Bangle              Great cars are great art   \n",
       "\n",
       "                                         description duration  \\\n",
       "0  With the same humor and humanity he exuded in ...  0:16:17   \n",
       "1  Fumes from indoor cooking fires kill more than...  0:15:06   \n",
       "2  Ashraf Ghani's passionate and powerful 10-minu...  0:18:45   \n",
       "3  In this passionate talk, legendary spacecraft ...  0:19:37   \n",
       "4  American designer Chris Bangle explains his ph...  0:20:04   \n",
       "\n",
       "                                                tags  \\\n",
       "0  cars,alternative energy,culture,politics,scien...   \n",
       "1  MacArthur grant,simplicity,industrial design,a...   \n",
       "2  corruption,poverty,economics,investment,milita...   \n",
       "3  aircraft,flight,industrial design,NASA,rocket ...   \n",
       "4  cars,industrial design,transportation,inventio...   \n",
       "\n",
       "                                          transcript      WC  \\\n",
       "0  0:14\\r\\r\\rThank you so much, Chris.\\rAnd it's ...  2281.0   \n",
       "1  0:11\\r\\r\\rIn terms of invention,\\rI'd like to ...  2687.0   \n",
       "2  0:12\\r\\r\\rA public, Dewey long ago observed,\\r...  2506.0   \n",
       "3  0:11\\r\\r\\rI want to start off by saying, Houst...  3092.0   \n",
       "4  0:12\\r\\r\\rWhat I want to talk about is, as bac...  3781.0   \n",
       "\n",
       "                                    clean_transcript  \\\n",
       "0  [thank, chris, truly, great, honor, opportunit...   \n",
       "1  [term, invention, like, tell, tale, favorite, ...   \n",
       "2  [public, dewey, long, ago, observe, constitute...   \n",
       "3  [want, start, say, houston, problem, enter, se...   \n",
       "4  [want, talk, background, idea, car, art, actua...   \n",
       "\n",
       "                             clean_transcript_string  \\\n",
       "0  thank chris truly great honor opportunity come...   \n",
       "1  term invention like tell tale favorite project...   \n",
       "2  public dewey long ago observe constitute discu...   \n",
       "3  want start say houston problem enter second ge...   \n",
       "4  want talk background idea car art actually mea...   \n",
       "\n",
       "                                         squash_tags  \n",
       "0  culture,politics,science,climate change,enviro...  \n",
       "1         invention,engineering,design,global issues  \n",
       "2  poverty,economics,culture,politics,policy,glob...  \n",
       "3  invention,engineering,entrepreneur,design,busi...  \n",
       "4           invention,design,technology,business,art  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_DIR = \"../../data/processed/\"\n",
    "INPUT_FILE_NAME = 'cleaned_squashed1.parquet'\n",
    "df = pd.read_parquet(DATA_DIR + INPUT_FILE_NAME)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2378 entries, 0 to 2377\n",
      "Data columns (total 10 columns):\n",
      "speaker                    2378 non-null object\n",
      "headline                   2378 non-null object\n",
      "description                2378 non-null object\n",
      "duration                   2378 non-null object\n",
      "tags                       2378 non-null object\n",
      "transcript                 2378 non-null object\n",
      "WC                         2378 non-null float64\n",
      "clean_transcript           2378 non-null object\n",
      "clean_transcript_string    2378 non-null object\n",
      "squash_tags                2378 non-null object\n",
      "dtypes: float64(1), object(9)\n",
      "memory usage: 185.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df = df.dropna(subset=['squash_tags'])\n",
    "df = df.reset_index(drop=True)\n",
    "df.iloc[:,:10].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['clean_transcript_string']\n",
    "labels = df[['squash_tags']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "y = []\n",
    "for index, row in labels.iterrows():\n",
    "    y.append(set(row['squash_tags'].split(',')))\n",
    "    \n",
    "mlb = MultiLabelBinarizer()\n",
    "encoded_y = mlb.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0]\n",
      "100\n",
      "[('climate change', 'culture', 'environment', 'global issues', 'politics', 'science', 'sustainability', 'technology'), ('design', 'engineering', 'global issues', 'invention'), ('business', 'culture', 'economics', 'entrepreneur', 'global development', 'global issues', 'policy', 'politics', 'poverty'), ('business', 'design', 'engineering', 'entrepreneur', 'invention'), ('art', 'business', 'design', 'invention', 'technology'), ('biodiversity', 'biology', 'biotech', 'ecology', 'entrepreneur', 'genetics', 'invention', 'oceans', 'science', 'technology'), ('computers', 'entertainment', 'media', 'music', 'performance', 'technology'), ('architecture', 'cities', 'collaboration', 'culture', 'design'), ('business', 'education', 'innovation', 'invention', 'robots', 'science', 'social change', 'sustainability', 'technology'), ('culture', 'disease', 'food', 'global issues', 'health', 'health care', 'science')]\n"
     ]
    }
   ],
   "source": [
    "print(encoded_y[0])\n",
    "print(len(encoded_y[0]))\n",
    "print(mlb.inverse_transform(encoded_y)[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from skmultilearn.model_selection.measures import get_combination_wise_output_matrix\n",
    "from skmultilearn.model_selection import iterative_train_test_split\n",
    "\n",
    "X_train, y_train, X_test, y_test = iterative_train_test_split(X.values.reshape(len(X.values), 1), encoded_y, test_size = 0.5)\n",
    "X_train = pd.DataFrame(X_train)[0]\n",
    "X_test = pd.DataFrame(X_test)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gridsearch for the best single model for all labels\n",
    "\n",
    "### References \n",
    "http://scikit.ml/api/skmultilearn.problem_transform.br.html\n",
    "\n",
    "https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "\n",
    "http://scikit.ml/stratification.html\n",
    "\n",
    "https://stackoverflow.com/questions/12632992/gridsearch-for-an-estimator-inside-a-onevsrestclassifier/12637528#12637528"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: \n",
    "# 1. Check if TfidfTransformer use_idf=False is the same as Countvectorizer? or there are other metrics to suppress\n",
    "# 2. Get scoring function to work, hamming? -- kinda done\n",
    "# 3. Balanced class labels\n",
    "# 4. Set better param ranges\n",
    "# 5. Remove vectorizer step once we decide on which is better, then use sparse csr and hopefully it trains faster\n",
    "\n",
    "# param_range = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "param_range = [1, 2, 3, 4, 5]\n",
    "param_range_lr = [1.0, 0.5, 0.1]\n",
    "\n",
    "# Set params, comment out as see fit\n",
    "\n",
    "vectorizer_params = {\n",
    "#     'vectorizer__min_df': np.linspace(0.005, 0.05, 5),\n",
    "#     'vectorizer__ngram_range': [(1, 1), (1, 2)], # This shit blows up your memory\n",
    "#     'tfidf__norm': ('l1', 'l2'),\n",
    "    'tfidf__use_idf': [True, False],\n",
    "}\n",
    "\n",
    "lr_params = {\n",
    "    'clf__classifier': [LogisticRegression()],\n",
    "        'clf__classifier__penalty': ['l1', 'l2'],\n",
    "        'clf__classifier__C': param_range_lr,\n",
    "        'clf__classifier__solver': ['liblinear']\n",
    "}\n",
    "\n",
    "svc_params = {\n",
    "    'clf__classifier': [SVC()],\n",
    "        'clf__classifier__kernel': ['linear', 'rbf'],\n",
    "        'clf__classifier__C': param_range, # np.logspace(-1, 2, 10),\n",
    "        'clf__classifier__gamma': ['auto'], # np.logspace(-1, 1, 10)\n",
    "        'clf__classifier__probability': [True],\n",
    "}\n",
    "\n",
    "rf_params = {\n",
    "    'clf__classifier': [RandomForestClassifier()],\n",
    "        'clf__classifier__criterion': ['gini', 'entropy'],\n",
    "        'clf__classifier__min_samples_leaf': param_range,\n",
    "        'clf__classifier__max_depth': param_range,\n",
    "        'clf__classifier__min_samples_split': param_range[1:],\n",
    "        'clf__classifier__n_estimators': [10],\n",
    "}\n",
    "\n",
    "mnb_params = {\n",
    "    'clf__classifier': [MultinomialNB()],\n",
    "        'clf__classifier__alpha': [0.7, 1.0],\n",
    "}\n",
    "\n",
    "## Stack params\n",
    "parameters = [\n",
    "#     {**vectorizer_params, **lr_params},\n",
    "#     {**vectorizer_params, **svc_params},\n",
    "#     {**vectorizer_params, **rf_params},\n",
    "    {**vectorizer_params, **mnb_params}\n",
    "]\n",
    "\n",
    "br_pipeline = Pipeline([('vectorizer', CountVectorizer()),\n",
    "                        ('tfidf', TfidfTransformer()),\n",
    "                        ('clf', BinaryRelevance()),\n",
    "                       ]\n",
    "                      )\n",
    "\n",
    "# Gridsearch settings\n",
    "# scoring = make_scorer(f1_score, average='micro') # possible scorings 'f1_micro' 'f1_macro'\n",
    "# scoring = 'f1_micro'\n",
    "# scoring = make_scorer(hamming_loss)\n",
    "# scoring = 'neg_log_loss'\n",
    "scoring = 'f1_samples'\n",
    "folds = 3\n",
    "njobs = -1\n",
    "\n",
    "br_model = GridSearchCV(br_pipeline, parameters, scoring=scoring, cv=folds, n_jobs=njobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'clf__classifier': MultinomialNB(alpha=0.7, class_prior=None, fit_prior=True), 'clf__classifier__alpha': 0.7, 'tfidf__use_idf': True} 0.0\n",
      "Wall time: 2min 33s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_clf__classifier</th>\n",
       "      <th>param_clf__classifier__alpha</th>\n",
       "      <th>param_tfidf__use_idf</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48.060127</td>\n",
       "      <td>4.288809</td>\n",
       "      <td>18.222782</td>\n",
       "      <td>2.329696</td>\n",
       "      <td>MultinomialNB(alpha=0.7, class_prior=None, fit...</td>\n",
       "      <td>0.7</td>\n",
       "      <td>True</td>\n",
       "      <td>{'clf__classifier': MultinomialNB(alpha=0.7, c...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58.619017</td>\n",
       "      <td>3.219350</td>\n",
       "      <td>14.699179</td>\n",
       "      <td>1.495346</td>\n",
       "      <td>MultinomialNB(alpha=0.7, class_prior=None, fit...</td>\n",
       "      <td>0.7</td>\n",
       "      <td>False</td>\n",
       "      <td>{'clf__classifier': MultinomialNB(alpha=0.7, c...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47.445024</td>\n",
       "      <td>10.882486</td>\n",
       "      <td>12.850930</td>\n",
       "      <td>0.220582</td>\n",
       "      <td>MultinomialNB(alpha=0.7, class_prior=None, fit...</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>{'clf__classifier': MultinomialNB(alpha=0.7, c...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30.636636</td>\n",
       "      <td>0.610798</td>\n",
       "      <td>11.925782</td>\n",
       "      <td>0.590671</td>\n",
       "      <td>MultinomialNB(alpha=0.7, class_prior=None, fit...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>{'clf__classifier': MultinomialNB(alpha=0.7, c...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0      48.060127      4.288809        18.222782        2.329696   \n",
       "1      58.619017      3.219350        14.699179        1.495346   \n",
       "2      47.445024     10.882486        12.850930        0.220582   \n",
       "3      30.636636      0.610798        11.925782        0.590671   \n",
       "\n",
       "                               param_clf__classifier  \\\n",
       "0  MultinomialNB(alpha=0.7, class_prior=None, fit...   \n",
       "1  MultinomialNB(alpha=0.7, class_prior=None, fit...   \n",
       "2  MultinomialNB(alpha=0.7, class_prior=None, fit...   \n",
       "3  MultinomialNB(alpha=0.7, class_prior=None, fit...   \n",
       "\n",
       "  param_clf__classifier__alpha param_tfidf__use_idf  \\\n",
       "0                          0.7                 True   \n",
       "1                          0.7                False   \n",
       "2                            1                 True   \n",
       "3                            1                False   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'clf__classifier': MultinomialNB(alpha=0.7, c...                0.0   \n",
       "1  {'clf__classifier': MultinomialNB(alpha=0.7, c...                0.0   \n",
       "2  {'clf__classifier': MultinomialNB(alpha=0.7, c...                0.0   \n",
       "3  {'clf__classifier': MultinomialNB(alpha=0.7, c...                0.0   \n",
       "\n",
       "   split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "0                0.0                0.0              0.0             0.0   \n",
       "1                0.0                0.0              0.0             0.0   \n",
       "2                0.0                0.0              0.0             0.0   \n",
       "3                0.0                0.0              0.0             0.0   \n",
       "\n",
       "   rank_test_score  \n",
       "0                1  \n",
       "1                1  \n",
       "2                1  \n",
       "3                1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "br_model.fit(X_train,y_train)\n",
    "print(br_model.best_params_, br_model.best_score_)\n",
    "pd.DataFrame(br_model.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary relevance best model's f1-score 0.01589319771137953\n"
     ]
    }
   ],
   "source": [
    "y_pred_prob = br_model.predict_proba(X_test)\n",
    "t = 0.1 # threshold value\n",
    "y_pred_new = (y_pred_prob >= t).astype(int)\n",
    "score = f1_score(y_test, y_pred_new, average=\"micro\")\n",
    "print(f\"Binary relevance best model's f1-score {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OneVsRest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: \n",
    "# 1. Check if TfidfTransformer use_idf=False is the same as Countvectorizer? or there are other metrics to suppress\n",
    "# 2. Use proper scoring function - ideally, predicting relevant labels should be more important than predicting irrelevant ones\n",
    "# 3. Balanced class labels\n",
    "# 4. Set better param ranges\n",
    "\n",
    "# param_range = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "param_range = [1, 2, 3, 4, 5]\n",
    "param_range_lr = [1.0, 0.5, 0.1]\n",
    "\n",
    "# Set params, comment out as see fit\n",
    "\n",
    "vectorizer_params = {\n",
    "#     'vectorizer__min_df': np.linspace(0.005, 0.05, 5),\n",
    "#     'vectorizer__ngram_range': [(1, 1), (1, 2)], # This shit blows up your memory\n",
    "#     'tfidf__norm': ('l1', 'l2'),\n",
    "    'tfidf__use_idf': [True, False],\n",
    "}\n",
    "\n",
    "lr_params = {\n",
    "    'clf__estimator': [LogisticRegression()],\n",
    "        'clf__estimator__penalty': ['l1', 'l2'],\n",
    "        'clf__estimator__C': param_range_lr,\n",
    "        'clf__estimator__solver': ['liblinear']\n",
    "}\n",
    "\n",
    "svc_params = {\n",
    "    'clf__estimator': [SVC()],\n",
    "        'clf__estimator__kernel': ['linear', 'rbf'],\n",
    "        'clf__estimator__C': param_range, # np.logspace(-1, 2, 10),\n",
    "        'clf__estimator__gamma': ['auto'], # np.logspace(-1, 1, 10)\n",
    "        'clf__estimator__probability': [True],\n",
    "}\n",
    "\n",
    "rf_params = {\n",
    "    'clf__estimator': [RandomForestClassifier()],\n",
    "        'clf__estimator__criterion': ['gini', 'entropy'],\n",
    "        'clf__estimator__min_samples_leaf': param_range,\n",
    "        'clf__estimator__max_depth': param_range,\n",
    "        'clf__estimator__min_samples_split': param_range[1:],\n",
    "        'clf__estimator__n_estimators': [10],\n",
    "}\n",
    "\n",
    "mnb_params = {\n",
    "    'clf__estimator': [MultinomialNB()],\n",
    "        'clf__estimator__alpha': [0.7, 1.0],\n",
    "}\n",
    "\n",
    "## Stack params\n",
    "parameters = [\n",
    "#     {**vectorizer_params, **lr_params},\n",
    "#     {**vectorizer_params, **svc_params},\n",
    "#     {**vectorizer_params, **rf_params},\n",
    "    {**vectorizer_params, **mnb_params}\n",
    "]\n",
    "\n",
    "ovr_pipeline = Pipeline([('vectorizer', CountVectorizer()),\n",
    "                         ('tfidf', TfidfTransformer()),\n",
    "                         ('clf', OneVsRestClassifier(LogisticRegression())),\n",
    "                        ]\n",
    "                       )\n",
    "\n",
    "# Gridsearch settings\n",
    "# scoring = make_scorer(f1_score, average='micro') # possible scorings 'f1_micro' 'f1_macro'\n",
    "scoring = 'f1_micro'\n",
    "# scoring = make_scorer(hamming_loss) # hamming gives equal weighting to both relevant and irrelevant?\n",
    "# maybe use precision somewhere\n",
    "folds = 3\n",
    "njobs = -1\n",
    "\n",
    "ovr_model = GridSearchCV(ovr_pipeline, parameters, scoring=scoring, cv=folds, n_jobs=njobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'clf__estimator': MultinomialNB(alpha=0.7, class_prior=None, fit_prior=True), 'clf__estimator__alpha': 0.7, 'tfidf__use_idf': True} 0.0\n",
      "Wall time: 15.3 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_clf__estimator</th>\n",
       "      <th>param_clf__estimator__alpha</th>\n",
       "      <th>param_tfidf__use_idf</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.917587</td>\n",
       "      <td>0.115933</td>\n",
       "      <td>1.192995</td>\n",
       "      <td>0.058628</td>\n",
       "      <td>MultinomialNB(alpha=0.7, class_prior=None, fit...</td>\n",
       "      <td>0.7</td>\n",
       "      <td>True</td>\n",
       "      <td>{'clf__estimator': MultinomialNB(alpha=0.7, cl...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.578013</td>\n",
       "      <td>0.586987</td>\n",
       "      <td>1.206009</td>\n",
       "      <td>0.099401</td>\n",
       "      <td>MultinomialNB(alpha=0.7, class_prior=None, fit...</td>\n",
       "      <td>0.7</td>\n",
       "      <td>False</td>\n",
       "      <td>{'clf__estimator': MultinomialNB(alpha=0.7, cl...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.442348</td>\n",
       "      <td>0.663231</td>\n",
       "      <td>1.074932</td>\n",
       "      <td>0.306867</td>\n",
       "      <td>MultinomialNB(alpha=0.7, class_prior=None, fit...</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>{'clf__estimator': MultinomialNB(alpha=0.7, cl...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.476177</td>\n",
       "      <td>0.138633</td>\n",
       "      <td>0.726943</td>\n",
       "      <td>0.097849</td>\n",
       "      <td>MultinomialNB(alpha=0.7, class_prior=None, fit...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>{'clf__estimator': MultinomialNB(alpha=0.7, cl...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       2.917587      0.115933         1.192995        0.058628   \n",
       "1       3.578013      0.586987         1.206009        0.099401   \n",
       "2       3.442348      0.663231         1.074932        0.306867   \n",
       "3       2.476177      0.138633         0.726943        0.097849   \n",
       "\n",
       "                                param_clf__estimator  \\\n",
       "0  MultinomialNB(alpha=0.7, class_prior=None, fit...   \n",
       "1  MultinomialNB(alpha=0.7, class_prior=None, fit...   \n",
       "2  MultinomialNB(alpha=0.7, class_prior=None, fit...   \n",
       "3  MultinomialNB(alpha=0.7, class_prior=None, fit...   \n",
       "\n",
       "  param_clf__estimator__alpha param_tfidf__use_idf  \\\n",
       "0                         0.7                 True   \n",
       "1                         0.7                False   \n",
       "2                           1                 True   \n",
       "3                           1                False   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'clf__estimator': MultinomialNB(alpha=0.7, cl...                0.0   \n",
       "1  {'clf__estimator': MultinomialNB(alpha=0.7, cl...                0.0   \n",
       "2  {'clf__estimator': MultinomialNB(alpha=0.7, cl...                0.0   \n",
       "3  {'clf__estimator': MultinomialNB(alpha=0.7, cl...                0.0   \n",
       "\n",
       "   split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "0                0.0                0.0              0.0             0.0   \n",
       "1                0.0                0.0              0.0             0.0   \n",
       "2                0.0                0.0              0.0             0.0   \n",
       "3                0.0                0.0              0.0             0.0   \n",
       "\n",
       "   rank_test_score  \n",
       "0                1  \n",
       "1                1  \n",
       "2                1  \n",
       "3                1  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "ovr_model.fit(X_train,y_train)\n",
    "print(ovr_model.best_params_, ovr_model.best_score_)\n",
    "pd.DataFrame(ovr_model.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One vs Rest best model's f1-score 0.01589319771137953\n"
     ]
    }
   ],
   "source": [
    "y_pred_prob = ovr_model.predict_proba(X_test)\n",
    "t = 0.1 # threshold value\n",
    "y_pred_new = (y_pred_prob >= t).astype(int)\n",
    "score = f1_score(y_test, y_pred_new, average=\"micro\")\n",
    "print(f\"One vs Rest best model's f1-score {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gridsearch best model for each tag\n",
    "\n",
    "https://stackoverflow.com/questions/38555650/try-multiple-estimator-in-one-grid-search\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_range = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "param_range = [1, 2, 3, 4, 5]\n",
    "param_range_lr = [1.0, 0.5, 0.1]\n",
    "\n",
    "# Set params, comment out as see fit\n",
    "\n",
    "vectorizer_params = {\n",
    "#     'vectorizer__min_df': np.linspace(0.005, 0.05, 5),\n",
    "#     'vectorizer__ngram_range': [(1, 1), (1, 2)], # This shit blows up your memory\n",
    "#     'tfidf__norm': ('l1', 'l2'),\n",
    "    'tfidf__use_idf': [True, False],\n",
    "}\n",
    "\n",
    "# Add any Binary classification model setting here.\n",
    "# Also add to general parameters to be passed into pipeline below if want to use new model.\n",
    "\n",
    "lr_params = {\n",
    "    'clf': [LogisticRegression()],\n",
    "        'clf__penalty': ['l1', 'l2'],\n",
    "        'clf__C': param_range_lr,\n",
    "        'clf__solver': ['liblinear'],\n",
    "}\n",
    "\n",
    "svc_params = {\n",
    "    'clf': [SVC()],\n",
    "        'clf__kernel': ['linear', 'rbf'],\n",
    "        'clf__C': param_range, # np.logspace(-1, 2, 10),\n",
    "        'clf__gamma': ['auto'], # np.logspace(-1, 1, 10)\n",
    "        'clf__probability': [True],\n",
    "}\n",
    "\n",
    "rf_params = {\n",
    "    'clf': [RandomForestClassifier()],\n",
    "        'clf__criterion': ['gini', 'entropy'],\n",
    "#         'clf__min_samples_leaf': param_range,\n",
    "#         'clf__max_depth': param_range,\n",
    "        'clf__min_samples_split': param_range[1:],\n",
    "        'clf__n_estimators': [15],\n",
    "}\n",
    "\n",
    "mnb_params = {\n",
    "    'clf': [MultinomialNB()],\n",
    "        'clf__alpha': [0.7, 1.0],\n",
    "}\n",
    "\n",
    "## Stack params\n",
    "parameters = [\n",
    "#     {**vectorizer_params, **lr_params},\n",
    "#     {**vectorizer_params, **svc_params},\n",
    "    {**vectorizer_params, **rf_params},\n",
    "#     {**vectorizer_params, **mnb_params}\n",
    "]\n",
    "\n",
    "per_tag_pipe = Pipeline([('vectorizer', CountVectorizer()), \n",
    "                  ('tfidf', TfidfTransformer()), \n",
    "                  ('clf', LogisticRegression())])\n",
    "\n",
    "# scoring = make_scorer(hamming_loss)\n",
    "scoring = 'f1'\n",
    "# scoring = 'f1_micro'\n",
    "# scoring = 'balanced_accuracy'\n",
    "# scoring = 'precision'\n",
    "folds = 3\n",
    "njobs = -1\n",
    "\n",
    "per_tag_model = GridSearchCV(per_tag_pipe, parameters, scoring=scoring, cv=folds, n_jobs=njobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['activism', 'adventure', 'africa', 'animals', 'architecture', 'art', 'beauty', 'big problems', 'biodiversity', 'biology', 'biotech', 'brain', 'business', 'children', 'cities', 'climate change', 'cognitive science', 'collaboration', 'communication', 'community', 'computers', 'creativity', 'culture', 'data', 'demo', 'design', 'disease', 'ecology', 'economics', 'education', 'energy', 'engineering', 'entertainment', 'entrepreneur', 'environment', 'evolution', 'exploration', 'family', 'film', 'food', 'future', 'genetics', 'global development', 'global issues', 'government', 'green', 'happiness', 'health', 'health care', 'history', 'humanity', 'humor', 'identity', 'illness', 'inequality', 'innovation', 'internet', 'invention', 'language', 'leadership', 'life', 'live music', 'math', 'media', 'medical research', 'medicine', 'mental health', 'mind', 'motivation', 'music', 'nature', 'neuroscience', 'oceans', 'parenting', 'peace', 'performance', 'personal growth', 'philosophy', 'photography', 'physics', 'policy', 'politics', 'potential', 'poverty', 'psychology', 'religion', 'robots', 'science', 'social change', 'society', 'space', 'storytelling', 'sustainability', 'technology', 'violence', 'visualizations', 'war', 'women', 'work', 'writing']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "93"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags = [tag for tag in mlb.inverse_transform(np.ones(shape=(1, 100)))[0]]\n",
    "print(tags)\n",
    "tags.index('technology')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing storytelling\n",
      "tag 91: storytelling best model {'clf': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=15,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False), 'clf__criterion': 'gini', 'clf__min_samples_split': 2, 'clf__n_estimators': 15, 'tfidf__use_idf': True}\n",
      "tag 91: storytelling counts - predicted: 22, actual: 59\n",
      "tag 91: storytelling test f1-score is 0.07407407407407408\n",
      "tag 91: storytelling test accuracy is 0.9362244897959183\n",
      "--------------------------\n",
      "Processing sustainability\n",
      "tag 92: sustainability best model {'clf': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=15,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False), 'clf__criterion': 'gini', 'clf__min_samples_split': 2, 'clf__n_estimators': 15, 'tfidf__use_idf': True}\n",
      "tag 92: sustainability counts - predicted: 30, actual: 36\n",
      "tag 92: sustainability test f1-score is 0.1515151515151515\n",
      "tag 92: sustainability test accuracy is 0.9523809523809523\n",
      "--------------------------\n",
      "Processing technology\n",
      "tag 93: technology best model {'clf': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=5,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=15,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False), 'clf__criterion': 'gini', 'clf__min_samples_split': 5, 'clf__n_estimators': 15, 'tfidf__use_idf': True}\n",
      "tag 93: technology counts - predicted: 770, actual: 348\n",
      "tag 93: technology test f1-score is 0.5599284436493739\n",
      "tag 93: technology test accuracy is 0.5816326530612245\n",
      "--------------------------\n",
      "Processing violence\n",
      "tag 94: violence best model {'clf': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=15,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False), 'clf__criterion': 'gini', 'clf__min_samples_split': 2, 'clf__n_estimators': 15, 'tfidf__use_idf': True}\n",
      "tag 94: violence counts - predicted: 14, actual: 35\n",
      "tag 94: violence test f1-score is 0.08163265306122448\n",
      "tag 94: violence test accuracy is 0.9617346938775511\n",
      "--------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for index in range(91, 95): #range(len(tags))\n",
    "    print(f\"Processing {tags[index]}\")\n",
    "    per_tag_model.fit(X_train, y_train[:, index])\n",
    "#     display(pd.DataFrame(per_tag_model.cv_results_))\n",
    "    t = 0.2 #threshold value\n",
    "    prediction_prob = per_tag_model.predict_proba(X_test)\n",
    "    prediction = (prediction_prob[:, 1] >= t).astype(int)\n",
    "    # save model or model params somewhere\n",
    "    print(f'tag {index}: {tags[index]} best model {per_tag_model.best_params_}')\n",
    "    print(f'tag {index}: {tags[index]} counts - predicted: {sum(prediction)}, actual: {sum(y_test[:, index])}')\n",
    "    print(f'tag {index}: {tags[index]} test f1-score is {f1_score(y_test[:, index], prediction, average=\"binary\")}')\n",
    "    print(f'tag {index}: {tags[index]} test accuracy is {accuracy_score(y_test[:, index], prediction)}')\n",
    "    print('--------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
