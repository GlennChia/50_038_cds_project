{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "colab": {
      "name": "colab_gridsearcher.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xh59vWA2qxv",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/GlennChia/50_038_cds_project/blob/master/notebooks/models/colab_gridsearcher.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJBOTheYXd36",
        "colab_type": "code",
        "outputId": "db5633f1-3592-4aa7-c63d-34a987422e83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "!pip install scikit-multilearn"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting scikit-multilearn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/1f/e6ff649c72a1cdf2c7a1d31eb21705110ce1c5d3e7e26b2cc300e1637272/scikit_multilearn-0.2.0-py3-none-any.whl (89kB)\n",
            "\r\u001b[K     |███▊                            | 10kB 21.4MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 20kB 4.1MB/s eta 0:00:01\r\u001b[K     |███████████                     | 30kB 5.8MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 40kB 7.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 51kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 61kB 5.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 71kB 6.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 81kB 7.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 92kB 4.7MB/s \n",
            "\u001b[?25hInstalling collected packages: scikit-multilearn\n",
            "Successfully installed scikit-multilearn-0.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmkdfuuuXRmn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import glob\n",
        "import joblib\n",
        "\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, TfidfTransformer\n",
        "\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "from sklearn.metrics import f1_score, hamming_loss, make_scorer, accuracy_score\n",
        "\n",
        "from skmultilearn.problem_transform import BinaryRelevance\n",
        "from skmultilearn.model_selection.measures import get_combination_wise_output_matrix\n",
        "from skmultilearn.model_selection import iterative_train_test_split\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-WZ6R6e7Lsa",
        "colab_type": "text"
      },
      "source": [
        "# IMPORTANT\n",
        "\n",
        "First, press f12 or Ctrl + Shift + I to open up console.\n",
        "\n",
        "Paste the following code to prevent timeout.\n",
        "\n",
        "```\n",
        "function ClickConnect() {\n",
        "  console.log(\"Working\"); \n",
        "  document.querySelector(\"colab-toolbar-button#connect\").click() \n",
        "}\n",
        "setInterval(ClickConnect,60000)\n",
        "```\n",
        "\n",
        "Then run the below code and click allow multiple downloads to ensure all models get downloaded.\n",
        "\n",
        "These temp files can be deleted after they've been run"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-X1Rpm27Ki8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "83b9fe91-391c-4839-8c21-ad4106e9ebcc"
      },
      "source": [
        "!touch temp1.txt temp2.txt temp3.txt\n",
        "temp_files = glob.glob(\"*.txt\")\n",
        "for file in temp_files:\n",
        "    print(f'Downloading {file} ...')\n",
        "    files.download(file)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading temp3.txt ...\n",
            "Downloading temp2.txt ...\n",
            "Downloading temp1.txt ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVJbn09PXRmq",
        "colab_type": "code",
        "outputId": "c6eff49d-f1c2-4437-a030-725eac916bd3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        }
      },
      "source": [
        "DATA_DIR = \"\"\n",
        "INPUT_FILE_NAME = \"https://github.com/GlennChia/50_038_cds_project/blob/master/data/processed/cleaned_squashed3.parquet?raw=true\"\n",
        "df = pd.read_parquet(DATA_DIR + INPUT_FILE_NAME)\n",
        "df.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>speaker</th>\n",
              "      <th>headline</th>\n",
              "      <th>description</th>\n",
              "      <th>duration</th>\n",
              "      <th>tags</th>\n",
              "      <th>transcript</th>\n",
              "      <th>WC</th>\n",
              "      <th>clean_transcript</th>\n",
              "      <th>clean_transcript_string</th>\n",
              "      <th>squash_tags</th>\n",
              "      <th>squash2_tags</th>\n",
              "      <th>squash3_tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Al Gore</td>\n",
              "      <td>Averting the climate crisis</td>\n",
              "      <td>With the same humor and humanity he exuded in ...</td>\n",
              "      <td>0:16:17</td>\n",
              "      <td>cars,alternative energy,culture,politics,scien...</td>\n",
              "      <td>0:14\\r\\r\\rThank you so much, Chris.\\rAnd it's ...</td>\n",
              "      <td>2281.0</td>\n",
              "      <td>[thank, chris, truly, great, honor, opportunit...</td>\n",
              "      <td>thank chris truly great honor opportunity come...</td>\n",
              "      <td>culture,politics,science,climate change,enviro...</td>\n",
              "      <td>culture,politics,science,global issues,environ...</td>\n",
              "      <td>culture,politics,science,global issues,environ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Amy Smith</td>\n",
              "      <td>Simple designs to save a life</td>\n",
              "      <td>Fumes from indoor cooking fires kill more than...</td>\n",
              "      <td>0:15:06</td>\n",
              "      <td>MacArthur grant,simplicity,industrial design,a...</td>\n",
              "      <td>0:11\\r\\r\\rIn terms of invention,\\rI'd like to ...</td>\n",
              "      <td>2687.0</td>\n",
              "      <td>[term, invention, like, tell, tale, favorite, ...</td>\n",
              "      <td>term invention like tell tale favorite project...</td>\n",
              "      <td>invention,engineering,design,global issues</td>\n",
              "      <td>invention,engineering,design,global issues</td>\n",
              "      <td>invention,design,global issues</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Ashraf Ghani</td>\n",
              "      <td>How to rebuild a broken state</td>\n",
              "      <td>Ashraf Ghani's passionate and powerful 10-minu...</td>\n",
              "      <td>0:18:45</td>\n",
              "      <td>corruption,poverty,economics,investment,milita...</td>\n",
              "      <td>0:12\\r\\r\\rA public, Dewey long ago observed,\\r...</td>\n",
              "      <td>2506.0</td>\n",
              "      <td>[public, dewey, long, ago, observe, constitute...</td>\n",
              "      <td>public dewey long ago observe constitute discu...</td>\n",
              "      <td>poverty,economics,culture,politics,policy,glob...</td>\n",
              "      <td>inequality,economics,culture,politics,governme...</td>\n",
              "      <td>inequality,economics,culture,politics,global i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Burt Rutan</td>\n",
              "      <td>The real future of space exploration</td>\n",
              "      <td>In this passionate talk, legendary spacecraft ...</td>\n",
              "      <td>0:19:37</td>\n",
              "      <td>aircraft,flight,industrial design,NASA,rocket ...</td>\n",
              "      <td>0:11\\r\\r\\rI want to start off by saying, Houst...</td>\n",
              "      <td>3092.0</td>\n",
              "      <td>[want, start, say, houston, problem, enter, se...</td>\n",
              "      <td>want start say houston problem enter second ge...</td>\n",
              "      <td>invention,engineering,entrepreneur,design,busi...</td>\n",
              "      <td>invention,engineering,entrepreneur,design,busi...</td>\n",
              "      <td>invention,design,business</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Chris Bangle</td>\n",
              "      <td>Great cars are great art</td>\n",
              "      <td>American designer Chris Bangle explains his ph...</td>\n",
              "      <td>0:20:04</td>\n",
              "      <td>cars,industrial design,transportation,inventio...</td>\n",
              "      <td>0:12\\r\\r\\rWhat I want to talk about is, as bac...</td>\n",
              "      <td>3781.0</td>\n",
              "      <td>[want, talk, background, idea, car, art, actua...</td>\n",
              "      <td>want talk background idea car art actually mea...</td>\n",
              "      <td>invention,design,technology,business,art</td>\n",
              "      <td>invention,design,technology,business,art</td>\n",
              "      <td>invention,design,technology,business,art</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        speaker  ...                                       squash3_tags\n",
              "0       Al Gore  ...  culture,politics,science,global issues,environ...\n",
              "1     Amy Smith  ...                     invention,design,global issues\n",
              "2  Ashraf Ghani  ...  inequality,economics,culture,politics,global i...\n",
              "3    Burt Rutan  ...                          invention,design,business\n",
              "4  Chris Bangle  ...           invention,design,technology,business,art\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_CKNP22XRmt",
        "colab_type": "code",
        "outputId": "24843634-56ec-486f-acd7-c5385e0c93eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "df = df.dropna(subset=['squash3_tags'])\n",
        "df = df.reset_index(drop=True)\n",
        "df.iloc[:,:10].info()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2328 entries, 0 to 2327\n",
            "Data columns (total 10 columns):\n",
            "speaker                    2328 non-null object\n",
            "headline                   2328 non-null object\n",
            "description                2328 non-null object\n",
            "duration                   2328 non-null object\n",
            "tags                       2328 non-null object\n",
            "transcript                 2328 non-null object\n",
            "WC                         2328 non-null float64\n",
            "clean_transcript           2328 non-null object\n",
            "clean_transcript_string    2328 non-null object\n",
            "squash_tags                2328 non-null object\n",
            "dtypes: float64(1), object(9)\n",
            "memory usage: 182.0+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPfHVZRxXRmw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = df['clean_transcript_string']\n",
        "labels = df[['squash3_tags']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rb6UGWzzXRmy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = []\n",
        "for index, row in labels.iterrows():\n",
        "    y.append(set(row['squash3_tags'].split(',')))\n",
        "    \n",
        "mlb = MultiLabelBinarizer()\n",
        "encoded_y = mlb.fit_transform(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXQqs2GnXRm2",
        "colab_type": "code",
        "outputId": "9ac311cc-69da-403d-d1cc-e540f3563f4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "print(encoded_y[0])\n",
        "print(len(encoded_y[0]))\n",
        "print(mlb.inverse_transform(encoded_y)[:10])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 1 1 1]\n",
            "26\n",
            "[('culture', 'environment', 'global issues', 'politics', 'science', 'technology'), ('design', 'global issues', 'invention'), ('business', 'culture', 'economics', 'global issues', 'inequality', 'politics'), ('business', 'design', 'invention'), ('art', 'business', 'design', 'invention', 'technology'), ('biodiversity', 'invention', 'science', 'technology'), ('entertainment', 'music', 'technology'), ('collaboration', 'culture', 'design'), ('business', 'culture', 'education', 'global issues', 'invention', 'science', 'technology'), ('culture', 'global issues', 'science')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNEwcoeDXRm4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from skmultilearn.model_selection import iterative_train_test_split\n",
        "\n",
        "X_train, y_train, X_test, y_test = iterative_train_test_split(X.values.reshape(len(X.values), 1), encoded_y, test_size = 0.2)\n",
        "X_train = pd.DataFrame(X_train)[0]\n",
        "X_test = pd.DataFrame(X_test)[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOLvy5u2XRm6",
        "colab_type": "code",
        "outputId": "25c7bfa4-4287-42c5-8362-732f375eea35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "print(y_train.sum(axis=0))\n",
        "print(y_test.sum(axis=0))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[108 209 171 115 263 105 130 142 105 868 320 123 164 228 115 174 543 101\n",
            " 128  91 104 117  99 146 684 630]\n",
            "[ 39  52  44  33  66  30  33  43  31 238  80  31  42  57  40  44 136  34\n",
            "  36  37  32  39  27  37 184 157]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODj-226sXRm8",
        "colab_type": "text"
      },
      "source": [
        "## Gridsearch for the best single model for all labels\n",
        "\n",
        "### References \n",
        "http://scikit.ml/api/skmultilearn.problem_transform.br.html\n",
        "\n",
        "https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "\n",
        "http://scikit.ml/stratification.html\n",
        "\n",
        "https://stackoverflow.com/questions/12632992/gridsearch-for-an-estimator-inside-a-onevsrestclassifier/12637528#12637528"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2uvjkMawXRm8",
        "colab_type": "text"
      },
      "source": [
        "### Binary Relevance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZO19FxkXRm9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO: \n",
        "# 1. Check if TfidfTransformer use_idf=False is the same as Countvectorizer? or there are other metrics to suppress\n",
        "# 2. Get scoring function to work, hamming? -- kinda done\n",
        "# 3. Balanced class labels\n",
        "# 4. Set better param ranges\n",
        "# 5. Remove vectorizer step once we decide on which is better, then use sparse csr and hopefully it trains faster\n",
        "\n",
        "param_range = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
        "# param_range = [1, 2, 3, 4, 5]\n",
        "param_range_lr = [1.0, 0.5, 0.1]\n",
        "\n",
        "# Set params, comment out as see fit\n",
        "\n",
        "vectorizer_params = {\n",
        "    'vectorizer__min_df': np.linspace(0.005, 0.05, 5),\n",
        "    'vectorizer__ngram_range': [(1, 1), (1, 2)], # This shit blows up your memory\n",
        "    'tfidf__norm': ('l1', 'l2'),\n",
        "    'tfidf__use_idf': [True, False],\n",
        "}\n",
        "\n",
        "lr_params = {\n",
        "    'clf__classifier': [LogisticRegression()],\n",
        "        'clf__classifier__penalty': ['l1', 'l2'],\n",
        "        'clf__classifier__C': param_range_lr,\n",
        "        'clf__classifier__solver': ['liblinear'],\n",
        "        'clf__classifier__class_weight': ['balanced'],\n",
        "}\n",
        "\n",
        "svc_params = {\n",
        "    'clf__classifier': [SVC()],\n",
        "        'clf__classifier__kernel': ['linear', 'rbf'],\n",
        "        'clf__classifier__C': param_range, # np.logspace(-1, 2, 10),\n",
        "        'clf__classifier__gamma': ['auto'], # np.logspace(-1, 1, 10)\n",
        "        'clf__classifier__probability': [True],\n",
        "        'clf__classifier__class_weight': ['balanced'],\n",
        "}\n",
        "\n",
        "rf_params = {\n",
        "    'clf__classifier': [RandomForestClassifier()],\n",
        "        'clf__classifier__criterion': ['gini', 'entropy'],\n",
        "        'clf__classifier__min_samples_leaf': param_range,\n",
        "        'clf__classifier__max_depth': param_range,\n",
        "        'clf__classifier__min_samples_split': param_range[1:],\n",
        "        'clf__classifier__n_estimators': [10],\n",
        "        'clf__classifier__class_weight': ['balanced'],\n",
        "}\n",
        "\n",
        "mnb_params = {\n",
        "    'clf__classifier': [MultinomialNB()],\n",
        "        'clf__classifier__alpha': [0.7, 1.0],\n",
        "}\n",
        "\n",
        "## Stack params\n",
        "parameters = [\n",
        "    {**vectorizer_params, **lr_params},\n",
        "    {**vectorizer_params, **svc_params},\n",
        "    {**vectorizer_params, **rf_params},\n",
        "    {**vectorizer_params, **mnb_params}\n",
        "]\n",
        "\n",
        "br_pipeline = Pipeline([('vectorizer', CountVectorizer()),\n",
        "                        ('tfidf', TfidfTransformer()),\n",
        "                        ('clf', BinaryRelevance()),\n",
        "                       ]\n",
        "                      )\n",
        "\n",
        "# Gridsearch settings\n",
        "# scoring = make_scorer(f1_score, average='micro') # possible scorings 'f1_micro' 'f1_macro'\n",
        "# scoring = 'f1_micro'\n",
        "# scoring = make_scorer(hamming_loss)\n",
        "# scoring = 'neg_log_loss'\n",
        "scoring = 'f1_samples'\n",
        "folds = 5\n",
        "njobs = -1\n",
        "\n",
        "br_model = GridSearchCV(br_pipeline, parameters, scoring=scoring, cv=folds, n_jobs=njobs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WJh-8LuXRm_",
        "colab_type": "code",
        "outputId": "39b679eb-1512-4c2e-e254-22c8e94b8435",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        }
      },
      "source": [
        "%%time\n",
        "br_model.fit(X_train,y_train)\n",
        "print(br_model.best_params_, br_model.best_score_)\n",
        "pd.DataFrame(br_model.cv_results_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'clf__classifier': LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='warn', n_jobs=None, penalty='l2',\n",
            "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
            "                   warm_start=False), 'clf__classifier__C': 1.0, 'clf__classifier__class_weight': 'balanced', 'clf__classifier__penalty': 'l2', 'clf__classifier__solver': 'liblinear', 'tfidf__use_idf': True} 0.5135059678386944\n",
            "CPU times: user 18.4 s, sys: 4.69 s, total: 23.1 s\n",
            "Wall time: 5min 45s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLerqSPSXRnB",
        "colab_type": "code",
        "outputId": "19e310b9-a5c7-410b-9752-0f6aa63c93d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_pred_prob = br_model.predict_proba(X_test)\n",
        "t = 0.2 # threshold value\n",
        "y_pred_new = (y_pred_prob >= t).astype(int)\n",
        "score = f1_score(y_test, y_pred_new, average=\"micro\")\n",
        "print(f\"Binary relevance best model's f1-score {score}\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Binary relevance best model's f1-score 0.2394831730769231\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9e4VlQz4i-8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filename = 'best_br_model.joblib'\n",
        "joblib.dump(br_model, filename)\n",
        "files.download(filename)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzEe91NeXRnD",
        "colab_type": "text"
      },
      "source": [
        "### OneVsRest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZbI-B92XRnE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO: \n",
        "# 1. Check if TfidfTransformer use_idf=False is the same as Countvectorizer? or there are other metrics to suppress\n",
        "# 2. Use proper scoring function - ideally, predicting relevant labels should be more important than predicting irrelevant ones\n",
        "# 3. Balanced class labels\n",
        "# 4. Set better param ranges\n",
        "\n",
        "param_range = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
        "# param_range = [1, 2, 3, 4, 5]\n",
        "param_range_lr = [1.0, 0.5, 0.1]\n",
        "\n",
        "# Set params, comment out as see fit\n",
        "\n",
        "vectorizer_params = {\n",
        "    'vectorizer__min_df': np.linspace(0.005, 0.05, 5),\n",
        "    'vectorizer__ngram_range': [(1, 1), (1, 2)], # This shit blows up your memory\n",
        "    'tfidf__norm': ('l1', 'l2'),\n",
        "    'tfidf__use_idf': [True, False],\n",
        "}\n",
        "\n",
        "lr_params = {\n",
        "    'clf__estimator': [LogisticRegression()],\n",
        "        'clf__estimator__penalty': ['l1', 'l2'],\n",
        "        'clf__estimator__C': param_range_lr,\n",
        "        'clf__estimator__solver': ['liblinear'],\n",
        "        'clf__estimator__class_weight': ['balanced'],\n",
        "}\n",
        "\n",
        "svc_params = {\n",
        "    'clf__estimator': [SVC()],\n",
        "        'clf__estimator__kernel': ['linear', 'rbf'],\n",
        "        'clf__estimator__C': param_range, # np.logspace(-1, 2, 10),\n",
        "        'clf__estimator__gamma': ['auto'], # np.logspace(-1, 1, 10)\n",
        "        'clf__estimator__probability': [True],\n",
        "        'clf__estimator__class_weight': ['balanced'],\n",
        "}\n",
        "\n",
        "rf_params = {\n",
        "    'clf__estimator': [RandomForestClassifier()],\n",
        "        'clf__estimator__criterion': ['gini', 'entropy'],\n",
        "        'clf__estimator__min_samples_leaf': param_range,\n",
        "        'clf__estimator__max_depth': param_range,\n",
        "        'clf__estimator__min_samples_split': param_range[1:],\n",
        "        'clf__estimator__n_estimators': [10],\n",
        "        'clf__estimator__class_weight': ['balanced'],\n",
        "}\n",
        "\n",
        "mnb_params = {\n",
        "    'clf__estimator': [MultinomialNB()],\n",
        "        'clf__estimator__alpha': [0.7, 1.0],\n",
        "}\n",
        "\n",
        "## Stack params\n",
        "parameters = [\n",
        "    {**vectorizer_params, **lr_params},\n",
        "    {**vectorizer_params, **svc_params},\n",
        "    {**vectorizer_params, **rf_params},\n",
        "    {**vectorizer_params, **mnb_params}\n",
        "]\n",
        "\n",
        "ovr_pipeline = Pipeline([('vectorizer', CountVectorizer()),\n",
        "                         ('tfidf', TfidfTransformer()),\n",
        "                         ('clf', OneVsRestClassifier(LogisticRegression())),\n",
        "                        ]\n",
        "                       )\n",
        "\n",
        "# Gridsearch settings\n",
        "# scoring = make_scorer(f1_score, average='micro') # possible scorings 'f1_micro' 'f1_macro'\n",
        "scoring = 'f1_micro'\n",
        "# scoring = make_scorer(hamming_loss) # hamming gives equal weighting to both relevant and irrelevant?\n",
        "# maybe use precision somewhere\n",
        "folds = 5\n",
        "njobs = -1\n",
        "\n",
        "ovr_model = GridSearchCV(ovr_pipeline, parameters, scoring=scoring, cv=folds, n_jobs=njobs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJ1yiaAIXRnG",
        "colab_type": "code",
        "outputId": "c533d3ce-549c-49af-fc1d-8b5b53a4cf05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "%%time\n",
        "ovr_model.fit(X_train,y_train)\n",
        "print(ovr_model.best_params_, ovr_model.best_score_)\n",
        "pd.DataFrame(ovr_model.cv_results_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'clf__estimator': MultinomialNB(alpha=0.7, class_prior=None, fit_prior=True), 'clf__estimator__alpha': 0.7, 'tfidf__use_idf': True} 0.15590712409736715\n",
            "CPU times: user 1.52 s, sys: 143 ms, total: 1.66 s\n",
            "Wall time: 14.2 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTGMGAIUXRnI",
        "colab_type": "code",
        "outputId": "f7b53843-840a-4766-8922-2631ea871175",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_pred_prob = ovr_model.predict_proba(X_test)\n",
        "t = 0.1 # threshold value\n",
        "y_pred_new = (y_pred_prob >= t).astype(int)\n",
        "score = f1_score(y_test, y_pred_new, average=\"micro\")\n",
        "print(f\"One vs Rest best model's f1-score {score}\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "One vs Rest best model's f1-score 0.35597592433361996\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9pbF1ED45XMR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filename = 'best_ovr_model.joblib'\n",
        "joblib.dump(ovr_model, filename)\n",
        "files.download(filename)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2etJb4b5XRnK",
        "colab_type": "text"
      },
      "source": [
        "## Gridsearch best model for each tag\n",
        "\n",
        "https://stackoverflow.com/questions/38555650/try-multiple-estimator-in-one-grid-search\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ieiFzS3_XRnL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "param_range = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
        "# param_range = [1, 2, 3, 4, 5]\n",
        "param_range_lr = [1.0, 0.5, 0.1]\n",
        "\n",
        "# Set params, comment out as see fit\n",
        "\n",
        "vectorizer_params = {\n",
        "    'vectorizer__min_df': np.linspace(0.005, 0.05, 5),\n",
        "    'vectorizer__ngram_range': [(1, 1), (1, 2)], # This shit blows up your memory\n",
        "    'tfidf__norm': ('l1', 'l2'),\n",
        "    'tfidf__use_idf': [True, False],\n",
        "}\n",
        "\n",
        "# Add any Binary classification model setting here.\n",
        "# Also add to general parameters to be passed into pipeline below if want to use new model.\n",
        "\n",
        "lr_params = {\n",
        "    'clf': [LogisticRegression()],\n",
        "        'clf__penalty': ['l1', 'l2'],\n",
        "        'clf__C': param_range_lr,\n",
        "        'clf__solver': ['liblinear'],\n",
        "        'clf__class_weight': ['balanced'],\n",
        "}\n",
        "\n",
        "svc_params = {\n",
        "    'clf': [SVC()],\n",
        "        'clf__kernel': ['linear', 'rbf'],\n",
        "        'clf__C': param_range, # np.logspace(-1, 2, 10),\n",
        "        'clf__gamma': ['auto'], # np.logspace(-1, 1, 10)\n",
        "        'clf__probability': [True],\n",
        "        'clf__class_weight': ['balanced'],\n",
        "}\n",
        "\n",
        "rf_params = {\n",
        "    'clf': [RandomForestClassifier()],\n",
        "        'clf__criterion': ['gini', 'entropy'],\n",
        "        'clf__min_samples_leaf': param_range,\n",
        "        'clf__max_depth': param_range,\n",
        "        'clf__min_samples_split': param_range[1:],\n",
        "        'clf__n_estimators': [15],\n",
        "        'clf__class_weight': ['balanced'],\n",
        "}\n",
        "\n",
        "mnb_params = {\n",
        "    'clf': [MultinomialNB()],\n",
        "        'clf__alpha': [0.7, 1.0],\n",
        "}\n",
        "\n",
        "## Stack params\n",
        "parameters = [\n",
        "    {**vectorizer_params, **lr_params},\n",
        "    {**vectorizer_params, **svc_params},\n",
        "    {**vectorizer_params, **rf_params},\n",
        "    {**vectorizer_params, **mnb_params}\n",
        "]\n",
        "\n",
        "per_tag_pipe = Pipeline([('vectorizer', CountVectorizer()), \n",
        "                  ('tfidf', TfidfTransformer()), \n",
        "                  ('clf', LogisticRegression())])\n",
        "\n",
        "scoring = 'f1'\n",
        "# scoring = 'balanced_accuracy'\n",
        "# scoring = 'precision'\n",
        "folds = 10\n",
        "njobs = -1\n",
        "\n",
        "per_tag_model = GridSearchCV(per_tag_pipe, parameters, scoring=scoring, cv=folds, n_jobs=njobs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Y9LC-0JXRnM",
        "colab_type": "code",
        "outputId": "7a28aea6-6ab7-4e7c-db51-f07d77063401",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "tags = [tag for tag in mlb.inverse_transform(np.ones(shape=(1, 26)))[0]]\n",
        "print(tags)\n",
        "tags.index('technology')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['activism', 'art', 'biodiversity', 'brain', 'business', 'children', 'collaboration', 'communication', 'community', 'culture', 'design', 'economics', 'education', 'entertainment', 'environment', 'future', 'global issues', 'history', 'humanity', 'inequality', 'invention', 'life', 'music', 'politics', 'science', 'technology']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAQ8Sv-sXRnP",
        "colab_type": "code",
        "outputId": "4697641d-39d3-46df-c278-07cdba9f4ebf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "for index in range(len(tags)):\n",
        "    print(f\"Processing {tags[index]}\")\n",
        "    per_tag_model.fit(X_train, y_train[:, index])\n",
        "#     display(pd.DataFrame(per_tag_model.cv_results_))\n",
        "    t = 0.2 #threshold value\n",
        "    prediction_prob = per_tag_model.predict_proba(X_test)\n",
        "    prediction = (prediction_prob[:, 1] >= t).astype(int)\n",
        "    # save model or model params somewhere\n",
        "    print(f'tag {index}: {tags[index]} best model {per_tag_model.best_params_}')\n",
        "    print(f'tag {index}: {tags[index]} counts - predicted: {sum(prediction)}, actual: {sum(y_test[:, index])}')\n",
        "    print(f'tag {index}: {tags[index]} test f1-score is {f1_score(y_test[:, index], prediction, average=\"binary\")}')\n",
        "    print(f'tag {index}: {tags[index]} test accuracy is {accuracy_score(y_test[:, index], prediction)}')\n",
        "    filename = f'best_{tags[index]}_model.joblib'\n",
        "    joblib.dump(per_tag_model, filename)\n",
        "    print('--------------------------')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing activism\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
            "  warnings.warn(msg, category=DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "tag 0: activism best model {'clf': RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "                       min_impurity_split=None, min_samples_leaf=1,\n",
            "                       min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "                       n_estimators=15, n_jobs=None, oob_score=False,\n",
            "                       random_state=None, verbose=0, warm_start=False), 'clf__class_weight': 'balanced', 'clf__criterion': 'gini', 'clf__min_samples_split': 2, 'clf__n_estimators': 15, 'tfidf__use_idf': True}\n",
            "tag 0: activism counts - predicted: 59, actual: 38\n",
            "tag 0: activism test f1-score is 0.20618556701030927\n",
            "tag 0: activism test accuracy is 0.8415637860082305\n",
            "--------------------------\n",
            "Processing art\n",
            "tag 1: art best model {'clf': RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "                       criterion='entropy', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "                       min_impurity_split=None, min_samples_leaf=1,\n",
            "                       min_samples_split=5, min_weight_fraction_leaf=0.0,\n",
            "                       n_estimators=15, n_jobs=None, oob_score=False,\n",
            "                       random_state=None, verbose=0, warm_start=False), 'clf__class_weight': 'balanced', 'clf__criterion': 'entropy', 'clf__min_samples_split': 5, 'clf__n_estimators': 15, 'tfidf__use_idf': False}\n",
            "tag 1: art counts - predicted: 110, actual: 52\n",
            "tag 1: art test f1-score is 0.382716049382716\n",
            "tag 1: art test accuracy is 0.7942386831275721\n",
            "--------------------------\n",
            "Processing biodiversity\n",
            "tag 2: biodiversity best model {'clf': RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "                       min_impurity_split=None, min_samples_leaf=1,\n",
            "                       min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "                       n_estimators=15, n_jobs=None, oob_score=False,\n",
            "                       random_state=None, verbose=0, warm_start=False), 'clf__class_weight': 'balanced', 'clf__criterion': 'gini', 'clf__min_samples_split': 2, 'clf__n_estimators': 15, 'tfidf__use_idf': True}\n",
            "tag 2: biodiversity counts - predicted: 95, actual: 44\n",
            "tag 2: biodiversity test f1-score is 0.3741007194244604\n",
            "tag 2: biodiversity test accuracy is 0.8209876543209876\n",
            "--------------------------\n",
            "Processing brain\n",
            "tag 3: brain best model {'clf': RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "                       min_impurity_split=None, min_samples_leaf=1,\n",
            "                       min_samples_split=5, min_weight_fraction_leaf=0.0,\n",
            "                       n_estimators=15, n_jobs=None, oob_score=False,\n",
            "                       random_state=None, verbose=0, warm_start=False), 'clf__class_weight': 'balanced', 'clf__criterion': 'gini', 'clf__min_samples_split': 5, 'clf__n_estimators': 15, 'tfidf__use_idf': False}\n",
            "tag 3: brain counts - predicted: 36, actual: 32\n",
            "tag 3: brain test f1-score is 0.4411764705882353\n",
            "tag 3: brain test accuracy is 0.9218106995884774\n",
            "--------------------------\n",
            "Processing business\n",
            "tag 4: business best model {'clf': RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "                       min_impurity_split=None, min_samples_leaf=1,\n",
            "                       min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "                       n_estimators=15, n_jobs=None, oob_score=False,\n",
            "                       random_state=None, verbose=0, warm_start=False), 'clf__class_weight': 'balanced', 'clf__criterion': 'gini', 'clf__min_samples_split': 2, 'clf__n_estimators': 15, 'tfidf__use_idf': True}\n",
            "tag 4: business counts - predicted: 197, actual: 66\n",
            "tag 4: business test f1-score is 0.3726235741444867\n",
            "tag 4: business test accuracy is 0.6604938271604939\n",
            "--------------------------\n",
            "Processing children\n",
            "tag 5: children best model {'clf': RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "                       criterion='entropy', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "                       min_impurity_split=None, min_samples_leaf=1,\n",
            "                       min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "                       n_estimators=15, n_jobs=None, oob_score=False,\n",
            "                       random_state=None, verbose=0, warm_start=False), 'clf__class_weight': 'balanced', 'clf__criterion': 'entropy', 'clf__min_samples_split': 2, 'clf__n_estimators': 15, 'tfidf__use_idf': False}\n",
            "tag 5: children counts - predicted: 20, actual: 30\n",
            "tag 5: children test f1-score is 0.4\n",
            "tag 5: children test accuracy is 0.9382716049382716\n",
            "--------------------------\n",
            "Processing collaboration\n",
            "tag 6: collaboration best model {'clf': RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "                       min_impurity_split=None, min_samples_leaf=1,\n",
            "                       min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "                       n_estimators=15, n_jobs=None, oob_score=False,\n",
            "                       random_state=None, verbose=0, warm_start=False), 'clf__class_weight': 'balanced', 'clf__criterion': 'gini', 'clf__min_samples_split': 2, 'clf__n_estimators': 15, 'tfidf__use_idf': True}\n",
            "tag 6: collaboration counts - predicted: 64, actual: 33\n",
            "tag 6: collaboration test f1-score is 0.18556701030927833\n",
            "tag 6: collaboration test accuracy is 0.8374485596707819\n",
            "--------------------------\n",
            "Processing communication\n",
            "tag 7: communication best model {'clf': RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "                       min_impurity_split=None, min_samples_leaf=1,\n",
            "                       min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "                       n_estimators=15, n_jobs=None, oob_score=False,\n",
            "                       random_state=None, verbose=0, warm_start=False), 'clf__class_weight': 'balanced', 'clf__criterion': 'gini', 'clf__min_samples_split': 2, 'clf__n_estimators': 15, 'tfidf__use_idf': True}\n",
            "tag 7: communication counts - predicted: 82, actual: 42\n",
            "tag 7: communication test f1-score is 0.2096774193548387\n",
            "tag 7: communication test accuracy is 0.7983539094650206\n",
            "--------------------------\n",
            "Processing community\n",
            "tag 8: community best model {'clf': RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "                       min_impurity_split=None, min_samples_leaf=1,\n",
            "                       min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "                       n_estimators=15, n_jobs=None, oob_score=False,\n",
            "                       random_state=None, verbose=0, warm_start=False), 'clf__class_weight': 'balanced', 'clf__criterion': 'gini', 'clf__min_samples_split': 2, 'clf__n_estimators': 15, 'tfidf__use_idf': True}\n",
            "tag 8: community counts - predicted: 55, actual: 31\n",
            "tag 8: community test f1-score is 0.16279069767441862\n",
            "tag 8: community test accuracy is 0.8518518518518519\n",
            "--------------------------\n",
            "Processing culture\n",
            "tag 9: culture best model {'clf': RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "                       min_impurity_split=None, min_samples_leaf=1,\n",
            "                       min_samples_split=5, min_weight_fraction_leaf=0.0,\n",
            "                       n_estimators=15, n_jobs=None, oob_score=False,\n",
            "                       random_state=None, verbose=0, warm_start=False), 'clf__class_weight': 'balanced', 'clf__criterion': 'gini', 'clf__min_samples_split': 5, 'clf__n_estimators': 15, 'tfidf__use_idf': True}\n",
            "tag 9: culture counts - predicted: 479, actual: 236\n",
            "tag 9: culture test f1-score is 0.6489510489510489\n",
            "tag 9: culture test accuracy is 0.4835390946502058\n",
            "--------------------------\n",
            "Processing design\n",
            "tag 10: design best model {'clf': RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "                       criterion='entropy', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "                       min_impurity_split=None, min_samples_leaf=1,\n",
            "                       min_samples_split=4, min_weight_fraction_leaf=0.0,\n",
            "                       n_estimators=15, n_jobs=None, oob_score=False,\n",
            "                       random_state=None, verbose=0, warm_start=False), 'clf__class_weight': 'balanced', 'clf__criterion': 'entropy', 'clf__min_samples_split': 4, 'clf__n_estimators': 15, 'tfidf__use_idf': False}\n",
            "tag 10: design counts - predicted: 229, actual: 80\n",
            "tag 10: design test f1-score is 0.38834951456310685\n",
            "tag 10: design test accuracy is 0.6111111111111112\n",
            "--------------------------\n",
            "Processing economics\n",
            "tag 11: economics best model {'clf': RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "                       min_impurity_split=None, min_samples_leaf=1,\n",
            "                       min_samples_split=4, min_weight_fraction_leaf=0.0,\n",
            "                       n_estimators=15, n_jobs=None, oob_score=False,\n",
            "                       random_state=None, verbose=0, warm_start=False), 'clf__class_weight': 'balanced', 'clf__criterion': 'gini', 'clf__min_samples_split': 4, 'clf__n_estimators': 15, 'tfidf__use_idf': True}\n",
            "tag 11: economics counts - predicted: 60, actual: 31\n",
            "tag 11: economics test f1-score is 0.32967032967032966\n",
            "tag 11: economics test accuracy is 0.8744855967078189\n",
            "--------------------------\n",
            "Processing education\n",
            "tag 12: education best model {'clf': RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "                       min_impurity_split=None, min_samples_leaf=1,\n",
            "                       min_samples_split=5, min_weight_fraction_leaf=0.0,\n",
            "                       n_estimators=15, n_jobs=None, oob_score=False,\n",
            "                       random_state=None, verbose=0, warm_start=False), 'clf__class_weight': 'balanced', 'clf__criterion': 'gini', 'clf__min_samples_split': 5, 'clf__n_estimators': 15, 'tfidf__use_idf': True}\n",
            "tag 12: education counts - predicted: 90, actual: 42\n",
            "tag 12: education test f1-score is 0.3181818181818182\n",
            "tag 12: education test accuracy is 0.8148148148148148\n",
            "--------------------------\n",
            "Processing entertainment\n",
            "tag 13: entertainment best model {'clf': RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "                       min_impurity_split=None, min_samples_leaf=1,\n",
            "                       min_samples_split=4, min_weight_fraction_leaf=0.0,\n",
            "                       n_estimators=15, n_jobs=None, oob_score=False,\n",
            "                       random_state=None, verbose=0, warm_start=False), 'clf__class_weight': 'balanced', 'clf__criterion': 'gini', 'clf__min_samples_split': 4, 'clf__n_estimators': 15, 'tfidf__use_idf': True}\n",
            "tag 13: entertainment counts - predicted: 112, actual: 58\n",
            "tag 13: entertainment test f1-score is 0.32941176470588235\n",
            "tag 13: entertainment test accuracy is 0.7654320987654321\n",
            "--------------------------\n",
            "Processing environment\n",
            "tag 14: environment best model {'clf': RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "                       criterion='entropy', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "                       min_impurity_split=None, min_samples_leaf=1,\n",
            "                       min_samples_split=3, min_weight_fraction_leaf=0.0,\n",
            "                       n_estimators=15, n_jobs=None, oob_score=False,\n",
            "                       random_state=None, verbose=0, warm_start=False), 'clf__class_weight': 'balanced', 'clf__criterion': 'entropy', 'clf__min_samples_split': 3, 'clf__n_estimators': 15, 'tfidf__use_idf': False}\n",
            "tag 14: environment counts - predicted: 46, actual: 38\n",
            "tag 14: environment test f1-score is 0.3333333333333333\n",
            "tag 14: environment test accuracy is 0.8847736625514403\n",
            "--------------------------\n",
            "Processing future\n",
            "tag 15: future best model {'clf': RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "                       min_impurity_split=None, min_samples_leaf=1,\n",
            "                       min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "                       n_estimators=15, n_jobs=None, oob_score=False,\n",
            "                       random_state=None, verbose=0, warm_start=False), 'clf__class_weight': 'balanced', 'clf__criterion': 'gini', 'clf__min_samples_split': 2, 'clf__n_estimators': 15, 'tfidf__use_idf': True}\n",
            "tag 15: future counts - predicted: 117, actual: 42\n",
            "tag 15: future test f1-score is 0.16352201257861634\n",
            "tag 15: future test accuracy is 0.7263374485596708\n",
            "--------------------------\n",
            "Processing global issues\n",
            "tag 16: global issues best model {'clf': RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "                       min_impurity_split=None, min_samples_leaf=1,\n",
            "                       min_samples_split=5, min_weight_fraction_leaf=0.0,\n",
            "                       n_estimators=15, n_jobs=None, oob_score=False,\n",
            "                       random_state=None, verbose=0, warm_start=False), 'clf__class_weight': 'balanced', 'clf__criterion': 'gini', 'clf__min_samples_split': 5, 'clf__n_estimators': 15, 'tfidf__use_idf': False}\n",
            "tag 16: global issues counts - predicted: 372, actual: 136\n",
            "tag 16: global issues test f1-score is 0.5\n",
            "tag 16: global issues test accuracy is 0.4773662551440329\n",
            "--------------------------\n",
            "Processing history\n",
            "tag 17: history best model {'clf': RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "                       min_impurity_split=None, min_samples_leaf=1,\n",
            "                       min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "                       n_estimators=15, n_jobs=None, oob_score=False,\n",
            "                       random_state=None, verbose=0, warm_start=False), 'clf__class_weight': 'balanced', 'clf__criterion': 'gini', 'clf__min_samples_split': 2, 'clf__n_estimators': 15, 'tfidf__use_idf': True}\n",
            "tag 17: history counts - predicted: 43, actual: 34\n",
            "tag 17: history test f1-score is 0.2077922077922078\n",
            "tag 17: history test accuracy is 0.8744855967078189\n",
            "--------------------------\n",
            "Processing humanity\n",
            "tag 18: humanity best model {'clf': RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "                       min_impurity_split=None, min_samples_leaf=1,\n",
            "                       min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "                       n_estimators=15, n_jobs=None, oob_score=False,\n",
            "                       random_state=None, verbose=0, warm_start=False), 'clf__class_weight': 'balanced', 'clf__criterion': 'gini', 'clf__min_samples_split': 2, 'clf__n_estimators': 15, 'tfidf__use_idf': True}\n",
            "tag 18: humanity counts - predicted: 38, actual: 36\n",
            "tag 18: humanity test f1-score is 0.13513513513513511\n",
            "tag 18: humanity test accuracy is 0.8683127572016461\n",
            "--------------------------\n",
            "Processing inequality\n",
            "tag 19: inequality best model {'clf': RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "                       criterion='entropy', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "                       min_impurity_split=None, min_samples_leaf=1,\n",
            "                       min_samples_split=4, min_weight_fraction_leaf=0.0,\n",
            "                       n_estimators=15, n_jobs=None, oob_score=False,\n",
            "                       random_state=None, verbose=0, warm_start=False), 'clf__class_weight': 'balanced', 'clf__criterion': 'entropy', 'clf__min_samples_split': 4, 'clf__n_estimators': 15, 'tfidf__use_idf': False}\n",
            "tag 19: inequality counts - predicted: 21, actual: 36\n",
            "tag 19: inequality test f1-score is 0.2105263157894737\n",
            "tag 19: inequality test accuracy is 0.9074074074074074\n",
            "--------------------------\n",
            "Processing invention\n",
            "tag 20: invention best model {'clf': RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "                       min_impurity_split=None, min_samples_leaf=1,\n",
            "                       min_samples_split=5, min_weight_fraction_leaf=0.0,\n",
            "                       n_estimators=15, n_jobs=None, oob_score=False,\n",
            "                       random_state=None, verbose=0, warm_start=False), 'clf__class_weight': 'balanced', 'clf__criterion': 'gini', 'clf__min_samples_split': 5, 'clf__n_estimators': 15, 'tfidf__use_idf': True}\n",
            "tag 20: invention counts - predicted: 38, actual: 27\n",
            "tag 20: invention test f1-score is 0.30769230769230765\n",
            "tag 20: invention test accuracy is 0.9074074074074074\n",
            "--------------------------\n",
            "Processing life\n",
            "tag 21: life best model {'clf': RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "                       min_impurity_split=None, min_samples_leaf=1,\n",
            "                       min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "                       n_estimators=15, n_jobs=None, oob_score=False,\n",
            "                       random_state=None, verbose=0, warm_start=False), 'clf__class_weight': 'balanced', 'clf__criterion': 'gini', 'clf__min_samples_split': 2, 'clf__n_estimators': 15, 'tfidf__use_idf': True}\n",
            "tag 21: life counts - predicted: 61, actual: 37\n",
            "tag 21: life test f1-score is 0.10204081632653063\n",
            "tag 21: life test accuracy is 0.8189300411522634\n",
            "--------------------------\n",
            "Processing music\n",
            "tag 22: music best model {'clf': RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "                       criterion='entropy', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "                       min_impurity_split=None, min_samples_leaf=1,\n",
            "                       min_samples_split=5, min_weight_fraction_leaf=0.0,\n",
            "                       n_estimators=15, n_jobs=None, oob_score=False,\n",
            "                       random_state=None, verbose=0, warm_start=False), 'clf__class_weight': 'balanced', 'clf__criterion': 'entropy', 'clf__min_samples_split': 5, 'clf__n_estimators': 15, 'tfidf__use_idf': True}\n",
            "tag 22: music counts - predicted: 29, actual: 25\n",
            "tag 22: music test f1-score is 0.6666666666666666\n",
            "tag 22: music test accuracy is 0.9629629629629629\n",
            "--------------------------\n",
            "Processing politics\n",
            "tag 23: politics best model {'clf': RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "                       min_impurity_split=None, min_samples_leaf=1,\n",
            "                       min_samples_split=4, min_weight_fraction_leaf=0.0,\n",
            "                       n_estimators=15, n_jobs=None, oob_score=False,\n",
            "                       random_state=None, verbose=0, warm_start=False), 'clf__class_weight': 'balanced', 'clf__criterion': 'gini', 'clf__min_samples_split': 4, 'clf__n_estimators': 15, 'tfidf__use_idf': False}\n",
            "tag 23: politics counts - predicted: 78, actual: 37\n",
            "tag 23: politics test f1-score is 0.4\n",
            "tag 23: politics test accuracy is 0.8580246913580247\n",
            "--------------------------\n",
            "Processing science\n",
            "tag 24: science best model {'clf': RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "                       criterion='entropy', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "                       min_impurity_split=None, min_samples_leaf=1,\n",
            "                       min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "                       n_estimators=15, n_jobs=None, oob_score=False,\n",
            "                       random_state=None, verbose=0, warm_start=False), 'clf__class_weight': 'balanced', 'clf__criterion': 'entropy', 'clf__min_samples_split': 2, 'clf__n_estimators': 15, 'tfidf__use_idf': False}\n",
            "tag 24: science counts - predicted: 417, actual: 176\n",
            "tag 24: science test f1-score is 0.5733558178752108\n",
            "tag 24: science test accuracy is 0.4794238683127572\n",
            "--------------------------\n",
            "Processing technology\n",
            "tag 25: technology best model {'clf': RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "                       min_impurity_split=None, min_samples_leaf=1,\n",
            "                       min_samples_split=5, min_weight_fraction_leaf=0.0,\n",
            "                       n_estimators=15, n_jobs=None, oob_score=False,\n",
            "                       random_state=None, verbose=0, warm_start=False), 'clf__class_weight': 'balanced', 'clf__criterion': 'gini', 'clf__min_samples_split': 5, 'clf__n_estimators': 15, 'tfidf__use_idf': True}\n",
            "tag 25: technology counts - predicted: 408, actual: 157\n",
            "tag 25: technology test f1-score is 0.5309734513274337\n",
            "tag 25: technology test accuracy is 0.4547325102880658\n",
            "--------------------------\n",
            "CPU times: user 1min 54s, sys: 9.19 s, total: 2min 4s\n",
            "Wall time: 21min 19s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjgcdiLgy783",
        "colab_type": "code",
        "outputId": "4274d168-e18b-44ff-d323-50844a2427ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "rf_models = glob.glob(\"*.joblib\")\n",
        "print(rf_models)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['best_rf_economics.joblib', 'best_rf_art.joblib', 'best_rf_life.joblib', 'best_rf_biodiversity.joblib', 'best_rf_future.joblib', 'best_rf_environment.joblib', 'best_rf_activism.joblib', 'best_rf_education.joblib', 'best_rf_culture.joblib', 'best_rf_business.joblib', 'best_rf_collaboration.joblib', 'best_rf_music.joblib', 'best_rf_global issues.joblib', 'best_rf_science.joblib', 'best_rf_community.joblib', 'best_rf_brain.joblib', 'best_rf_inequality.joblib', 'best_rf_invention.joblib', 'best_rf_children.joblib', 'best_rf_humanity.joblib', 'best_rf_entertainment.joblib', 'best_rf_politics.joblib', 'best_rf_communication.joblib', 'best_rf_design.joblib', 'best_rf_technology.joblib', 'best_rf_history.joblib']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "806R0-HpXRnQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for index, file in enumerate(rf_models):\n",
        "    print(f'Downloading model {index + 1}: {file} ...')\n",
        "    files.download(file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPfOkwksp5dn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z54wz2OUp66m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}