{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Link: https://www.analyticsvidhya.com/blog/2018/04/a-comprehensive-guide-to-understand-and-implement-text-classification-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-62-c72ff1397f30>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdecomposition\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensemble\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[1;31m#textblob, string#,# xgboost, numpy, textblob, string\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msequence\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn import decomposition, ensemble\n",
    "\n",
    "import pandas,numpy, string #, xgboost #textblob, string#,# xgboost, numpy, textblob, string\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras import layers, models, optimizers\n",
    "\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"../../data/raw/\"\n",
    "INPUT_FILE_NAME = 'cleaned_squashed.parquet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker</th>\n",
       "      <th>headline</th>\n",
       "      <th>description</th>\n",
       "      <th>duration</th>\n",
       "      <th>tags</th>\n",
       "      <th>transcript</th>\n",
       "      <th>WC</th>\n",
       "      <th>clean_transcript</th>\n",
       "      <th>clean_transcript_string</th>\n",
       "      <th>squash_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Al Gore</td>\n",
       "      <td>Averting the climate crisis</td>\n",
       "      <td>With the same humor and humanity he exuded in ...</td>\n",
       "      <td>0:16:17</td>\n",
       "      <td>cars,alternative energy,culture,politics,scien...</td>\n",
       "      <td>0:14\\r\\r\\rThank you so much, Chris.\\rAnd it's ...</td>\n",
       "      <td>2281.0</td>\n",
       "      <td>[thank, chris, truly, great, honor, opportunit...</td>\n",
       "      <td>thank chris truly great honor opportunity come...</td>\n",
       "      <td>alternative energy,culture,politics,science,cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Amy Smith</td>\n",
       "      <td>Simple designs to save a life</td>\n",
       "      <td>Fumes from indoor cooking fires kill more than...</td>\n",
       "      <td>0:15:06</td>\n",
       "      <td>MacArthur grant,simplicity,industrial design,a...</td>\n",
       "      <td>0:11\\r\\r\\rIn terms of invention,\\rI'd like to ...</td>\n",
       "      <td>2687.0</td>\n",
       "      <td>[term, invention, like, tell, tale, favorite, ...</td>\n",
       "      <td>term invention like tell tale favorite project...</td>\n",
       "      <td>industrial design,alternative energy,invention...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ashraf Ghani</td>\n",
       "      <td>How to rebuild a broken state</td>\n",
       "      <td>Ashraf Ghani's passionate and powerful 10-minu...</td>\n",
       "      <td>0:18:45</td>\n",
       "      <td>corruption,poverty,economics,investment,milita...</td>\n",
       "      <td>0:12\\r\\r\\rA public, Dewey long ago observed,\\r...</td>\n",
       "      <td>2506.0</td>\n",
       "      <td>[public, dewey, long, ago, observe, constitute...</td>\n",
       "      <td>public dewey long ago observe constitute discu...</td>\n",
       "      <td>poverty,economics,investment,culture,politics,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Burt Rutan</td>\n",
       "      <td>The real future of space exploration</td>\n",
       "      <td>In this passionate talk, legendary spacecraft ...</td>\n",
       "      <td>0:19:37</td>\n",
       "      <td>aircraft,flight,industrial design,NASA,rocket ...</td>\n",
       "      <td>0:11\\r\\r\\rI want to start off by saying, Houst...</td>\n",
       "      <td>3092.0</td>\n",
       "      <td>[want, start, say, houston, problem, enter, se...</td>\n",
       "      <td>want start say houston problem enter second ge...</td>\n",
       "      <td>industrial design,invention,engineering,entrep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chris Bangle</td>\n",
       "      <td>Great cars are great art</td>\n",
       "      <td>American designer Chris Bangle explains his ph...</td>\n",
       "      <td>0:20:04</td>\n",
       "      <td>cars,industrial design,transportation,inventio...</td>\n",
       "      <td>0:12\\r\\r\\rWhat I want to talk about is, as bac...</td>\n",
       "      <td>3781.0</td>\n",
       "      <td>[want, talk, background, idea, car, art, actua...</td>\n",
       "      <td>want talk background idea car art actually mea...</td>\n",
       "      <td>industrial design,transportation,invention,des...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        speaker                              headline  \\\n",
       "0       Al Gore           Averting the climate crisis   \n",
       "1     Amy Smith         Simple designs to save a life   \n",
       "2  Ashraf Ghani         How to rebuild a broken state   \n",
       "3    Burt Rutan  The real future of space exploration   \n",
       "4  Chris Bangle              Great cars are great art   \n",
       "\n",
       "                                         description duration  \\\n",
       "0  With the same humor and humanity he exuded in ...  0:16:17   \n",
       "1  Fumes from indoor cooking fires kill more than...  0:15:06   \n",
       "2  Ashraf Ghani's passionate and powerful 10-minu...  0:18:45   \n",
       "3  In this passionate talk, legendary spacecraft ...  0:19:37   \n",
       "4  American designer Chris Bangle explains his ph...  0:20:04   \n",
       "\n",
       "                                                tags  \\\n",
       "0  cars,alternative energy,culture,politics,scien...   \n",
       "1  MacArthur grant,simplicity,industrial design,a...   \n",
       "2  corruption,poverty,economics,investment,milita...   \n",
       "3  aircraft,flight,industrial design,NASA,rocket ...   \n",
       "4  cars,industrial design,transportation,inventio...   \n",
       "\n",
       "                                          transcript      WC  \\\n",
       "0  0:14\\r\\r\\rThank you so much, Chris.\\rAnd it's ...  2281.0   \n",
       "1  0:11\\r\\r\\rIn terms of invention,\\rI'd like to ...  2687.0   \n",
       "2  0:12\\r\\r\\rA public, Dewey long ago observed,\\r...  2506.0   \n",
       "3  0:11\\r\\r\\rI want to start off by saying, Houst...  3092.0   \n",
       "4  0:12\\r\\r\\rWhat I want to talk about is, as bac...  3781.0   \n",
       "\n",
       "                                    clean_transcript  \\\n",
       "0  [thank, chris, truly, great, honor, opportunit...   \n",
       "1  [term, invention, like, tell, tale, favorite, ...   \n",
       "2  [public, dewey, long, ago, observe, constitute...   \n",
       "3  [want, start, say, houston, problem, enter, se...   \n",
       "4  [want, talk, background, idea, car, art, actua...   \n",
       "\n",
       "                             clean_transcript_string  \\\n",
       "0  thank chris truly great honor opportunity come...   \n",
       "1  term invention like tell tale favorite project...   \n",
       "2  public dewey long ago observe constitute discu...   \n",
       "3  want start say houston problem enter second ge...   \n",
       "4  want talk background idea car art actually mea...   \n",
       "\n",
       "                                         squash_tags  \n",
       "0  alternative energy,culture,politics,science,cl...  \n",
       "1  industrial design,alternative energy,invention...  \n",
       "2  poverty,economics,investment,culture,politics,...  \n",
       "3  industrial design,invention,engineering,entrep...  \n",
       "4  industrial design,transportation,invention,des...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet(DATA_DIR + INPUT_FILE_NAME)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_full_dataframe(x):\n",
    "    pd.set_option('display.max_rows', len(x))\n",
    "    print(x)\n",
    "    pd.reset_option('display.max_rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               tags  counts  no_count     ratio  overall_ratio\n",
      "0        technology     695      1691  0.410999       0.291282\n",
      "1           science     522      1864  0.280043       0.218776\n",
      "2     global issues     483      1903  0.253810       0.202431\n",
      "3           culture     470      1916  0.245303       0.196982\n",
      "4            design     400      1986  0.201410       0.167645\n",
      "..              ...     ...       ...       ...            ...\n",
      "413             gay       1      2385  0.000419       0.000419\n",
      "414      blockchain       1      2385  0.000419       0.000419\n",
      "415  ted en español       1      2385  0.000419       0.000419\n",
      "416        asteroid       1      2385  0.000419       0.000419\n",
      "417                       1      2385  0.000419       0.000419\n",
      "\n",
      "[418 rows x 5 columns]\n",
      "            squash_tags  counts  no_count     ratio  overall_ratio\n",
      "0            technology     695      1691  0.410999       0.291282\n",
      "1               science     522      1864  0.280043       0.218776\n",
      "2         global issues     483      1903  0.253810       0.202431\n",
      "3               culture     470      1916  0.245303       0.196982\n",
      "4                design     400      1986  0.201410       0.167645\n",
      "5                  tedx     398      1988  0.200201       0.166806\n",
      "6              business     329      2057  0.159942       0.137888\n",
      "7         entertainment     285      2101  0.135650       0.119447\n",
      "8                health     226      2160  0.104630       0.094719\n",
      "9            innovation     212      2174  0.097516       0.088852\n",
      "10            education     206      2180  0.094495       0.086337\n",
      "11                  art     204      2182  0.093492       0.085499\n",
      "12              society     202      2184  0.092491       0.084661\n",
      "13        social change     198      2188  0.090494       0.082984\n",
      "14        communication     185      2201  0.084053       0.077536\n",
      "15             politics     183      2203  0.083069       0.076697\n",
      "16               future     181      2205  0.082086       0.075859\n",
      "17              biology     174      2212  0.078662       0.072925\n",
      "18           creativity     174      2212  0.078662       0.072925\n",
      "19             humanity     164      2222  0.073807       0.068734\n",
      "20        collaboration     163      2223  0.073324       0.068315\n",
      "21          environment     155      2231  0.069476       0.064962\n",
      "22             medicine     154      2232  0.068996       0.064543\n",
      "23            economics     154      2232  0.068996       0.064543\n",
      "24                brain     148      2238  0.066130       0.062028\n",
      "25             activism     147      2239  0.065654       0.061609\n",
      "26            invention     136      2250  0.060444       0.056999\n",
      "27            community     136      2250  0.060444       0.056999\n",
      "28              history     135      2251  0.059973       0.056580\n",
      "29             children     135      2251  0.059973       0.056580\n",
      "30          ted fellows     132      2254  0.058563       0.055323\n",
      "31          health care     130      2256  0.057624       0.054484\n",
      "32                music     119      2267  0.052492       0.049874\n",
      "33                women     115      2271  0.050638       0.048198\n",
      "34               cities     113      2273  0.049714       0.047360\n",
      "35         storytelling     112      2274  0.049252       0.046940\n",
      "36              animals     108      2278  0.047410       0.045264\n",
      "37                  war     108      2278  0.047410       0.045264\n",
      "38          engineering     107      2279  0.046950       0.044845\n",
      "39           leadership     107      2279  0.046950       0.044845\n",
      "40             identity     106      2280  0.046491       0.044426\n",
      "41               nature     106      2280  0.046491       0.044426\n",
      "42            computers     105      2281  0.046032       0.044007\n",
      "43           psychology     104      2282  0.045574       0.043588\n",
      "44                humor      99      2287  0.043288       0.041492\n",
      "45                 life      99      2287  0.043288       0.041492\n",
      "46          performance      98      2288  0.042832       0.041073\n",
      "47          exploration      96      2290  0.041921       0.040235\n",
      "48               africa      94      2292  0.041012       0.039396\n",
      "49                 data      89      2297  0.038746       0.037301\n",
      "50          photography      88      2298  0.038294       0.036882\n",
      "51           inequality      86      2300  0.037391       0.036044\n",
      "52     medical research      86      2300  0.037391       0.036044\n",
      "53      personal growth      85      2301  0.036940       0.035624\n",
      "54         neuroscience      84      2302  0.036490       0.035205\n",
      "55           government      83      2303  0.036040       0.034786\n",
      "56       climate change      81      2305  0.035141       0.033948\n",
      "57       visualizations      80      2306  0.034692       0.033529\n",
      "58             internet      77      2309  0.033348       0.032272\n",
      "59         architecture      76      2310  0.032900       0.031852\n",
      "60       sustainability      74      2312  0.032007       0.031014\n",
      "61               oceans      73      2313  0.031561       0.030595\n",
      "62              disease      72      2314  0.031115       0.030176\n",
      "63                green      71      2315  0.030670       0.029757\n",
      "64            happiness      71      2315  0.030670       0.029757\n",
      "65              biotech      70      2316  0.030225       0.029338\n",
      "66            potential      70      2316  0.030225       0.029338\n",
      "67                 work      69      2317  0.029780       0.028919\n",
      "68              physics      67      2319  0.028892       0.028080\n",
      "69                media      66      2320  0.028448       0.027661\n",
      "70                 film      66      2320  0.028448       0.027661\n",
      "71             violence      65      2321  0.028005       0.027242\n",
      "72            evolution      64      2322  0.027562       0.026823\n",
      "73                 mind      64      2322  0.027562       0.026823\n",
      "74         big problems      63      2323  0.027120       0.026404\n",
      "75              writing      62      2324  0.026678       0.025985\n",
      "76           motivation      61      2325  0.026237       0.025566\n",
      "77           philosophy      60      2326  0.025795       0.025147\n",
      "78         biodiversity      60      2326  0.025795       0.025147\n",
      "79           live music      60      2326  0.025795       0.025147\n",
      "80         entrepreneur      60      2326  0.025795       0.025147\n",
      "81             genetics      59      2327  0.025355       0.024728\n",
      "82        mental health      59      2327  0.025355       0.024728\n",
      "83   global development      58      2328  0.024914       0.024308\n",
      "84             language      58      2328  0.024914       0.024308\n",
      "85               beauty      56      2330  0.024034       0.023470\n",
      "86                space      56      2330  0.024034       0.023470\n",
      "87               robots      55      2331  0.023595       0.023051\n",
      "88                 food      55      2331  0.023595       0.023051\n",
      "89    cognitive science      55      2331  0.023595       0.023051\n",
      "90                 math      53      2333  0.022718       0.022213\n",
      "91              ecology      52      2334  0.022279       0.021794\n",
      "92             religion      52      2334  0.022279       0.021794\n",
      "93      ted brain trust      52      2334  0.022279       0.021794\n",
      "94                peace      52      2334  0.022279       0.021794\n",
      "95                 demo      52      2334  0.022279       0.021794\n",
      "96               energy      51      2335  0.021842       0.021375\n",
      "97              poverty      51      2335  0.021842       0.021375\n",
      "98              illness      50      2336  0.021404       0.020956\n",
      "99               policy      49      2337  0.020967       0.020536\n",
      "100              family      49      2337  0.020967       0.020536\n",
      "101           parenting      49      2337  0.020967       0.020536\n",
      "102           adventure      48      2338  0.020530       0.020117\n",
      "103       public health      47      2339  0.020094       0.019698\n",
      "104                self      47      2339  0.020094       0.019698\n",
      "105              poetry      47      2339  0.020094       0.019698\n",
      "106            universe      47      2339  0.020094       0.019698\n",
      "107      product design      46      2340  0.019658       0.019279\n",
      "108       relationships      46      2340  0.019658       0.019279\n",
      "109           democracy      45      2341  0.019223       0.018860\n",
      "110              cancer      45      2341  0.019223       0.018860\n",
      "111              comedy      45      2341  0.019223       0.018860\n",
      "112          journalism      45      2341  0.019223       0.018860\n",
      "113        intelligence      45      2341  0.019223       0.018860\n",
      "114        social media      45      2341  0.019223       0.018860\n",
      "115      infrastructure      45      2341  0.019223       0.018860\n",
      "116           astronomy      44      2342  0.018787       0.018441\n",
      "117                 law      43      2343  0.018353       0.018022\n",
      "118               crime      43      2343  0.018353       0.018022\n",
      "119            software      43      2343  0.018353       0.018022\n",
      "120            teaching      42      2344  0.017918       0.017603\n",
      "121              choice      42      2344  0.017918       0.017603\n",
      "122               death      42      2344  0.017918       0.017603\n",
      "123                 dna      41      2345  0.017484       0.017184\n",
      "124                 web      41      2345  0.017484       0.017184\n",
      "125               aging      41      2345  0.017484       0.017184\n",
      "126     science and art      39      2347  0.016617       0.016345\n",
      "127                love      38      2348  0.016184       0.015926\n",
      "128           materials      37      2349  0.015751       0.015507\n",
      "129            security      37      2349  0.015751       0.015507\n",
      "130               water      37      2349  0.015751       0.015507\n",
      "131               youth      36      2350  0.015319       0.015088\n",
      "132                race      36      2350  0.015319       0.015088\n",
      "133           terrorism      35      2351  0.014887       0.014669\n",
      "134           chemistry      35      2351  0.014887       0.014669\n",
      "135      transportation      35      2351  0.014887       0.014669\n",
      "136  alternative energy      35      2351  0.014887       0.014669\n",
      "137                  ai      35      2351  0.014887       0.014669\n",
      "138                 sex      35      2351  0.014887       0.014669\n",
      "139        goal-setting      34      2352  0.014456       0.014250\n",
      "140           pollution      34      2352  0.014456       0.014250\n",
      "141         agriculture      34      2352  0.014456       0.014250\n",
      "142               books      34      2352  0.014456       0.014250\n",
      "143     decision-making      33      2353  0.014025       0.013831\n",
      "144         open-source      33      2353  0.014025       0.013831\n",
      "145          compassion      33      2353  0.014025       0.013831\n",
      "146             insects      33      2353  0.014025       0.013831\n",
      "147         middle east      32      2354  0.013594       0.013412\n",
      "148        philanthropy      32      2354  0.013594       0.013412\n",
      "149   molecular biology      32      2354  0.013594       0.013412\n",
      "150              sports      31      2355  0.013163       0.012992\n",
      "151           algorithm      30      2356  0.012733       0.012573\n",
      "152          investment      29      2357  0.012304       0.012154\n",
      "153            feminism      29      2357  0.012304       0.012154\n",
      "154              gaming      29      2357  0.012304       0.012154\n",
      "155          disability      29      2357  0.012304       0.012154\n",
      "156                fear      28      2358  0.011874       0.011735\n",
      "157           curiosity      28      2358  0.011874       0.011735\n",
      "158        microbiology      28      2358  0.011874       0.011735\n",
      "159               money      28      2358  0.011874       0.011735\n",
      "160          statistics      28      2358  0.011874       0.011735\n",
      "161              plants      28      2358  0.011874       0.011735\n",
      "162             success      28      2358  0.011874       0.011735\n",
      "163   women in business      27      2359  0.011446       0.011316\n",
      "164                fish      27      2359  0.011446       0.011316\n",
      "165           ted prize      27      2359  0.011446       0.011316\n",
      "166        biomechanics      27      2359  0.011446       0.011316\n",
      "167              gender      27      2359  0.011446       0.011316\n",
      "168    interface design      27      2359  0.011446       0.011316\n",
      "169   industrial design      27      2359  0.011446       0.011316\n",
      "170      urban planning      26      2360  0.011017       0.010897\n",
      "171             empathy      26      2360  0.011017       0.010897\n",
      "172       united states      25      2361  0.010589       0.010478\n",
      "173                code      25      2361  0.010589       0.010478\n",
      "174                asia      25      2361  0.010589       0.010478\n",
      "175          depression      25      2361  0.010589       0.010478\n",
      "176             planets      24      2362  0.010161       0.010059\n",
      "177            bacteria      24      2362  0.010161       0.010059\n",
      "178               faith      24      2362  0.010161       0.010059\n"
     ]
    }
   ],
   "source": [
    "def compute_tag_ratio(target_column, df=df):\n",
    "    tags = df[target_column].str.replace(', ',',').str.lower().str.strip()\n",
    "    split_tags = tags.str.split(',')\n",
    "    tag_counts_per_talk = split_tags.apply(len)\n",
    "\n",
    "    joined_tags = tags.str.cat(sep=',').split(',')\n",
    "    all_tags = pd.Series(joined_tags)\n",
    "\n",
    "    tag_counts = all_tags.value_counts().rename_axis(target_column).reset_index(name='counts')\n",
    "    tag_counts['no_count'] = len(df)-tag_counts['counts']\n",
    "    tag_counts['ratio'] = tag_counts['counts']/tag_counts['no_count']\n",
    "    tag_counts['overall_ratio'] = tag_counts['counts']/(tag_counts['no_count'] + tag_counts['counts'])\n",
    "    return tag_counts\n",
    "\n",
    "print(compute_tag_ratio('tags', df))\n",
    "squashed_tag_counts = compute_tag_ratio('squash_tags', df)\n",
    "print_full_dataframe(squashed_tag_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['technology', 'science', 'global issues', 'culture', 'design', 'tedx', 'business', 'entertainment', 'health', 'innovation', 'education', 'art', 'society', 'social change', 'communication', 'politics', 'future', 'biology', 'creativity', 'humanity', 'collaboration', 'environment', 'medicine', 'economics', 'brain', 'activism', 'invention', 'community', 'history', 'children', 'ted fellows', 'health care', 'music', 'women', 'cities', 'storytelling', 'animals', 'war', 'engineering', 'leadership', 'identity', 'nature', 'computers', 'psychology', 'humor', 'life', 'performance', 'exploration', 'africa', 'data', 'photography', 'inequality', 'medical research', 'personal growth', 'neuroscience', 'government', 'climate change', 'visualizations', 'internet', 'architecture', 'sustainability', 'oceans', 'disease', 'green', 'happiness', 'biotech', 'potential', 'work', 'physics', 'media', 'film', 'violence', 'evolution', 'mind', 'big problems', 'writing', 'motivation', 'philosophy', 'biodiversity', 'live music', 'entrepreneur', 'genetics', 'mental health', 'global development', 'language', 'beauty', 'space', 'robots', 'food', 'cognitive science', 'math', 'ecology', 'religion', 'ted brain trust', 'peace', 'demo', 'energy', 'poverty', 'illness', 'policy', 'family', 'parenting', 'adventure', 'public health', 'self', 'poetry', 'universe', 'product design', 'relationships', 'democracy', 'cancer', 'comedy', 'journalism', 'intelligence', 'social media', 'infrastructure', 'astronomy', 'law', 'crime', 'software', 'teaching', 'choice', 'death', 'dna', 'web', 'aging', 'science and art', 'love', 'materials', 'security', 'water', 'youth', 'race', 'terrorism', 'chemistry', 'transportation', 'alternative energy', 'ai', 'sex', 'goal-setting', 'pollution', 'agriculture', 'books', 'decision-making', 'open-source', 'compassion', 'insects', 'middle east', 'philanthropy', 'molecular biology', 'sports', 'algorithm', 'investment', 'feminism', 'gaming', 'disability', 'fear', 'curiosity', 'microbiology', 'money', 'statistics', 'plants', 'success', 'women in business', 'fish', 'ted prize', 'biomechanics', 'gender', 'interface design', 'industrial design', 'urban planning', 'empathy', 'united states', 'code', 'asia', 'depression', 'planets', 'bacteria', 'faith']\n"
     ]
    }
   ],
   "source": [
    "all_tags = list(squashed_tag_counts.squash_tags.unique())\n",
    "print(all_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_one_hot_encode(transcript_column, tag_column, unique_tags, df=df):\n",
    "    complete_transcripts_tags = []\n",
    "    for rows, value in df.iterrows():\n",
    "        one_hot_encoding = [0] * len(all_tags)\n",
    "        transcript = [value[transcript_column]]\n",
    "        indiv_tags = value[tag_column].split(',')\n",
    "        for tags in indiv_tags:\n",
    "            if tags == '':\n",
    "                continue\n",
    "            index = unique_tags.index(tags.lower().lstrip(' '))\n",
    "            one_hot_encoding[index] = 1\n",
    "        indiv_transcript_tags = transcript + one_hot_encoding\n",
    "        complete_transcripts_tags.append(indiv_transcript_tags)\n",
    "    return pd.DataFrame(complete_transcripts_tags, columns=['transcript'] + all_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript</th>\n",
       "      <th>technology</th>\n",
       "      <th>science</th>\n",
       "      <th>global issues</th>\n",
       "      <th>culture</th>\n",
       "      <th>design</th>\n",
       "      <th>tedx</th>\n",
       "      <th>business</th>\n",
       "      <th>entertainment</th>\n",
       "      <th>health</th>\n",
       "      <th>...</th>\n",
       "      <th>industrial design</th>\n",
       "      <th>urban planning</th>\n",
       "      <th>empathy</th>\n",
       "      <th>united states</th>\n",
       "      <th>code</th>\n",
       "      <th>asia</th>\n",
       "      <th>depression</th>\n",
       "      <th>planets</th>\n",
       "      <th>bacteria</th>\n",
       "      <th>faith</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>thank chris truly great honor opportunity come...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>term invention like tell tale favorite project...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>public dewey long ago observe constitute discu...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>want start say houston problem enter second ge...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>want talk background idea car art actually mea...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2381</th>\n",
       "      <td>imagine walk even discover everybody room look...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2382</th>\n",
       "      <td>pay close attention easy attention pull differ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2383</th>\n",
       "      <td>happy pic take senior college right dance prac...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2384</th>\n",
       "      <td>sevenyearold grandson sleep hall wake lot morn...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2385</th>\n",
       "      <td>michael brown engineer innovator inventor insp...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2386 rows × 180 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             transcript  technology  science  \\\n",
       "0     thank chris truly great honor opportunity come...           1        1   \n",
       "1     term invention like tell tale favorite project...           0        0   \n",
       "2     public dewey long ago observe constitute discu...           0        0   \n",
       "3     want start say houston problem enter second ge...           0        0   \n",
       "4     want talk background idea car art actually mea...           1        0   \n",
       "...                                                 ...         ...      ...   \n",
       "2381  imagine walk even discover everybody room look...           0        0   \n",
       "2382  pay close attention easy attention pull differ...           1        0   \n",
       "2383  happy pic take senior college right dance prac...           0        0   \n",
       "2384  sevenyearold grandson sleep hall wake lot morn...           0        0   \n",
       "2385  michael brown engineer innovator inventor insp...           1        0   \n",
       "\n",
       "      global issues  culture  design  tedx  business  entertainment  health  \\\n",
       "0                 1        1       0     0         0              0       0   \n",
       "1                 1        0       1     0         0              0       0   \n",
       "2                 1        1       0     0         1              0       0   \n",
       "3                 0        0       1     0         1              0       0   \n",
       "4                 0        0       1     0         1              0       0   \n",
       "...             ...      ...     ...   ...       ...            ...     ...   \n",
       "2381              0        0       0     0         0              0       0   \n",
       "2382              0        0       0     0         0              0       0   \n",
       "2383              0        0       0     0         0              0       0   \n",
       "2384              0        0       0     0         0              0       0   \n",
       "2385              0        0       1     0         0              0       0   \n",
       "\n",
       "      ...  industrial design  urban planning  empathy  united states  code  \\\n",
       "0     ...                  0               0        0              0     0   \n",
       "1     ...                  1               0        0              0     0   \n",
       "2     ...                  0               0        0              0     0   \n",
       "3     ...                  1               0        0              0     0   \n",
       "4     ...                  1               0        0              0     0   \n",
       "...   ...                ...             ...      ...            ...   ...   \n",
       "2381  ...                  0               1        0              0     0   \n",
       "2382  ...                  0               0        0              0     0   \n",
       "2383  ...                  0               0        0              0     0   \n",
       "2384  ...                  0               0        0              0     0   \n",
       "2385  ...                  0               0        0              0     0   \n",
       "\n",
       "      asia  depression  planets  bacteria  faith  \n",
       "0        0           0        0         0      0  \n",
       "1        0           0        0         0      0  \n",
       "2        0           0        0         0      0  \n",
       "3        0           0        0         0      0  \n",
       "4        0           0        0         0      0  \n",
       "...    ...         ...      ...       ...    ...  \n",
       "2381     0           0        0         0      0  \n",
       "2382     0           0        0         0      0  \n",
       "2383     0           0        0         0      0  \n",
       "2384     0           0        0         0      0  \n",
       "2385     0           0        0         0      0  \n",
       "\n",
       "[2386 rows x 180 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ted_tags = create_one_hot_encode('clean_transcript_string', 'squash_tags', all_tags)\n",
    "ted_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target_column(target_tag, df=ted_tags):\n",
    "    return df[['transcript', target_tag]]\n",
    "single_class = get_target_column('technology', ted_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#breakdown by class\n",
    "sns.countplot(x=\"technology\", data=single_class, palette=\"muted\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transcript    object\n",
       "technology     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_class.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(target_tag, df=ted_tags):\n",
    "    train_x, valid_x, train_y, valid_y = model_selection.train_test_split(df['transcript'], df[target_tag])\n",
    "    return train_x, valid_x, train_y, valid_y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset into training and validation datasets \n",
    "train_x, valid_x, train_y, valid_y = train_test_split('technology')\n",
    "\n",
    "# label encode the target variable \n",
    "encoder = preprocessing.LabelEncoder()\n",
    "train_y = encoder.fit_transform(train_y)\n",
    "valid_y = encoder.fit_transform(valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a count vectorizer object \n",
    "count_vect = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}')\n",
    "count_vect.fit(single_class['transcript'])\n",
    "\n",
    "# transform the training and validation data using count vectorizer object\n",
    "xtrain_count =  count_vect.transform(train_x)\n",
    "xvalid_count =  count_vect.transform(valid_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word level tf-idf\n",
    "tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=5000)\n",
    "tfidf_vect.fit(single_class['transcript'])\n",
    "xtrain_tfidf =  tfidf_vect.transform(train_x)\n",
    "xvalid_tfidf =  tfidf_vect.transform(valid_x)\n",
    "\n",
    "# ngram level tf-idf \n",
    "tfidf_vect_ngram = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=5000)\n",
    "tfidf_vect_ngram.fit(single_class['transcript'])\n",
    "xtrain_tfidf_ngram =  tfidf_vect_ngram.transform(train_x)\n",
    "xvalid_tfidf_ngram =  tfidf_vect_ngram.transform(valid_x)\n",
    "\n",
    "# characters level tf-idf\n",
    "tfidf_vect_ngram_chars = TfidfVectorizer(analyzer='char', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=5000)\n",
    "tfidf_vect_ngram_chars.fit(single_class['transcript'])\n",
    "xtrain_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(train_x) \n",
    "xvalid_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(valid_x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(classifier, feature_vector_train, label, feature_vector_valid, is_neural_net=False):\n",
    "    # fit the training dataset on the classifier\n",
    "    classifier.fit(feature_vector_train, label)\n",
    "    \n",
    "    # predict the labels on validation dataset\n",
    "    predictions = classifier.predict(feature_vector_valid)\n",
    "    \n",
    "    if is_neural_net:\n",
    "        predictions = predictions.argmax(axis=-1)\n",
    "    \n",
    "    return metrics.accuracy_score(predictions, valid_y), classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB, Count Vectors: 0.7638190954773869\n",
      "NB, WordLevel TF-IDF: 0.7587939698492462\n",
      "NB, N-Gram Vectors: 0.7219430485762144\n",
      "NB, CharLevel Vectors: 0.7068676716917923\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes on Count Vectors\n",
    "accuracy, classifier_count = train_model(naive_bayes.MultinomialNB(), xtrain_count, train_y, xvalid_count)\n",
    "print (\"NB, Count Vectors: {}\".format(accuracy))\n",
    "\n",
    "# Naive Bayes on Word Level TF IDF Vectors\n",
    "accuracy, classifier_word_tfidf = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf, train_y, xvalid_tfidf)\n",
    "print (\"NB, WordLevel TF-IDF: {}\".format(accuracy))\n",
    "\n",
    "# Naive Bayes on Ngram Level TF IDF Vectors\n",
    "accuracy, classifier_ngram_tfidf = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf_ngram, train_y, xvalid_tfidf_ngram)\n",
    "print (\"NB, N-Gram Vectors: {}\".format(accuracy))\n",
    "\n",
    "# Naive Bayes on Character Level TF IDF Vectors\n",
    "accuracy, classifier_charlevel_tfidf = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf_ngram_chars, train_y, xvalid_tfidf_ngram_chars)\n",
    "print (\"NB, CharLevel Vectors: {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Glenn\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR, Count Vectors: 0.7453936348408711\n",
      "LR, WordLevel TF-IDF: 0.7788944723618091\n",
      "LR, N-Gram Vectors: 0.7236180904522613\n",
      "LR, CharLevel Vectors: 0.7403685092127303\n"
     ]
    }
   ],
   "source": [
    "# Linear Classifier on Count Vectors\n",
    "accuracy, classifier_count = train_model(linear_model.LogisticRegression(), xtrain_count, train_y, xvalid_count)\n",
    "print (\"LR, Count Vectors: {}\".format(accuracy))\n",
    "\n",
    "# Linear Classifier on Word Level TF IDF Vectors\n",
    "accuracy, classifier_word_tfidf = train_model(linear_model.LogisticRegression(), xtrain_tfidf, train_y, xvalid_tfidf)\n",
    "print (\"LR, WordLevel TF-IDF: {}\".format(accuracy))\n",
    "\n",
    "# Linear Classifier on Ngram Level TF IDF Vectors\n",
    "accuracy, classifier_ngram_tfidf = train_model(linear_model.LogisticRegression(), xtrain_tfidf_ngram, train_y, xvalid_tfidf_ngram)\n",
    "print (\"LR, N-Gram Vectors: {}\".format(accuracy))\n",
    "\n",
    "# Linear Classifier on Character Level TF IDF Vectors\n",
    "accuracy, classifier_charlevel_tfidf = train_model(linear_model.LogisticRegression(), xtrain_tfidf_ngram_chars, train_y, xvalid_tfidf_ngram_chars)\n",
    "print (\"LR, CharLevel Vectors: {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM, N-Gram Vectors: 0.7420435510887772\n"
     ]
    }
   ],
   "source": [
    "accuracy, classifier_ngram_tfidf = train_model(svm.SVC(kernel='linear', class_weight='balanced', C=1.0), xtrain_tfidf_ngram, train_y, xvalid_tfidf_ngram)\n",
    "print (\"SVM, N-Gram Vectors: {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Glenn\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF, Count Vectors: 0.7370184254606366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Glenn\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF, WordLevel TF-IDF: 0.7520938023450586\n"
     ]
    }
   ],
   "source": [
    "# RF on Count Vectors\n",
    "accuracy, classifier_count = train_model(ensemble.RandomForestClassifier(class_weight='balanced'), xtrain_count, train_y, xvalid_count)\n",
    "print (\"RF, Count Vectors: {}\".format(accuracy))\n",
    "\n",
    "# RF on Word Level TF IDF Vectors\n",
    "accuracy, classifier_word_tfidf = train_model(ensemble.RandomForestClassifier(class_weight='balanced'), xtrain_tfidf, train_y, xvalid_tfidf)\n",
    "print (\"RF, WordLevel TF-IDF: {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xgboost' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-61-ce8727fbd564>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Extereme Gradient Boosting on Count Vectors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0maccuracy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclassifier_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxgboost\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXGBClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxtrain_count\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtocsc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxvalid_count\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtocsc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"Xgb, Count Vectors: {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Extereme Gradient Boosting on Word Level TF IDF Vectors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'xgboost' is not defined"
     ]
    }
   ],
   "source": [
    "# Extereme Gradient Boosting on Count Vectors\n",
    "accuracy, classifier_count = train_model(xgboost.XGBClassifier(), xtrain_count.tocsc(), train_y, xvalid_count.tocsc())\n",
    "print (\"Xgb, Count Vectors: {}\".format(accuracy))\n",
    "\n",
    "# Extereme Gradient Boosting on Word Level TF IDF Vectors\n",
    "accuracy, classifier_word_tfidf = train_model(xgboost.XGBClassifier(), xtrain_tfidf.tocsc(), train_y, xvalid_tfidf.tocsc())\n",
    "print (\"Xgb, WordLevel TF-IDF: {}\".format(accuracy))\n",
    "\n",
    "# Extereme Gradient Boosting on Character Level TF IDF Vectors\n",
    "accuracy, classifier_word_tfidf  = train_model(xgboost.XGBClassifier(), xtrain_tfidf_ngram_chars.tocsc(), train_y, xvalid_tfidf_ngram_chars.tocsc())\n",
    "print (\"Xgb, CharLevel Vectors: {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_pipeline = Pipeline(steps = [\n",
    "#     ('target_column', get_target_column(target_tag='technology', df=ted_tags)),\n",
    "#     ('tts', train_test_split(target_tag='technology'))\n",
    "# ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
