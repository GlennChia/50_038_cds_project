{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"../../data/raw/\"\n",
    "INPUT_FILE_NAME = 'cleaned.parquet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker</th>\n",
       "      <th>headline</th>\n",
       "      <th>description</th>\n",
       "      <th>duration</th>\n",
       "      <th>tags</th>\n",
       "      <th>transcript</th>\n",
       "      <th>WC</th>\n",
       "      <th>clean_transcript</th>\n",
       "      <th>clean_transcript_string</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Al Gore</td>\n",
       "      <td>Averting the climate crisis</td>\n",
       "      <td>With the same humor and humanity he exuded in ...</td>\n",
       "      <td>0:16:17</td>\n",
       "      <td>cars,alternative energy,culture,politics,scien...</td>\n",
       "      <td>0:14\\r\\r\\rThank you so much, Chris.\\rAnd it's ...</td>\n",
       "      <td>2281.0</td>\n",
       "      <td>[thank, chris, truly, great, honor, opportunit...</td>\n",
       "      <td>thank chris truly great honor opportunity come...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Amy Smith</td>\n",
       "      <td>Simple designs to save a life</td>\n",
       "      <td>Fumes from indoor cooking fires kill more than...</td>\n",
       "      <td>0:15:06</td>\n",
       "      <td>MacArthur grant,simplicity,industrial design,a...</td>\n",
       "      <td>0:11\\r\\r\\rIn terms of invention,\\rI'd like to ...</td>\n",
       "      <td>2687.0</td>\n",
       "      <td>[term, invention, like, tell, tale, favorite, ...</td>\n",
       "      <td>term invention like tell tale favorite project...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ashraf Ghani</td>\n",
       "      <td>How to rebuild a broken state</td>\n",
       "      <td>Ashraf Ghani's passionate and powerful 10-minu...</td>\n",
       "      <td>0:18:45</td>\n",
       "      <td>corruption,poverty,economics,investment,milita...</td>\n",
       "      <td>0:12\\r\\r\\rA public, Dewey long ago observed,\\r...</td>\n",
       "      <td>2506.0</td>\n",
       "      <td>[public, dewey, long, ago, observe, constitute...</td>\n",
       "      <td>public dewey long ago observe constitute discu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Burt Rutan</td>\n",
       "      <td>The real future of space exploration</td>\n",
       "      <td>In this passionate talk, legendary spacecraft ...</td>\n",
       "      <td>0:19:37</td>\n",
       "      <td>aircraft,flight,industrial design,NASA,rocket ...</td>\n",
       "      <td>0:11\\r\\r\\rI want to start off by saying, Houst...</td>\n",
       "      <td>3092.0</td>\n",
       "      <td>[want, start, say, houston, problem, enter, se...</td>\n",
       "      <td>want start say houston problem enter second ge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chris Bangle</td>\n",
       "      <td>Great cars are great art</td>\n",
       "      <td>American designer Chris Bangle explains his ph...</td>\n",
       "      <td>0:20:04</td>\n",
       "      <td>cars,industrial design,transportation,inventio...</td>\n",
       "      <td>0:12\\r\\r\\rWhat I want to talk about is, as bac...</td>\n",
       "      <td>3781.0</td>\n",
       "      <td>[want, talk, background, idea, car, art, actua...</td>\n",
       "      <td>want talk background idea car art actually mea...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        speaker                              headline  \\\n",
       "0       Al Gore           Averting the climate crisis   \n",
       "1     Amy Smith         Simple designs to save a life   \n",
       "2  Ashraf Ghani         How to rebuild a broken state   \n",
       "3    Burt Rutan  The real future of space exploration   \n",
       "4  Chris Bangle              Great cars are great art   \n",
       "\n",
       "                                         description duration  \\\n",
       "0  With the same humor and humanity he exuded in ...  0:16:17   \n",
       "1  Fumes from indoor cooking fires kill more than...  0:15:06   \n",
       "2  Ashraf Ghani's passionate and powerful 10-minu...  0:18:45   \n",
       "3  In this passionate talk, legendary spacecraft ...  0:19:37   \n",
       "4  American designer Chris Bangle explains his ph...  0:20:04   \n",
       "\n",
       "                                                tags  \\\n",
       "0  cars,alternative energy,culture,politics,scien...   \n",
       "1  MacArthur grant,simplicity,industrial design,a...   \n",
       "2  corruption,poverty,economics,investment,milita...   \n",
       "3  aircraft,flight,industrial design,NASA,rocket ...   \n",
       "4  cars,industrial design,transportation,inventio...   \n",
       "\n",
       "                                          transcript      WC  \\\n",
       "0  0:14\\r\\r\\rThank you so much, Chris.\\rAnd it's ...  2281.0   \n",
       "1  0:11\\r\\r\\rIn terms of invention,\\rI'd like to ...  2687.0   \n",
       "2  0:12\\r\\r\\rA public, Dewey long ago observed,\\r...  2506.0   \n",
       "3  0:11\\r\\r\\rI want to start off by saying, Houst...  3092.0   \n",
       "4  0:12\\r\\r\\rWhat I want to talk about is, as bac...  3781.0   \n",
       "\n",
       "                                    clean_transcript  \\\n",
       "0  [thank, chris, truly, great, honor, opportunit...   \n",
       "1  [term, invention, like, tell, tale, favorite, ...   \n",
       "2  [public, dewey, long, ago, observe, constitute...   \n",
       "3  [want, start, say, houston, problem, enter, se...   \n",
       "4  [want, talk, background, idea, car, art, actua...   \n",
       "\n",
       "                             clean_transcript_string  \n",
       "0  thank chris truly great honor opportunity come...  \n",
       "1  term invention like tell tale favorite project...  \n",
       "2  public dewey long ago observe constitute discu...  \n",
       "3  want start say houston problem enter second ge...  \n",
       "4  want talk background idea car art actually mea...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet(DATA_DIR + INPUT_FILE_NAME)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               tags  counts  no_count     ratio\n",
      "0        technology     695      1691  0.410999\n",
      "1           science     522      1864  0.280043\n",
      "2     global issues     483      1903  0.253810\n",
      "3           culture     470      1916  0.245303\n",
      "4            design     400      1986  0.201410\n",
      "..              ...     ...       ...       ...\n",
      "413  ted en espanol       1      2385  0.000419\n",
      "414           cloud       1      2385  0.000419\n",
      "415         testing       1      2385  0.000419\n",
      "416    epidemiology       1      2385  0.000419\n",
      "417  ted en español       1      2385  0.000419\n",
      "\n",
      "[418 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "tags = df['tags'].str.replace(', ',',').str.lower().str.strip()\n",
    "split_tags = tags.str.split(',')\n",
    "tag_counts_per_talk = split_tags.apply(len)\n",
    "\n",
    "joined_tags = tags.str.cat(sep=',').split(',')\n",
    "all_tags = pd.Series(joined_tags)\n",
    "\n",
    "tag_counts = all_tags.value_counts().rename_axis('tags').reset_index(name='counts')\n",
    "tag_counts['no_count'] = len(df)-tag_counts['counts']\n",
    "tag_counts['ratio'] = tag_counts['counts']/tag_counts['no_count']\n",
    "print(tag_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cars', 'alternative energy', 'culture', 'politics', 'science', 'climate change', 'environment', 'sustainability', 'global issues', 'technology', 'macarthur grant', 'simplicity', 'industrial design', 'invention', 'engineering', 'design', 'corruption', 'poverty', 'economics', 'investment', 'military', 'policy', 'global development', 'entrepreneur', 'business', 'aircraft', 'flight', 'nasa', 'rocket science', 'transportation', 'art', 'biotech', 'oceans', 'genetics', 'dna', 'biology', 'biodiversity', 'ecology', 'computers', 'software', 'interface design', 'music', 'media', 'entertainment', 'performance', 'new york', 'memory', 'interview', 'death', 'architecture', 'disaster relief', 'cities', 'urban planning', 'collaboration', 'robots', 'education', 'innovation', 'social change', 'obesity', 'disease', 'health', 'health care', 'food', 'primates', 'africa', 'animals', 'nature', 'wunderkind', 'cancer', 'creativity', 'love', 'gender', 'relationships', 'cognitive science', 'psychology', 'evolution', 'biomimicry', 'fish', 'philosophy', 'choice', 'history', 'future', 'consumerism', 'marketing', 'storytelling', 'communication', 'community', 'faith', 'illusion', 'religion', 'ted brain trust', 'film', 'activism', 'open-source', 'library', 'poetry', 'product design', 'science and art', 'narcotics', 'race', 'statistics', 'parenting', 'brazil', 'animation', 'terrorism', 'war', 'peace', 'photography', 'wikipedia', 'aging', 'one laptop per child', 'philanthropy', 'children', 'cosmos', 'complexity', 'universe', 'astronomy', 'time', 'leadership', 'happiness', 'violin', 'youth', 'piano', 'physics', 'materials', 'typography', 'energy', 'green', 'pollution', 'inequality', 'ted prize', 'medicine', 'ebola', 'aids', 'sports', 'performance art', 'theater', 'united states', 'map', 'women', 'demo', 'dance', 'teaching', 'anthropology', 'language', 'success', 'work', 'christianity', 'god', 'motivation', 'work-life balance', 'personal growth', 'potential', 'apes', 'intelligence', 'online video', 'biomechanics', 'brain', 'telecom', 'microfinance', 'live music', 'singer', 'prosthetics', 'ants', 'insects', 'atheism', 'comedy', 'humor', 'travel', 'exploration', 'code', 'asia', 'math', 'google', 'visualizations', 'decision-making', 'consciousness', 'goal-setting', 'guitar', 'vocals', 'cello', 'self', 'china', 'web', 'spoken word', 'composing', 'natural disaster', 'meme', 'water', 'museums', 'ai', 'women in business', 'microsoft', 'virtual reality', 'buddhism', 'moon', 'mining', 'planets', 'space', 'adventure', 'bioethics', 'gaming', 'literature', 'books', 'sociology', 'violence', 'solar system', 'humanity', 'human origins', 'paleontology', 'drones', 'illness', 'law', 'suicide', 'depression', 'mental health', 'string theory', 'magic', 'empathy', 'compassion', 'writing', 'ted books', 'play', 'latin america', 'world cultures', 'infrastructure', 'bees', 'garden', 'plants', 'ancient world', 'toy', 'hack', 'news', 'heart health', 'public health', 'big bang', 'bacteria', 'microbiology', 'submarine', 'sex', 'society', 'archaeology', 'dinosaurs', 'evil', 'crime', 'prison', 'beauty', 'plastic', 'vaccines', 'conducting', 'family', 'trees', 'extraterrestrial life', 'personality', 'origami', 'dark matter', 'identity', 'nanoscale', 'morality', 'geology', 'life', 'presentation', 'democracy', 'solar', 'smell', 'social media', 'senses', 'fashion', 'mars', 'curiosity', 'programming', 'chemistry', 'shopping', 'body language', 'virus', 'solar energy', 'fear', 'birds', 'wind energy', 'extreme sports', 'prediction', 'productivity', 'mind', 'ted fellows', 'natural resources', 'agriculture', 'india', 'neuroscience', 'tedx', 'state-building', 'money', 'europe', 'data', 'sight', 'internet', 'government', 'men', 'advertising', 'sanitation', 'charter for compassion', 'weather', 'big problems', 'slavery', 'trafficking', 'egypt', 'yesallwomen', 'feminism', 'autism spectrum disorder', 'botany', 'discovery', 'mission blue', 'student', 'hiv', 'nuclear weapons', 'oil', 'novel', 'iraq', 'islam', 'monkeys', 'iran', 'middle east', 'sound', 'population', 'bullying', 'journalism', 'cyborg', 'foreign policy', 'surgery', 'medical research', 'protests', 'deextinction', 'exoskeleton', 'disability', 'nuclear energy', 'crowdsourcing', 'brand', 'speech', 'failure', 'security', 'pain', 'gender spectrum', 'glacier', 'mobility', 'public spaces', 'pharmaceuticals', 'molecular biology', 'behavioral economics', 'medical imaging', 'physiology', 'pregnancy', 'synthetic biology', 'hearing', 'jazz', 'nobel prize', 'finance', 'tedyouth', '3d printing', 'guns', 'algorithm', 'conservation', 'immigration', 'privacy', 'machine learning', 'lgbt', 'skateboarding', 'microbes', 'augmented reality', 'urban', 'forensics', 'painting', 'pandemic', 'mindfulness', 'meditation', 'transgender', 'testing', 'farming', 'debate', 'cloud', 'sleep', 'television', 'street art', 'addiction', 'south america', 'vulnerability', 'capitalism', 'tedmed', 'refugees', 'criminal justice', 'grammar', 'asteroid', 'biosphere', 'resources', 'development', 'manufacturing', 'friendship', 'funny', 'nonviolence', 'arts', 'ptsd', 'trust', 'driverless cars', 'surveillance', 'gender equality', 'blockchain', 'gay', 'crispr', 'sexual violence', 'anthropocene', 'syria', 'movies', 'ted residency', 'ted-ed', 'telescopes', 'ted en espanol', \"alzheimer's\", 'ted en español', 'epidemiology']\n",
      "417\n"
     ]
    }
   ],
   "source": [
    "joined_tags = df['tags'].str.cat(sep=',').split(',')\n",
    "all_tags = pd.Series(joined_tags).str.strip().str.lower()\n",
    "all_tags = list(dict.fromkeys(all_tags))\n",
    "try:\n",
    "    all_tags.remove('')\n",
    "except:\n",
    "    pass\n",
    "print(all_tags)\n",
    "print(len(all_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2386\n"
     ]
    }
   ],
   "source": [
    "def create_one_hot_encode(df=df):\n",
    "    complete_transcripts_tags = []\n",
    "    for rows, value in df.iterrows():\n",
    "        one_hot_encoding = [0] * len(all_tags)\n",
    "        transcript = [value['clean_transcript_string']]\n",
    "        indiv_tags = value['tags'].split(',')\n",
    "        for tags in indiv_tags:\n",
    "            if tags == '':\n",
    "                continue\n",
    "            index = all_tags.index(tags.lower().lstrip(' '))\n",
    "            one_hot_encoding[index] = 1\n",
    "        indiv_transcript_tags = transcript + one_hot_encoding\n",
    "        complete_transcripts_tags.append(indiv_transcript_tags)\n",
    "    return pd.DataFrame(complete_transcripts_tags, columns=['transcript'] + all_tags)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript</th>\n",
       "      <th>cars</th>\n",
       "      <th>alternative energy</th>\n",
       "      <th>culture</th>\n",
       "      <th>politics</th>\n",
       "      <th>science</th>\n",
       "      <th>climate change</th>\n",
       "      <th>environment</th>\n",
       "      <th>sustainability</th>\n",
       "      <th>global issues</th>\n",
       "      <th>...</th>\n",
       "      <th>anthropocene</th>\n",
       "      <th>syria</th>\n",
       "      <th>movies</th>\n",
       "      <th>ted residency</th>\n",
       "      <th>ted-ed</th>\n",
       "      <th>telescopes</th>\n",
       "      <th>ted en espanol</th>\n",
       "      <th>alzheimer's</th>\n",
       "      <th>ted en español</th>\n",
       "      <th>epidemiology</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>thank chris truly great honor opportunity come...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>term invention like tell tale favorite project...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>public dewey long ago observe constitute discu...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>want start say houston problem enter second ge...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>want talk background idea car art actually mea...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2381</th>\n",
       "      <td>imagine walk even discover everybody room look...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2382</th>\n",
       "      <td>pay close attention easy attention pull differ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2383</th>\n",
       "      <td>happy pic take senior college right dance prac...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2384</th>\n",
       "      <td>sevenyearold grandson sleep hall wake lot morn...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2385</th>\n",
       "      <td>michael brown engineer innovator inventor insp...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2386 rows × 418 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             transcript  cars  \\\n",
       "0     thank chris truly great honor opportunity come...     1   \n",
       "1     term invention like tell tale favorite project...     0   \n",
       "2     public dewey long ago observe constitute discu...     0   \n",
       "3     want start say houston problem enter second ge...     0   \n",
       "4     want talk background idea car art actually mea...     1   \n",
       "...                                                 ...   ...   \n",
       "2381  imagine walk even discover everybody room look...     0   \n",
       "2382  pay close attention easy attention pull differ...     0   \n",
       "2383  happy pic take senior college right dance prac...     0   \n",
       "2384  sevenyearold grandson sleep hall wake lot morn...     0   \n",
       "2385  michael brown engineer innovator inventor insp...     0   \n",
       "\n",
       "      alternative energy  culture  politics  science  climate change  \\\n",
       "0                      1        1         1        1               1   \n",
       "1                      1        0         0        0               0   \n",
       "2                      0        1         1        0               0   \n",
       "3                      0        0         0        0               0   \n",
       "4                      0        0         0        0               0   \n",
       "...                  ...      ...       ...      ...             ...   \n",
       "2381                   0        0         0        0               0   \n",
       "2382                   0        0         0        0               0   \n",
       "2383                   0        0         0        0               0   \n",
       "2384                   0        0         0        0               0   \n",
       "2385                   0        0         0        0               0   \n",
       "\n",
       "      environment  sustainability  global issues  ...  anthropocene  syria  \\\n",
       "0               1               1              1  ...             0      0   \n",
       "1               0               0              1  ...             0      0   \n",
       "2               0               0              1  ...             0      0   \n",
       "3               0               0              0  ...             0      0   \n",
       "4               0               0              0  ...             0      0   \n",
       "...           ...             ...            ...  ...           ...    ...   \n",
       "2381            0               0              0  ...             0      0   \n",
       "2382            0               0              0  ...             0      0   \n",
       "2383            0               0              0  ...             0      0   \n",
       "2384            0               0              0  ...             0      0   \n",
       "2385            0               0              0  ...             0      0   \n",
       "\n",
       "      movies  ted residency  ted-ed  telescopes  ted en espanol  alzheimer's  \\\n",
       "0          0              0       0           0               0            0   \n",
       "1          0              0       0           0               0            0   \n",
       "2          0              0       0           0               0            0   \n",
       "3          0              0       0           0               0            0   \n",
       "4          0              0       0           0               0            0   \n",
       "...      ...            ...     ...         ...             ...          ...   \n",
       "2381       0              0       0           0               0            0   \n",
       "2382       0              0       0           0               0            0   \n",
       "2383       0              0       0           0               0            0   \n",
       "2384       0              0       0           0               0            0   \n",
       "2385       0              0       0           0               0            0   \n",
       "\n",
       "      ted en español  epidemiology  \n",
       "0                  0             0  \n",
       "1                  0             0  \n",
       "2                  0             0  \n",
       "3                  0             0  \n",
       "4                  0             0  \n",
       "...              ...           ...  \n",
       "2381               0             0  \n",
       "2382               0             0  \n",
       "2383               0             0  \n",
       "2384               0             0  \n",
       "2385               0             0  \n",
       "\n",
       "[2386 rows x 418 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ted_tags = create_one_hot_encode()\n",
    "ted_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript</th>\n",
       "      <th>technology</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>thank chris truly great honor opportunity come...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>term invention like tell tale favorite project...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>public dewey long ago observe constitute discu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>want start say houston problem enter second ge...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>want talk background idea car art actually mea...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2381</th>\n",
       "      <td>imagine walk even discover everybody room look...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2382</th>\n",
       "      <td>pay close attention easy attention pull differ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2383</th>\n",
       "      <td>happy pic take senior college right dance prac...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2384</th>\n",
       "      <td>sevenyearold grandson sleep hall wake lot morn...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2385</th>\n",
       "      <td>michael brown engineer innovator inventor insp...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2386 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             transcript  technology\n",
       "0     thank chris truly great honor opportunity come...           1\n",
       "1     term invention like tell tale favorite project...           0\n",
       "2     public dewey long ago observe constitute discu...           0\n",
       "3     want start say houston problem enter second ge...           0\n",
       "4     want talk background idea car art actually mea...           1\n",
       "...                                                 ...         ...\n",
       "2381  imagine walk even discover everybody room look...           0\n",
       "2382  pay close attention easy attention pull differ...           1\n",
       "2383  happy pic take senior college right dance prac...           0\n",
       "2384  sevenyearold grandson sleep hall wake lot morn...           0\n",
       "2385  michael brown engineer innovator inventor insp...           1\n",
       "\n",
       "[2386 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_class = ted_tags[['transcript', 'technology']]\n",
    "single_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "#breakdown by class\n",
    "sns.countplot(x=\"technology\", data=single_class, palette=\"muted\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transcript    object\n",
       "technology     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_class.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn import decomposition, ensemble\n",
    "\n",
    "import pandas,numpy, string #textblob, string#,# xgboost, numpy, textblob, string\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras import layers, models, optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset into training and validation datasets \n",
    "train_x, valid_x, train_y, valid_y = model_selection.train_test_split(single_class['transcript'], single_class['technology'])\n",
    "\n",
    "# label encode the target variable \n",
    "encoder = preprocessing.LabelEncoder()\n",
    "train_y = encoder.fit_transform(train_y)\n",
    "valid_y = encoder.fit_transform(valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a count vectorizer object \n",
    "count_vect = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}')\n",
    "count_vect.fit(single_class['transcript'])\n",
    "\n",
    "# transform the training and validation data using count vectorizer object\n",
    "xtrain_count =  count_vect.transform(train_x)\n",
    "xvalid_count =  count_vect.transform(valid_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word level tf-idf\n",
    "tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=5000)\n",
    "tfidf_vect.fit(single_class['transcript'])\n",
    "xtrain_tfidf =  tfidf_vect.transform(train_x)\n",
    "xvalid_tfidf =  tfidf_vect.transform(valid_x)\n",
    "\n",
    "# ngram level tf-idf \n",
    "tfidf_vect_ngram = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=5000)\n",
    "tfidf_vect_ngram.fit(single_class['transcript'])\n",
    "xtrain_tfidf_ngram =  tfidf_vect_ngram.transform(train_x)\n",
    "xvalid_tfidf_ngram =  tfidf_vect_ngram.transform(valid_x)\n",
    "\n",
    "# characters level tf-idf\n",
    "tfidf_vect_ngram_chars = TfidfVectorizer(analyzer='char', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=5000)\n",
    "tfidf_vect_ngram_chars.fit(single_class['transcript'])\n",
    "xtrain_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(train_x) \n",
    "xvalid_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(valid_x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(classifier, feature_vector_train, label, feature_vector_valid, is_neural_net=False):\n",
    "    # fit the training dataset on the classifier\n",
    "    classifier.fit(feature_vector_train, label)\n",
    "    \n",
    "    # predict the labels on validation dataset\n",
    "    predictions = classifier.predict(feature_vector_valid)\n",
    "    \n",
    "    if is_neural_net:\n",
    "        predictions = predictions.argmax(axis=-1)\n",
    "    \n",
    "    return metrics.accuracy_score(predictions, valid_y), classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB, Count Vectors: 0.7772194304857621\n",
      "NB, WordLevel TF-IDF: 0.7554438860971524\n",
      "NB, N-Gram Vectors: 0.711892797319933\n",
      "NB, CharLevel Vectors: 0.6867671691792295\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes on Count Vectors\n",
    "accuracy, classifier_count = train_model(naive_bayes.MultinomialNB(), xtrain_count, train_y, xvalid_count)\n",
    "print (\"NB, Count Vectors: {}\".format(accuracy))\n",
    "\n",
    "# Naive Bayes on Word Level TF IDF Vectors\n",
    "accuracy, classifier_word_tfidf = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf, train_y, xvalid_tfidf)\n",
    "print (\"NB, WordLevel TF-IDF: {}\".format(accuracy))\n",
    "\n",
    "# Naive Bayes on Ngram Level TF IDF Vectors\n",
    "accuracy, classifier_ngram_tfidf = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf_ngram, train_y, xvalid_tfidf_ngram)\n",
    "print (\"NB, N-Gram Vectors: {}\".format(accuracy))\n",
    "\n",
    "# Naive Bayes on Character Level TF IDF Vectors\n",
    "accuracy, classifier_charlevel_tfidf = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf_ngram_chars, train_y, xvalid_tfidf_ngram_chars)\n",
    "print (\"NB, CharLevel Vectors: {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1149    lucky person privilege beautiful earth people ...\n",
      "1501    democracy trouble question come deep dilemma e...\n",
      "954     know million cellular radio mast deploy worldw...\n",
      "2325    couple year produce dead mall series short fil...\n",
      "661     want talk penguin today want start say need ne...\n",
      "                              ...                        \n",
      "620     illegal wildlife trade brazil major threat fau...\n",
      "1100    extraordinary honor spend time jail prison dea...\n",
      "863     idea stuxnet worm actually simple want iran bo...\n",
      "2305    tell time race race contemporary way understan...\n",
      "96      rachel carson silent spring think people like ...\n",
      "Name: transcript, Length: 597, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(valid_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 1 0 0 1 0 0 1 0 0 1 0 1 0\n",
      " 0 0 0 0 1 1 1 0 0 0 1 1 0 0 1 0 1 0 0 0 0 1 1 0 0 0 1 1 0 0 0 0 0 0 1 0 0\n",
      " 0 1 0 1 1 0 0 0 1 0 1 0 0 0 0 1 1 0 0 0 0 1 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 1 1 0 1 1 0 0 1 0 0 0 0 1 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 1 1 1 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 1 1 1 0 1 0 0 0 0 0 0 1 1 1 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 1 0 0 1 1 1 0 1 1 1 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 1 0 1 0 1 1\n",
      " 0 0 0 1 1 0 0 1 0 0 1 0 0 0 0 0 1 0 1 1 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 1 0\n",
      " 1 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 1 1\n",
      " 0 0 0 0 0 1 1 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 1 0 0 1 0 0 1 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 1 0 0 1 1 0 1 0 1 0 0 0 0 0 1\n",
      " 1 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 1 0 0 1 1 1 0 0 0 1 1 0 1 0 0 0 1 0\n",
      " 0 0 1 0 0 0 1 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 1 0 0 0 0 1 1 1 0 0 1 0 0 0\n",
      " 1 1 0 0 0 0 0 0 1 0 0 1 1 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 1 0 1\n",
      " 1 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 1 0 1 1 0 1 0 0 0\n",
      " 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0\n",
      " 0 0 1 0 1]\n",
      "597\n"
     ]
    }
   ],
   "source": [
    "print(valid_y)\n",
    "print(len(valid_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'lucky person privilege beautiful earth people creature live passion inspire age seven parent take morocco edge sahara desert imagine little brit cold damp like home amaze experience want explore filmmaker end earth try perfect shoot capture animal behavior see lucky share million people worldwide idea new perspective planet actually able message get bed day spring step think hard new story new subject new technology change way film enable fresh new image tell brand new story nature great event series bbc david attenborough want image grizzly bear pretty familiar time think life hardly film go alaska grizzly rely high inaccessible mountain slope denning way film shoot air video david attenborough alaska british columbia thousand bear family emerge winter sleep eat condition ideal hibernation lot snow dig den food mother lead cub coast snow melt get challenge small cub mountain dangerous place ultimately fate bear family bear north pacific depend salmon kb love shoot goosebump time film helicopter gyrostabilized camera wonderful bite gear like fly tripod crane dolly roll technology money shoot right place right time sequence especially difficult year get follow year way remote part alaska hang helicopter week eventually get lucky cloud lift wind bear show manage magic moment filmmaker new technology amaze tool thing excite new specie discover hear animal know series untamed america national geographic new specie bat discover cloud forest ecuador amaze discovery solve mystery pollinate unique flower depend solely bat series air think video narrator tubelipped nectar bat pool delicious nectar lie flower long flute reach necessity mother evolution music twoandahalfinch bat threeandahalfinch tongue long relative body length mammal world human ninefoot tongue kb tongue film cut tiny little hole base flower camera slow action time imagine quick thing real life people ask favorite place planet truth wonderful place location draw time time remote location go backpacker time film recently untamed america altiplano high andes south america otherworldly place know foot tough freeze cold air get hard breathe especially carry heavy film equipment pound head feel like constant hangover advantage wonderful atmosphere enable star heaven amaze clarity look video narrator mile south tropic chile bolivia andes completely change call altiplano high plain place extreme extreme contrast desert freeze water boil like mar earth hostile life star foot dry air make perfect stargaze world astronomer telescope nearby look naked eye need music kb thank let share image magnificent wonderful earth thank let share'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-91cfebedd5f8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdf_predict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassifier_count\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalid_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdf_predict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'transcript'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalid_x\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdf_predict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'technology'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalid_y\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdf_predict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_predict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\naive_bayes.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     63\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0mvalues\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \"\"\"\n\u001b[1;32m---> 65\u001b[1;33m         \u001b[0mjll\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_joint_log_likelihood\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjll\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\naive_bayes.py\u001b[0m in \u001b[0;36m_joint_log_likelihood\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    734\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"classes_\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    735\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 736\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    737\u001b[0m         return (safe_sparse_dot(X, self.feature_log_prob_.T) +\n\u001b[0;32m    738\u001b[0m                 self.class_log_prior_)\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    494\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'error'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 496\u001b[1;33m                 \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    497\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\cds\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m     \"\"\"\n\u001b[1;32m---> 85\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\cds\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m    949\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    950\u001b[0m             \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"M8[ns]\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 951\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    952\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    953\u001b[0m     \u001b[1;31m# ----------------------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\cds\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m     \"\"\"\n\u001b[1;32m---> 85\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\cds\\lib\\site-packages\\pandas\\core\\arrays\\numpy_.py\u001b[0m in \u001b[0;36m__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 166\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    167\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m     \u001b[0m_HANDLED_TYPES\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumbers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNumber\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\cds\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m     \"\"\"\n\u001b[1;32m---> 85\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'lucky person privilege beautiful earth people creature live passion inspire age seven parent take morocco edge sahara desert imagine little brit cold damp like home amaze experience want explore filmmaker end earth try perfect shoot capture animal behavior see lucky share million people worldwide idea new perspective planet actually able message get bed day spring step think hard new story new subject new technology change way film enable fresh new image tell brand new story nature great event series bbc david attenborough want image grizzly bear pretty familiar time think life hardly film go alaska grizzly rely high inaccessible mountain slope denning way film shoot air video david attenborough alaska british columbia thousand bear family emerge winter sleep eat condition ideal hibernation lot snow dig den food mother lead cub coast snow melt get challenge small cub mountain dangerous place ultimately fate bear family bear north pacific depend salmon kb love shoot goosebump time film helicopter gyrostabilized camera wonderful bite gear like fly tripod crane dolly roll technology money shoot right place right time sequence especially difficult year get follow year way remote part alaska hang helicopter week eventually get lucky cloud lift wind bear show manage magic moment filmmaker new technology amaze tool thing excite new specie discover hear animal know series untamed america national geographic new specie bat discover cloud forest ecuador amaze discovery solve mystery pollinate unique flower depend solely bat series air think video narrator tubelipped nectar bat pool delicious nectar lie flower long flute reach necessity mother evolution music twoandahalfinch bat threeandahalfinch tongue long relative body length mammal world human ninefoot tongue kb tongue film cut tiny little hole base flower camera slow action time imagine quick thing real life people ask favorite place planet truth wonderful place location draw time time remote location go backpacker time film recently untamed america altiplano high andes south america otherworldly place know foot tough freeze cold air get hard breathe especially carry heavy film equipment pound head feel like constant hangover advantage wonderful atmosphere enable star heaven amaze clarity look video narrator mile south tropic chile bolivia andes completely change call altiplano high plain place extreme extreme contrast desert freeze water boil like mar earth hostile life star foot dry air make perfect stargaze world astronomer telescope nearby look naked eye need music kb thank let share image magnificent wonderful earth thank let share'"
     ]
    }
   ],
   "source": [
    "df_predict = pd.DataFrame()\n",
    "print(classifier_count.predict(valid_x))\n",
    "df_predict['transcript'] = valid_x\n",
    "df_predict['technology'] = valid_y\n",
    "df_predict = df_predict.sort_index()\n",
    "print(df_predict)\n",
    "check = df_predict.join(single_class, lsuffix='_caller', rsuffix='_other')\n",
    "print(check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-47-122ed0049c11>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_option\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'display.max_rows'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mcheck\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'same'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'technology_caller'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'technology_other'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'one'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mcheck\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "import numpy as np\n",
    "check['same'] = np.where((df['technology_caller'] == df['technology_other']) , df['one'], np.nan)\n",
    "check"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
