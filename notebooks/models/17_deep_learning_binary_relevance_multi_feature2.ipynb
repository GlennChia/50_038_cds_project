{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Useful links\n",
    "\n",
    "1. For the architecture https://towardsdatascience.com/deep-learning-for-specific-information-extraction-from-unstructured-texts-12c5b9dceada\n",
    "2. https://androidkt.com/multi-label-text-classification-in-tensorflow-keras/\n",
    "3. https://keras.io/preprocessing/sequence/\n",
    "4. https://machinelearningmastery.com/develop-word-based-neural-language-models-python-keras/ ( Not really)\n",
    "5. For deep learning using word embeddings https://stackabuse.com/python-for-nlp-multi-label-text-classification-with-keras/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"../../data/processed/\"\n",
    "INPUT_FILE_NAME = 'cleaned_squash3_with_pos_ner.parquet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker</th>\n",
       "      <th>headline</th>\n",
       "      <th>description</th>\n",
       "      <th>duration</th>\n",
       "      <th>tags</th>\n",
       "      <th>transcript</th>\n",
       "      <th>WC</th>\n",
       "      <th>clean_transcript</th>\n",
       "      <th>clean_transcript_string</th>\n",
       "      <th>squash_tags</th>\n",
       "      <th>squash2_tags</th>\n",
       "      <th>squash3_tags</th>\n",
       "      <th>pos_sequence</th>\n",
       "      <th>ner_sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Al Gore</td>\n",
       "      <td>Averting the climate crisis</td>\n",
       "      <td>With the same humor and humanity he exuded in ...</td>\n",
       "      <td>0:16:17</td>\n",
       "      <td>cars,alternative energy,culture,politics,scien...</td>\n",
       "      <td>0:14\\r\\r\\rThank you so much, Chris.\\rAnd it's ...</td>\n",
       "      <td>2281.0</td>\n",
       "      <td>[thank, chris, truly, great, honor, opportunit...</td>\n",
       "      <td>thank chris truly great honor opportunity come...</td>\n",
       "      <td>culture,politics,science,climate change,enviro...</td>\n",
       "      <td>culture,politics,science,global issues,environ...</td>\n",
       "      <td>culture,politics,science,global issues,environ...</td>\n",
       "      <td>VERB PROPN ADV ADJ NOUN NOUN VERB NOUN ADV ADV...</td>\n",
       "      <td>PERSON ORG ORG GPE LOC ORG PRODUCT GPE GPE PER...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Amy Smith</td>\n",
       "      <td>Simple designs to save a life</td>\n",
       "      <td>Fumes from indoor cooking fires kill more than...</td>\n",
       "      <td>0:15:06</td>\n",
       "      <td>MacArthur grant,simplicity,industrial design,a...</td>\n",
       "      <td>0:11\\r\\r\\rIn terms of invention,\\rI'd like to ...</td>\n",
       "      <td>2687.0</td>\n",
       "      <td>[term, invention, like, tell, tale, favorite, ...</td>\n",
       "      <td>term invention like tell tale favorite project...</td>\n",
       "      <td>invention,engineering,design,global issues</td>\n",
       "      <td>invention,engineering,design,global issues</td>\n",
       "      <td>invention,design,global issues</td>\n",
       "      <td>NOUN NOUN SCONJ VERB PROPN ADJ NOUN VERB NOUN ...</td>\n",
       "      <td>GPE DATE CARDINAL DATE ORG PERSON LOC ORG GPE ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ashraf Ghani</td>\n",
       "      <td>How to rebuild a broken state</td>\n",
       "      <td>Ashraf Ghani's passionate and powerful 10-minu...</td>\n",
       "      <td>0:18:45</td>\n",
       "      <td>corruption,poverty,economics,investment,milita...</td>\n",
       "      <td>0:12\\r\\r\\rA public, Dewey long ago observed,\\r...</td>\n",
       "      <td>2506.0</td>\n",
       "      <td>[public, dewey, long, ago, observe, constitute...</td>\n",
       "      <td>public dewey long ago observe constitute discu...</td>\n",
       "      <td>poverty,economics,culture,politics,policy,glob...</td>\n",
       "      <td>inequality,economics,culture,politics,governme...</td>\n",
       "      <td>inequality,economics,culture,politics,global i...</td>\n",
       "      <td>ADJ PROPN ADV ADV VERB ADJ NOUN NOUN PROPN PRO...</td>\n",
       "      <td>DATE NORP ORDINAL DATE MONEY DATE DATE DATE EV...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Burt Rutan</td>\n",
       "      <td>The real future of space exploration</td>\n",
       "      <td>In this passionate talk, legendary spacecraft ...</td>\n",
       "      <td>0:19:37</td>\n",
       "      <td>aircraft,flight,industrial design,NASA,rocket ...</td>\n",
       "      <td>0:11\\r\\r\\rI want to start off by saying, Houst...</td>\n",
       "      <td>3092.0</td>\n",
       "      <td>[want, start, say, houston, problem, enter, se...</td>\n",
       "      <td>want start say houston problem enter second ge...</td>\n",
       "      <td>invention,engineering,entrepreneur,design,busi...</td>\n",
       "      <td>invention,engineering,entrepreneur,design,busi...</td>\n",
       "      <td>invention,design,business</td>\n",
       "      <td>VERB NOUN VERB PROPN NOUN VERB ADJ NOUN NOUN N...</td>\n",
       "      <td>GPE ORDINAL ORG PERSON DATE DATE DATE TIME PER...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chris Bangle</td>\n",
       "      <td>Great cars are great art</td>\n",
       "      <td>American designer Chris Bangle explains his ph...</td>\n",
       "      <td>0:20:04</td>\n",
       "      <td>cars,industrial design,transportation,inventio...</td>\n",
       "      <td>0:12\\r\\r\\rWhat I want to talk about is, as bac...</td>\n",
       "      <td>3781.0</td>\n",
       "      <td>[want, talk, background, idea, car, art, actua...</td>\n",
       "      <td>want talk background idea car art actually mea...</td>\n",
       "      <td>invention,design,technology,business,art</td>\n",
       "      <td>invention,design,technology,business,art</td>\n",
       "      <td>invention,design,technology,business,art</td>\n",
       "      <td>VERB NOUN NOUN NOUN NOUN NOUN ADV ADJ NOUN NOU...</td>\n",
       "      <td>PERSON PRODUCT ORG ORG PERSON PERSON PERSON OR...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        speaker                              headline  \\\n",
       "0       Al Gore           Averting the climate crisis   \n",
       "1     Amy Smith         Simple designs to save a life   \n",
       "2  Ashraf Ghani         How to rebuild a broken state   \n",
       "3    Burt Rutan  The real future of space exploration   \n",
       "4  Chris Bangle              Great cars are great art   \n",
       "\n",
       "                                         description duration  \\\n",
       "0  With the same humor and humanity he exuded in ...  0:16:17   \n",
       "1  Fumes from indoor cooking fires kill more than...  0:15:06   \n",
       "2  Ashraf Ghani's passionate and powerful 10-minu...  0:18:45   \n",
       "3  In this passionate talk, legendary spacecraft ...  0:19:37   \n",
       "4  American designer Chris Bangle explains his ph...  0:20:04   \n",
       "\n",
       "                                                tags  \\\n",
       "0  cars,alternative energy,culture,politics,scien...   \n",
       "1  MacArthur grant,simplicity,industrial design,a...   \n",
       "2  corruption,poverty,economics,investment,milita...   \n",
       "3  aircraft,flight,industrial design,NASA,rocket ...   \n",
       "4  cars,industrial design,transportation,inventio...   \n",
       "\n",
       "                                          transcript      WC  \\\n",
       "0  0:14\\r\\r\\rThank you so much, Chris.\\rAnd it's ...  2281.0   \n",
       "1  0:11\\r\\r\\rIn terms of invention,\\rI'd like to ...  2687.0   \n",
       "2  0:12\\r\\r\\rA public, Dewey long ago observed,\\r...  2506.0   \n",
       "3  0:11\\r\\r\\rI want to start off by saying, Houst...  3092.0   \n",
       "4  0:12\\r\\r\\rWhat I want to talk about is, as bac...  3781.0   \n",
       "\n",
       "                                    clean_transcript  \\\n",
       "0  [thank, chris, truly, great, honor, opportunit...   \n",
       "1  [term, invention, like, tell, tale, favorite, ...   \n",
       "2  [public, dewey, long, ago, observe, constitute...   \n",
       "3  [want, start, say, houston, problem, enter, se...   \n",
       "4  [want, talk, background, idea, car, art, actua...   \n",
       "\n",
       "                             clean_transcript_string  \\\n",
       "0  thank chris truly great honor opportunity come...   \n",
       "1  term invention like tell tale favorite project...   \n",
       "2  public dewey long ago observe constitute discu...   \n",
       "3  want start say houston problem enter second ge...   \n",
       "4  want talk background idea car art actually mea...   \n",
       "\n",
       "                                         squash_tags  \\\n",
       "0  culture,politics,science,climate change,enviro...   \n",
       "1         invention,engineering,design,global issues   \n",
       "2  poverty,economics,culture,politics,policy,glob...   \n",
       "3  invention,engineering,entrepreneur,design,busi...   \n",
       "4           invention,design,technology,business,art   \n",
       "\n",
       "                                        squash2_tags  \\\n",
       "0  culture,politics,science,global issues,environ...   \n",
       "1         invention,engineering,design,global issues   \n",
       "2  inequality,economics,culture,politics,governme...   \n",
       "3  invention,engineering,entrepreneur,design,busi...   \n",
       "4           invention,design,technology,business,art   \n",
       "\n",
       "                                        squash3_tags  \\\n",
       "0  culture,politics,science,global issues,environ...   \n",
       "1                     invention,design,global issues   \n",
       "2  inequality,economics,culture,politics,global i...   \n",
       "3                          invention,design,business   \n",
       "4           invention,design,technology,business,art   \n",
       "\n",
       "                                        pos_sequence  \\\n",
       "0  VERB PROPN ADV ADJ NOUN NOUN VERB NOUN ADV ADV...   \n",
       "1  NOUN NOUN SCONJ VERB PROPN ADJ NOUN VERB NOUN ...   \n",
       "2  ADJ PROPN ADV ADV VERB ADJ NOUN NOUN PROPN PRO...   \n",
       "3  VERB NOUN VERB PROPN NOUN VERB ADJ NOUN NOUN N...   \n",
       "4  VERB NOUN NOUN NOUN NOUN NOUN ADV ADJ NOUN NOU...   \n",
       "\n",
       "                                        ner_sequence  \n",
       "0  PERSON ORG ORG GPE LOC ORG PRODUCT GPE GPE PER...  \n",
       "1  GPE DATE CARDINAL DATE ORG PERSON LOC ORG GPE ...  \n",
       "2  DATE NORP ORDINAL DATE MONEY DATE DATE DATE EV...  \n",
       "3  GPE ORDINAL ORG PERSON DATE DATE DATE TIME PER...  \n",
       "4  PERSON PRODUCT ORG ORG PERSON PERSON PERSON OR...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet(DATA_DIR + INPUT_FILE_NAME)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2328 entries, 0 to 2327\n",
      "Data columns (total 14 columns):\n",
      "speaker                    2328 non-null object\n",
      "headline                   2328 non-null object\n",
      "description                2328 non-null object\n",
      "duration                   2328 non-null object\n",
      "tags                       2328 non-null object\n",
      "transcript                 2328 non-null object\n",
      "WC                         2328 non-null float64\n",
      "clean_transcript           2328 non-null object\n",
      "clean_transcript_string    2328 non-null object\n",
      "squash_tags                2328 non-null object\n",
      "squash2_tags               2328 non-null object\n",
      "squash3_tags               2328 non-null object\n",
      "pos_sequence               2328 non-null object\n",
      "ner_sequence               2328 non-null object\n",
      "dtypes: float64(1), object(13)\n",
      "memory usage: 254.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.iloc[:,:14].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     squash3_tags  counts  no_count     ratio  overall_ratio\n",
      "0         culture    1106      1222  0.905074       0.475086\n",
      "1         science     868      1460  0.594521       0.372852\n",
      "2      technology     787      1541  0.510707       0.338058\n",
      "3   global issues     679      1649  0.411765       0.291667\n",
      "4          design     400      1928  0.207469       0.171821\n",
      "5        business     329      1999  0.164582       0.141323\n",
      "6   entertainment     285      2043  0.139501       0.122423\n",
      "7             art     261      2067  0.126270       0.112113\n",
      "8          future     218      2110  0.103318       0.093643\n",
      "9    biodiversity     215      2113  0.101751       0.092354\n",
      "10      education     206      2122  0.097078       0.088488\n",
      "11  communication     185      2143  0.086328       0.079467\n",
      "12       politics     183      2145  0.085315       0.078608\n",
      "13       humanity     164      2164  0.075786       0.070447\n",
      "14  collaboration     163      2165  0.075289       0.070017\n",
      "15           life     156      2172  0.071823       0.067010\n",
      "16    environment     155      2173  0.071330       0.066581\n",
      "17      economics     154      2174  0.070837       0.066151\n",
      "18          brain     148      2180  0.067890       0.063574\n",
      "19       activism     147      2181  0.067400       0.063144\n",
      "20      community     136      2192  0.062044       0.058419\n",
      "21      invention     136      2192  0.062044       0.058419\n",
      "22        history     135      2193  0.061560       0.057990\n",
      "23       children     135      2193  0.061560       0.057990\n",
      "24     inequality     128      2200  0.058182       0.054983\n",
      "25          music     126      2202  0.057221       0.054124\n"
     ]
    }
   ],
   "source": [
    "def print_full_dataframe(x):\n",
    "    pd.set_option('display.max_rows', len(x))\n",
    "    print(x)\n",
    "    pd.reset_option('display.max_rows')\n",
    "    \n",
    "def compute_tag_ratio(target_column, df=df):\n",
    "    tags = df[target_column].str.replace(', ',',').str.lower().str.strip()\n",
    "    split_tags = tags.str.split(',')\n",
    "    tag_counts_per_talk = split_tags.apply(len)\n",
    "\n",
    "    joined_tags = tags.str.cat(sep=',').split(',')\n",
    "    all_tags = pd.Series(joined_tags)\n",
    "\n",
    "    tag_counts = all_tags.value_counts().rename_axis(target_column).reset_index(name='counts')\n",
    "    tag_counts['no_count'] = len(df)-tag_counts['counts']\n",
    "    tag_counts['ratio'] = tag_counts['counts']/tag_counts['no_count']\n",
    "    tag_counts['overall_ratio'] = tag_counts['counts']/(tag_counts['no_count'] + tag_counts['counts'])\n",
    "    return tag_counts\n",
    "\n",
    "#print(compute_tag_ratio('squash3_tags', df))\n",
    "squashed_tag_counts = compute_tag_ratio('squash3_tags', df)\n",
    "print_full_dataframe(squashed_tag_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Feature Extraction via Deep learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Create one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "# y = []\n",
    "# for index, row in df.iterrows():\n",
    "#     y.append(set(row['squash3_tags'].split(',')))\n",
    "    \n",
    "# mlb = MultiLabelBinarizer()\n",
    "# encoded_y = mlb.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(encoded_y[0])\n",
    "# print(len(encoded_y[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['culture', 'politics', 'science', 'global issues', 'environment', 'technology', 'invention', 'design', 'inequality', 'economics', 'business', 'art', 'biodiversity', 'music', 'entertainment', 'collaboration', 'education', 'history', 'future', 'communication', 'community', 'activism', 'children', 'brain', 'humanity', 'life']\n",
      "26\n"
     ]
    }
   ],
   "source": [
    "joined_tags = df['squash3_tags'].str.cat(sep=',').split(',')\n",
    "all_tags = pd.Series(joined_tags).str.strip().str.lower()\n",
    "all_tags = list(dict.fromkeys(all_tags))\n",
    "try:\n",
    "    all_tags.remove('')\n",
    "except:\n",
    "    pass\n",
    "print(all_tags)\n",
    "print(len(all_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_one_hot_encode(df=df):\n",
    "    complete_transcripts_tags = []\n",
    "    for rows, value in df.iterrows():\n",
    "        one_hot_encoding = [0] * 26\n",
    "        headline = [value['headline']]\n",
    "        transcript = [value['clean_transcript_string']]\n",
    "        pos_sequence = [value['pos_sequence']]\n",
    "        ner_sequence = [value['ner_sequence']]\n",
    "        indiv_tags = value['squash3_tags'].split(',')\n",
    "        for tags in indiv_tags:\n",
    "            if tags == '':\n",
    "                continue\n",
    "            index = all_tags.index(tags.lower().lstrip(' '))\n",
    "            one_hot_encoding[index] = 1\n",
    "        indiv_transcript_tags = headline + transcript + pos_sequence + ner_sequence + one_hot_encoding\n",
    "        complete_transcripts_tags.append(indiv_transcript_tags)\n",
    "    return pd.DataFrame(complete_transcripts_tags, columns=['headline', 'transcript', 'pos_sequence', 'ner_sequence'] + all_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>transcript</th>\n",
       "      <th>pos_sequence</th>\n",
       "      <th>ner_sequence</th>\n",
       "      <th>culture</th>\n",
       "      <th>politics</th>\n",
       "      <th>science</th>\n",
       "      <th>global issues</th>\n",
       "      <th>environment</th>\n",
       "      <th>technology</th>\n",
       "      <th>...</th>\n",
       "      <th>education</th>\n",
       "      <th>history</th>\n",
       "      <th>future</th>\n",
       "      <th>communication</th>\n",
       "      <th>community</th>\n",
       "      <th>activism</th>\n",
       "      <th>children</th>\n",
       "      <th>brain</th>\n",
       "      <th>humanity</th>\n",
       "      <th>life</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Averting the climate crisis</td>\n",
       "      <td>thank chris truly great honor opportunity come...</td>\n",
       "      <td>VERB PROPN ADV ADJ NOUN NOUN VERB NOUN ADV ADV...</td>\n",
       "      <td>PERSON ORG ORG GPE LOC ORG PRODUCT GPE GPE PER...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Simple designs to save a life</td>\n",
       "      <td>term invention like tell tale favorite project...</td>\n",
       "      <td>NOUN NOUN SCONJ VERB PROPN ADJ NOUN VERB NOUN ...</td>\n",
       "      <td>GPE DATE CARDINAL DATE ORG PERSON LOC ORG GPE ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How to rebuild a broken state</td>\n",
       "      <td>public dewey long ago observe constitute discu...</td>\n",
       "      <td>ADJ PROPN ADV ADV VERB ADJ NOUN NOUN PROPN PRO...</td>\n",
       "      <td>DATE NORP ORDINAL DATE MONEY DATE DATE DATE EV...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The real future of space exploration</td>\n",
       "      <td>want start say houston problem enter second ge...</td>\n",
       "      <td>VERB NOUN VERB PROPN NOUN VERB ADJ NOUN NOUN N...</td>\n",
       "      <td>GPE ORDINAL ORG PERSON DATE DATE DATE TIME PER...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Great cars are great art</td>\n",
       "      <td>want talk background idea car art actually mea...</td>\n",
       "      <td>VERB NOUN NOUN NOUN NOUN NOUN ADV ADJ NOUN NOU...</td>\n",
       "      <td>PERSON PRODUCT ORG ORG PERSON PERSON PERSON OR...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2323</th>\n",
       "      <td>Why glass towers are bad for city life -- and ...</td>\n",
       "      <td>imagine walk even discover everybody room look...</td>\n",
       "      <td>VERB NOUN ADV VERB PRON NOUN VERB ADV NOUN NOU...</td>\n",
       "      <td>ORG GPE ORG GPE GPE GPE GPE GPE GPE GPE GPE PE...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2324</th>\n",
       "      <td>What happens in your brain when you pay attent...</td>\n",
       "      <td>pay close attention easy attention pull differ...</td>\n",
       "      <td>VERB ADJ NOUN ADJ NOUN VERB ADJ NOUN NOUN NOUN...</td>\n",
       "      <td>ORDINAL PERSON PRODUCT DATE EVENT</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2325</th>\n",
       "      <td>Why you should define your fears instead of yo...</td>\n",
       "      <td>happy pic take senior college right dance prac...</td>\n",
       "      <td>ADJ PROPN VERB ADJ NOUN ADJ NOUN NOUN ADJ VERB...</td>\n",
       "      <td>DATE PERSON ORG PERSON PERSON GPE PERSON GPE O...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2326</th>\n",
       "      <td>12 truths I learned from life and writing</td>\n",
       "      <td>sevenyearold grandson sleep hall wake lot morn...</td>\n",
       "      <td>PROPN PROPN PROPN PROPN VERB NOUN NOUN VERB VE...</td>\n",
       "      <td>PERSON PERSON PERSON PERSON PERSON DATE CARDIN...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2327</th>\n",
       "      <td>How I built a jet suit</td>\n",
       "      <td>michael brown engineer innovator inventor insp...</td>\n",
       "      <td>PROPN PROPN PROPN PROPN PROPN PROPN PROPN NOUN...</td>\n",
       "      <td>PERSON DATE DATE PERSON GPE CARDINAL GPE GPE O...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2328 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               headline  \\\n",
       "0                           Averting the climate crisis   \n",
       "1                         Simple designs to save a life   \n",
       "2                         How to rebuild a broken state   \n",
       "3                  The real future of space exploration   \n",
       "4                              Great cars are great art   \n",
       "...                                                 ...   \n",
       "2323  Why glass towers are bad for city life -- and ...   \n",
       "2324  What happens in your brain when you pay attent...   \n",
       "2325  Why you should define your fears instead of yo...   \n",
       "2326          12 truths I learned from life and writing   \n",
       "2327                             How I built a jet suit   \n",
       "\n",
       "                                             transcript  \\\n",
       "0     thank chris truly great honor opportunity come...   \n",
       "1     term invention like tell tale favorite project...   \n",
       "2     public dewey long ago observe constitute discu...   \n",
       "3     want start say houston problem enter second ge...   \n",
       "4     want talk background idea car art actually mea...   \n",
       "...                                                 ...   \n",
       "2323  imagine walk even discover everybody room look...   \n",
       "2324  pay close attention easy attention pull differ...   \n",
       "2325  happy pic take senior college right dance prac...   \n",
       "2326  sevenyearold grandson sleep hall wake lot morn...   \n",
       "2327  michael brown engineer innovator inventor insp...   \n",
       "\n",
       "                                           pos_sequence  \\\n",
       "0     VERB PROPN ADV ADJ NOUN NOUN VERB NOUN ADV ADV...   \n",
       "1     NOUN NOUN SCONJ VERB PROPN ADJ NOUN VERB NOUN ...   \n",
       "2     ADJ PROPN ADV ADV VERB ADJ NOUN NOUN PROPN PRO...   \n",
       "3     VERB NOUN VERB PROPN NOUN VERB ADJ NOUN NOUN N...   \n",
       "4     VERB NOUN NOUN NOUN NOUN NOUN ADV ADJ NOUN NOU...   \n",
       "...                                                 ...   \n",
       "2323  VERB NOUN ADV VERB PRON NOUN VERB ADV NOUN NOU...   \n",
       "2324  VERB ADJ NOUN ADJ NOUN VERB ADJ NOUN NOUN NOUN...   \n",
       "2325  ADJ PROPN VERB ADJ NOUN ADJ NOUN NOUN ADJ VERB...   \n",
       "2326  PROPN PROPN PROPN PROPN VERB NOUN NOUN VERB VE...   \n",
       "2327  PROPN PROPN PROPN PROPN PROPN PROPN PROPN NOUN...   \n",
       "\n",
       "                                           ner_sequence  culture  politics  \\\n",
       "0     PERSON ORG ORG GPE LOC ORG PRODUCT GPE GPE PER...        1         1   \n",
       "1     GPE DATE CARDINAL DATE ORG PERSON LOC ORG GPE ...        0         0   \n",
       "2     DATE NORP ORDINAL DATE MONEY DATE DATE DATE EV...        1         1   \n",
       "3     GPE ORDINAL ORG PERSON DATE DATE DATE TIME PER...        0         0   \n",
       "4     PERSON PRODUCT ORG ORG PERSON PERSON PERSON OR...        0         0   \n",
       "...                                                 ...      ...       ...   \n",
       "2323  ORG GPE ORG GPE GPE GPE GPE GPE GPE GPE GPE PE...        1         0   \n",
       "2324                 ORDINAL PERSON PRODUCT DATE EVENT         0         0   \n",
       "2325  DATE PERSON ORG PERSON PERSON GPE PERSON GPE O...        1         0   \n",
       "2326  PERSON PERSON PERSON PERSON PERSON DATE CARDIN...        1         0   \n",
       "2327  PERSON DATE DATE PERSON GPE CARDINAL GPE GPE O...        1         0   \n",
       "\n",
       "      science  global issues  environment  technology  ...  education  \\\n",
       "0           1              1            1           1  ...          0   \n",
       "1           0              1            0           0  ...          0   \n",
       "2           0              1            0           0  ...          0   \n",
       "3           0              0            0           0  ...          0   \n",
       "4           0              0            0           1  ...          0   \n",
       "...       ...            ...          ...         ...  ...        ...   \n",
       "2323        0              0            0           0  ...          0   \n",
       "2324        1              0            0           1  ...          0   \n",
       "2325        0              0            0           0  ...          0   \n",
       "2326        0              0            0           0  ...          0   \n",
       "2327        0              0            0           1  ...          0   \n",
       "\n",
       "      history  future  communication  community  activism  children  brain  \\\n",
       "0           0       0              0          0         0         0      0   \n",
       "1           0       0              0          0         0         0      0   \n",
       "2           0       0              0          0         0         0      0   \n",
       "3           0       0              0          0         0         0      0   \n",
       "4           0       0              0          0         0         0      0   \n",
       "...       ...     ...            ...        ...       ...       ...    ...   \n",
       "2323        0       0              0          1         0         0      0   \n",
       "2324        0       0              0          0         0         0      1   \n",
       "2325        0       0              0          0         0         0      0   \n",
       "2326        0       0              1          0         0         0      0   \n",
       "2327        0       1              0          0         0         0      0   \n",
       "\n",
       "      humanity  life  \n",
       "0            0     0  \n",
       "1            0     0  \n",
       "2            0     0  \n",
       "3            0     0  \n",
       "4            0     0  \n",
       "...        ...   ...  \n",
       "2323         0     0  \n",
       "2324         0     0  \n",
       "2325         1     1  \n",
       "2326         1     0  \n",
       "2327         0     0  \n",
       "\n",
       "[2328 rows x 30 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = create_one_hot_encode()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target_column(target_tag, df=df):\n",
    "    return df[['headline', 'transcript','pos_sequence', 'ner_sequence', target_tag]]\n",
    "single_class = get_target_column('culture', df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_x = single_class[['transcript']]\n",
    "# df_y = df[['technology']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x = single_class[['headline', 'transcript','pos_sequence', 'ner_sequence']]\n",
    "df_y = list(single_class['culture'])\n",
    "#print(df_x[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Perform train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, train_y, valid_y = train_test_split(df_x, df_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from numpy import array\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Activation, Dropout, Dense\n",
    "from keras.layers import Flatten, LSTM, Conv1D, MaxPooling1D, concatenate\n",
    "from keras.layers import GlobalMaxPooling1D\n",
    "from keras.models import Model\n",
    "from keras.layers.embeddings import Embedding\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.layers import Input\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras import optimizers\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Use word embeddings for the main transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract train and test transcripts to list \n",
    "X_train_transcripts = X_train['transcript'].tolist()\n",
    "X_test_transcripts = X_test['transcript'].tolist()\n",
    "# Extract headline - we will use tfidf because headlines are short \n",
    "X_train_headline = X_train['headline'].tolist()\n",
    "X_test_headline = X_test['headline'].tolist()\n",
    "# Extract POS tags\n",
    "X_train_pos_seq= X_train['pos_sequence'].tolist()\n",
    "X_test_pos_seq = X_test['pos_sequence'].tolist()\n",
    "# Extract NER tags\n",
    "X_train_ner_seq = X_train['ner_sequence'].tolist()\n",
    "X_test_ner_seq = X_test['ner_sequence'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(X_train_transcripts)\n",
    "\n",
    "X_train_transcripts = tokenizer.texts_to_sequences(X_train_transcripts)\n",
    "X_test_transcripts = tokenizer.texts_to_sequences(X_test_transcripts)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "maxlen = 500 # since the average length is about there. Too long and the predicions are bad. we assume the intro has the most info\n",
    "\n",
    "X_train_transcripts = pad_sequences(X_train_transcripts, padding='post', maxlen=maxlen)\n",
    "X_test_transcripts = pad_sequences(X_test_transcripts, padding='post', maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from numpy import asarray\n",
    "from numpy import zeros\n",
    "\n",
    "embeddings_dictionary = dict()\n",
    "\n",
    "glove_file = open('./glove.6B.100d.txt', encoding=\"utf8\")\n",
    "\n",
    "for line in glove_file:\n",
    "    records = line.split()\n",
    "    word = records[0]\n",
    "    vector_dimensions = asarray(records[1:], dtype='float32')\n",
    "    embeddings_dictionary[word] = vector_dimensions\n",
    "glove_file.close()\n",
    "\n",
    "embedding_matrix = zeros((vocab_size, 100))\n",
    "for word, index in tokenizer.word_index.items():\n",
    "    embedding_vector = embeddings_dictionary.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[index] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 522 1149  522 4334  563 2710  139 1793  302 1793 1253  562    5   17\n",
      "    1  161   17    1   33  161   17  899  774  181  124   18 1349   35\n",
      "  444  444  159  262 1080  481   70 4109   53    6   46  283   58  513\n",
      "   36 1794    6    3  124  513  197   15   15  190   17   64    1   59\n",
      "  190  294 3242   42  767   40   88  283  139   34  130  446   12  829\n",
      "  283 1657   18   22 2738   59  124 1915  283 1915   59  273  604   26\n",
      "  833    3   15  167 1189  937  335   59  353   22  353  434  348    7\n",
      "  283  130  229  348 2500  622  280   15   65   65  283   58  513    4\n",
      "  305   64    1   59  124  106  124    1  448   42   11  438  261  276\n",
      "  492  261  276   43  527  124 1594  124    1  217   19  367  294 3242\n",
      "    4  367   48   59  192  112  447  124   48  244 1667  112 1914  124\n",
      "  229 1038    3   16 2059   87 1279  438  554   10  130  683  492   15\n",
      "   11   36  522 1636  841   17  522   90  683  492   15    3  284   79\n",
      "    5   42 1087  372  227 1087  372 2060  276    6  799  830  781 1843\n",
      "   59   17  228  747   42  372 2248  273  284  397  137  217 1081  392\n",
      " 2298 3544  228   59 2060  228  271  361  372 2738  124  284  522  522\n",
      "  284 3874   24  243  515   71    6   26   64 1362 2110   64    1   59\n",
      "   27  284 1989  290   24 1526  353  465  683  492   15  261    3  261\n",
      "  137 3875  307  115   42  261  302  261  261 2891  290  448  124  522\n",
      "   14  367    3 3597    4  217   17   10    5  747 1003  101  492 1441\n",
      "  392  255  201   17  415 2500  622  210   42  124  438  554   42  105\n",
      "  166 1023   22 2738  392   22   42   90  114  168 2689   91  517 4406\n",
      "  147  880  392  261  160  160   25  899  158    5  261 3652  261  261\n",
      " 3598  249   91  121 3598  132   18  299    7 1989 2738  392  217   17\n",
      " 2739 1177  392 3598  249  137   56  325  465  278  143   19 1038 1149\n",
      "  132 1038 1149 2948  133  438  261  139    8 1701   75  143   75  143\n",
      "   41  471   41 1795   21  511  905  124  367 2008  139  217  105   17\n",
      "   69    3   29   20   22 1637   23  373  124  605  401  605  401   29\n",
      "  182  209   10  539   55  217   48   17  449    1   22  159  438  261\n",
      "  554   53 1362 2110  623   53 1362 2110   48  168   55  276  152  346\n",
      "  244  244   32   64   59   90 1014  353  609 1689  124   63   73   20\n",
      "   10  553  101    1  990   59  124 2857 1494    1   21  265  228    1\n",
      "  186 1494    1 1417   59  124  899  447  142  555 2661 1459   67  124\n",
      "   67  305  359 2661   35   15  643   35   14   28  373  562   54  124\n",
      "   28   54  124  124  355  448   42   91  106  124   11  517   21  511\n",
      "  990  124  555    1   64    1   29   73   20   47]\n",
      "(1746, 500)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(X_train_transcripts[1])\n",
    "print(X_train_transcripts.shape)\n",
    "print(type(X_train_transcripts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(train_y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 tfidf the headline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidf_vect_pos = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=50)\n",
    "# tfidf_vect_pos.fit(X_train_headline)\n",
    "\n",
    "# xtrain_tfidf_headline =  tfidf_vect_pos.transform(X_train_headline)\n",
    "# xtest_tfidf_headline =  tfidf_vect_pos.transform(X_test_headline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(xtrain_tfidf_headline.shape)\n",
    "# print(xtest_tfidf_headline.shape)\n",
    "# print(xtrain_tfidf_headline[0])\n",
    "# print(type(xtrain_tfidf_headline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidf_vect_pos = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=5000)\n",
    "# tfidf_vect_pos.fit(df['pos_sequence'])\n",
    "# tfidf_vect_ner = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=5000)\n",
    "# tfidf_vect_ner.fit(df['ner_sequence'])\n",
    "\n",
    "# xtrain_tfidf_pos =  tfidf_vect_pos.transform(X_train['pos_sequence'])\n",
    "# xtest_tfidf_pos =  tfidf_vect_pos.transform(X_test['pos_sequence'])\n",
    "\n",
    "# xtrain_tfidf_ner =  tfidf_vect_ner.transform(X_train['ner_sequence'])\n",
    "# xtest_tfidf_ner =  tfidf_vect_ner.transform(X_test['ner_sequence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try word embeddings on the vector \n",
    "tokenizer2 = Tokenizer(num_words=100)\n",
    "tokenizer2.fit_on_texts(X_train_headline)\n",
    "\n",
    "X_train_headline = tokenizer.texts_to_sequences(X_train_headline)\n",
    "X_test_headline = tokenizer.texts_to_sequences(X_test_headline)\n",
    "\n",
    "vocab_size2 = len(tokenizer2.word_index) + 1\n",
    "\n",
    "maxlen2 = 100 # since the average length is about there. Too long and the predicions are bad. we assume the intro has the most info\n",
    "\n",
    "X_train_headline = pad_sequences(X_train_headline, padding='post', maxlen=maxlen2)\n",
    "X_test_headline = pad_sequences(X_test_headline, padding='post', maxlen=maxlen2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Glenn\\Anaconda3\\envs\\cds\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Glenn\\Anaconda3\\envs\\cds\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Glenn\\Anaconda3\\envs\\cds\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Glenn\\Anaconda3\\envs\\cds\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Glenn\\Anaconda3\\envs\\cds\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Glenn\\Anaconda3\\envs\\cds\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Glenn\\Anaconda3\\envs\\cds\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Glenn\\Anaconda3\\envs\\cds\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Glenn\\Anaconda3\\envs\\cds\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Glenn\\Anaconda3\\envs\\cds\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Glenn\\Anaconda3\\envs\\cds\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 100, 100)     4268300     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 500)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 96, 128)      64128       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 500, 100)     4268300     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_1 (GlobalM (None, 128)          0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 128)          117248      embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           1290        global_max_pooling1d_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 128)          0           lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 4)            44          dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 4)            516         dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 8)            0           dense_2[0][0]                    \n",
      "                                                                 dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 2)            18          concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 1)            3           dense_4[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 8,719,847\n",
      "Trainable params: 183,247\n",
      "Non-trainable params: 8,536,600\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:From C:\\Users\\Glenn\\Anaconda3\\envs\\cds\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Glenn\\Anaconda3\\envs\\cds\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Glenn\\Anaconda3\\envs\\cds\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import plot_model\n",
    "# define two sets of inputs\n",
    "inputA = Input(shape=(maxlen2,))\n",
    "inputB = Input(shape=(maxlen,))\n",
    " \n",
    "# the first branch operates on the first input which is the headline\n",
    "embedding_layer_hedline = Embedding(vocab_size, 100, weights=[embedding_matrix], trainable=False)(inputA) \n",
    "#model.add(layers.Embedding(vocab_size, embedding_dim, input_length=maxlen))\n",
    "#model.add(layers.Conv1D(128, 5, activation='relu'))\n",
    "x = Conv1D(128, 5, activation='relu')(embedding_layer_hedline)\n",
    "# model.add(layers.GlobalMaxPooling1D())\n",
    "x = GlobalMaxPooling1D()(x)\n",
    "x = Dense(10, activation='relu')(x)\n",
    "X = Dropout(0.2)(x)\n",
    "x = Dense(4, activation=\"relu\")(x)\n",
    "# model.add(layers.Dense(10, activation='relu'))\n",
    "# model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "# x = Dense(50, activation=\"relu\")(inputA)\n",
    "# x = Dense(4, activation=\"relu\")(x)\n",
    "x = Model(inputs=inputA, outputs=x)\n",
    " \n",
    "# the second branch opreates on the second input\n",
    "embedding_layer = Embedding(vocab_size, 100, weights=[embedding_matrix], trainable=False)(inputB)\n",
    "y = LSTM(128)(embedding_layer)\n",
    "y = Dropout(0.2)(y)\n",
    "y = Dense(4, activation='relu')(y)\n",
    "y = Model(inputs=inputB, outputs=y)\n",
    " \n",
    "# combine the output of the two branches\n",
    "combined = concatenate([x.output, y.output])\n",
    " \n",
    "# apply a FC layer and then a regression prediction on the\n",
    "# combined outputs\n",
    "z = Dense(2, activation=\"relu\")(combined)\n",
    "z = Dense(1, activation=\"sigmoid\")(z)\n",
    " \n",
    "# our model will accept the inputs of the two branches and\n",
    "# then output a single value\n",
    "model = Model(inputs=[x.input, y.input], outputs=z)\n",
    "print(model.summary())\n",
    "adam = optimizers.adam(lr=0.0001)\n",
    "#model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Glenn\\Anaconda3\\envs\\cds\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Glenn\\Anaconda3\\envs\\cds\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "Train on 1396 samples, validate on 350 samples\n",
      "Epoch 1/4\n",
      "1396/1396 [==============================] - 153s 110ms/step - loss: 0.6921 - acc: 0.5251 - val_loss: 0.6877 - val_acc: 0.5629\n",
      "Epoch 2/4\n",
      "1396/1396 [==============================] - 127s 91ms/step - loss: 0.6456 - acc: 0.6010 - val_loss: 0.7203 - val_acc: 0.5286\n",
      "Epoch 3/4\n",
      "1396/1396 [==============================] - 132s 94ms/step - loss: 0.5964 - acc: 0.6676 - val_loss: 0.6866 - val_acc: 0.5629\n",
      "Epoch 4/4\n",
      "1396/1396 [==============================] - 131s 94ms/step - loss: 0.5152 - acc: 0.7536 - val_loss: 0.8433 - val_acc: 0.5286\n"
     ]
    }
   ],
   "source": [
    "adam = optimizers.adam(lr=0.001)\n",
    "#model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['acc'])\n",
    "history = model.fit([X_train_headline, X_train_transcripts], train_y, batch_size=32, epochs=4, verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.utils import plot_model\n",
    "# # define two sets of inputs\n",
    "# inputA = Input(shape=(50,))\n",
    "# inputB = Input(shape=(maxlen,))\n",
    " \n",
    "# # the first branch operates on the first input\n",
    "# x = Dense(50, activation=\"relu\")(inputA)\n",
    "# x = Dense(4, activation=\"relu\")(x)\n",
    "# x = Model(inputs=inputA, outputs=x)\n",
    " \n",
    "# # the second branch opreates on the second input\n",
    "# embedding_layer = Embedding(vocab_size, 100, weights=[embedding_matrix], trainable=False)(inputB)\n",
    "# y = LSTM(128)(embedding_layer)\n",
    "# y = Dense(4, activation='sigmoid')(y)\n",
    "# y = Model(inputs=inputB, outputs=y)\n",
    " \n",
    "# # combine the output of the two branches\n",
    "# combined = concatenate([x.output, y.output])\n",
    " \n",
    "# # apply a FC layer and then a regression prediction on the\n",
    "# # combined outputs\n",
    "# z = Dense(2, activation=\"relu\")(combined)\n",
    "# z = Dense(1, activation=\"linear\")(z)\n",
    " \n",
    "# # our model will accept the inputs of the two branches and\n",
    "# # then output a single value\n",
    "# model = Model(inputs=[x.input, y.input], outputs=z)\n",
    "# print(model.summary())\n",
    "# adam = optimizers.adam(lr=0.0001)\n",
    "# #model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "# model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, to_file='model_plot_cnn.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adam = optimizers.adam(lr=0.0001)\n",
    "# #model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "# model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['acc'])\n",
    "# history = model.fit([xtrain_tfidf_headline, X_train_transcripts], train_y, batch_size=32, epochs=4, verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.utils import plot_model\n",
    "# plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deep_inputs = Input(shape=(maxlen,))\n",
    "# embedding_layer = Embedding(vocab_size, 100, weights=[embedding_matrix], trainable=False)(deep_inputs)\n",
    "# LSTM_Layer_1 = LSTM(128)(embedding_layer)\n",
    "# dense_layer_1 = Dense(1, activation='sigmoid')(LSTM_Layer_1)\n",
    "# model = Model(inputs=deep_inputs, outputs=dense_layer_1)\n",
    "\n",
    "# model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "# history = model.fit(X_train, train_y, batch_size=128, epochs=6, verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_glove = Sequential()\n",
    "# model_glove.add(Embedding(vocab_size, 100, input_length=3000, weights=[embedding_matrix], trainable=False))(Input(shape=(maxlen,)))\n",
    "# model_glove.add(Dropout(0.2))\n",
    "# model_glove.add(Conv1D(64, 5, activation='relu'))\n",
    "# model_glove.add(MaxPooling1D(pool_size=4))\n",
    "# model_glove.add(LSTM(100))\n",
    "# model_glove.add(Dense(1, activation='sigmoid'))\n",
    "# model_glove.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# ## Fit train data\n",
    "# model_glove.fit(X_train, np.array(train_y), validation_split=0.2, epochs = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict([X_test_headline, X_test_transcripts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0506216 ]\n",
      " [0.7015069 ]\n",
      " [0.771372  ]\n",
      " [0.7046806 ]\n",
      " [0.3308062 ]\n",
      " [0.54171705]\n",
      " [0.64751625]\n",
      " [0.17043173]\n",
      " [0.53182375]\n",
      " [0.15405098]\n",
      " [0.01686966]\n",
      " [0.6094669 ]\n",
      " [0.23457596]\n",
      " [0.7087351 ]\n",
      " [0.33083844]\n",
      " [0.53438133]\n",
      " [0.43729925]\n",
      " [0.30675387]\n",
      " [0.06718248]\n",
      " [0.19494626]\n",
      " [0.33276278]\n",
      " [0.7176246 ]\n",
      " [0.82287955]\n",
      " [0.56874925]\n",
      " [0.48245707]\n",
      " [0.7068858 ]\n",
      " [0.72965884]\n",
      " [0.05217862]\n",
      " [0.25651515]\n",
      " [0.15907162]\n",
      " [0.2775736 ]\n",
      " [0.7101451 ]\n",
      " [0.2170488 ]\n",
      " [0.2410909 ]\n",
      " [0.20428258]\n",
      " [0.46574804]\n",
      " [0.41968566]\n",
      " [0.50015247]\n",
      " [0.26167285]\n",
      " [0.4912542 ]\n",
      " [0.3446594 ]\n",
      " [0.08268791]\n",
      " [0.5118027 ]\n",
      " [0.11423931]\n",
      " [0.06188875]\n",
      " [0.5755898 ]\n",
      " [0.70481646]\n",
      " [0.38806266]\n",
      " [0.03264368]\n",
      " [0.25701624]\n",
      " [0.6536801 ]\n",
      " [0.27295253]\n",
      " [0.14607769]\n",
      " [0.7601503 ]\n",
      " [0.6367817 ]\n",
      " [0.4593596 ]\n",
      " [0.16319877]\n",
      " [0.12724057]\n",
      " [0.8519433 ]\n",
      " [0.16641438]\n",
      " [0.02178499]\n",
      " [0.25872493]\n",
      " [0.48524693]\n",
      " [0.5589116 ]\n",
      " [0.6263304 ]\n",
      " [0.4012768 ]\n",
      " [0.46574804]\n",
      " [0.48110595]\n",
      " [0.10224521]\n",
      " [0.4142361 ]\n",
      " [0.24237874]\n",
      " [0.28975278]\n",
      " [0.45862627]\n",
      " [0.4549885 ]\n",
      " [0.21870968]\n",
      " [0.46574804]\n",
      " [0.4523521 ]\n",
      " [0.32355493]\n",
      " [0.48157284]\n",
      " [0.69722533]\n",
      " [0.46574804]\n",
      " [0.78022325]\n",
      " [0.54829144]\n",
      " [0.6051637 ]\n",
      " [0.22524863]\n",
      " [0.18188357]\n",
      " [0.10656333]\n",
      " [0.03299692]\n",
      " [0.0443632 ]\n",
      " [0.6026155 ]\n",
      " [0.48677793]\n",
      " [0.5879632 ]\n",
      " [0.63680387]\n",
      " [0.42017516]\n",
      " [0.59488064]\n",
      " [0.07477373]\n",
      " [0.43808144]\n",
      " [0.46574804]\n",
      " [0.06358597]\n",
      " [0.13613147]\n",
      " [0.15345132]\n",
      " [0.47268745]\n",
      " [0.5364159 ]\n",
      " [0.625945  ]\n",
      " [0.34823057]\n",
      " [0.39694548]\n",
      " [0.16660395]\n",
      " [0.63379174]\n",
      " [0.61488444]\n",
      " [0.56977487]\n",
      " [0.62196684]\n",
      " [0.25922632]\n",
      " [0.37534925]\n",
      " [0.8494009 ]\n",
      " [0.13420758]\n",
      " [0.71822363]\n",
      " [0.25881797]\n",
      " [0.65482664]\n",
      " [0.7000495 ]\n",
      " [0.30070233]\n",
      " [0.7490411 ]\n",
      " [0.47907373]\n",
      " [0.41959605]\n",
      " [0.13127518]\n",
      " [0.40226978]\n",
      " [0.25560924]\n",
      " [0.10770234]\n",
      " [0.68000364]\n",
      " [0.45025733]\n",
      " [0.7109373 ]\n",
      " [0.46574804]\n",
      " [0.06156757]\n",
      " [0.6651509 ]\n",
      " [0.08573186]\n",
      " [0.3309387 ]\n",
      " [0.29147774]\n",
      " [0.6289941 ]\n",
      " [0.5642094 ]\n",
      " [0.3674913 ]\n",
      " [0.3654757 ]\n",
      " [0.4757183 ]\n",
      " [0.7080925 ]\n",
      " [0.7837175 ]\n",
      " [0.70418984]\n",
      " [0.36022034]\n",
      " [0.19972214]\n",
      " [0.05800614]\n",
      " [0.04227856]\n",
      " [0.31974083]\n",
      " [0.60807896]\n",
      " [0.5284256 ]\n",
      " [0.5455623 ]\n",
      " [0.48157284]\n",
      " [0.01135531]\n",
      " [0.45358074]\n",
      " [0.46574804]\n",
      " [0.5524962 ]\n",
      " [0.45978546]\n",
      " [0.34888193]\n",
      " [0.6482103 ]\n",
      " [0.7507643 ]\n",
      " [0.06784269]\n",
      " [0.16201165]\n",
      " [0.17888445]\n",
      " [0.58820647]\n",
      " [0.38988724]\n",
      " [0.84591943]\n",
      " [0.6745214 ]\n",
      " [0.38725737]\n",
      " [0.30139497]\n",
      " [0.44052315]\n",
      " [0.04186344]\n",
      " [0.07261863]\n",
      " [0.3916579 ]\n",
      " [0.21067989]\n",
      " [0.26946548]\n",
      " [0.51261854]\n",
      " [0.094374  ]\n",
      " [0.08153567]\n",
      " [0.69793713]\n",
      " [0.36022034]\n",
      " [0.26095247]\n",
      " [0.576816  ]\n",
      " [0.6553984 ]\n",
      " [0.10937482]\n",
      " [0.6068334 ]\n",
      " [0.38892782]\n",
      " [0.39460686]\n",
      " [0.12102732]\n",
      " [0.46574804]\n",
      " [0.7275819 ]\n",
      " [0.3363191 ]\n",
      " [0.03328747]\n",
      " [0.55118024]\n",
      " [0.21799234]\n",
      " [0.46574804]\n",
      " [0.47759506]\n",
      " [0.5317098 ]\n",
      " [0.81971556]\n",
      " [0.46574804]\n",
      " [0.03686118]\n",
      " [0.22085091]\n",
      " [0.7004455 ]\n",
      " [0.35831732]\n",
      " [0.6162452 ]\n",
      " [0.18069208]\n",
      " [0.4338484 ]\n",
      " [0.46375772]\n",
      " [0.16168869]\n",
      " [0.46574804]\n",
      " [0.0611203 ]\n",
      " [0.2878826 ]\n",
      " [0.45025733]\n",
      " [0.46541184]\n",
      " [0.38228375]\n",
      " [0.5118928 ]\n",
      " [0.7162045 ]\n",
      " [0.31909788]\n",
      " [0.49344665]\n",
      " [0.690802  ]\n",
      " [0.2576053 ]\n",
      " [0.3301614 ]\n",
      " [0.04796055]\n",
      " [0.5214363 ]\n",
      " [0.5026572 ]\n",
      " [0.6510693 ]\n",
      " [0.40527448]\n",
      " [0.6976495 ]\n",
      " [0.40475667]\n",
      " [0.79369414]\n",
      " [0.5413449 ]\n",
      " [0.46574804]\n",
      " [0.13534176]\n",
      " [0.4702271 ]\n",
      " [0.07746378]\n",
      " [0.14871183]\n",
      " [0.69053435]\n",
      " [0.4439057 ]\n",
      " [0.56041133]\n",
      " [0.1231119 ]\n",
      " [0.14123553]\n",
      " [0.6344037 ]\n",
      " [0.8700967 ]\n",
      " [0.15718132]\n",
      " [0.1003027 ]\n",
      " [0.32917482]\n",
      " [0.46574804]\n",
      " [0.66729337]\n",
      " [0.65984154]\n",
      " [0.57818764]\n",
      " [0.04601198]\n",
      " [0.34316087]\n",
      " [0.30093622]\n",
      " [0.37479347]\n",
      " [0.6714654 ]\n",
      " [0.7848669 ]\n",
      " [0.2851695 ]\n",
      " [0.33517766]\n",
      " [0.626008  ]\n",
      " [0.29720712]\n",
      " [0.10079142]\n",
      " [0.14028451]\n",
      " [0.096957  ]\n",
      " [0.3740999 ]\n",
      " [0.23134843]\n",
      " [0.5813271 ]\n",
      " [0.18976334]\n",
      " [0.08367214]\n",
      " [0.0953061 ]\n",
      " [0.46574804]\n",
      " [0.40847036]\n",
      " [0.4544678 ]\n",
      " [0.22255796]\n",
      " [0.35216993]\n",
      " [0.6017084 ]\n",
      " [0.2436054 ]\n",
      " [0.45181778]\n",
      " [0.49635944]\n",
      " [0.16028711]\n",
      " [0.25488943]\n",
      " [0.4978302 ]\n",
      " [0.5144209 ]\n",
      " [0.3010295 ]\n",
      " [0.15813392]\n",
      " [0.07457182]\n",
      " [0.29761916]\n",
      " [0.6562704 ]\n",
      " [0.49359614]\n",
      " [0.07092232]\n",
      " [0.1020548 ]\n",
      " [0.432482  ]\n",
      " [0.5117826 ]\n",
      " [0.6762249 ]\n",
      " [0.01516473]\n",
      " [0.13892674]\n",
      " [0.05473143]\n",
      " [0.05854094]\n",
      " [0.46574804]\n",
      " [0.01646855]\n",
      " [0.25344214]\n",
      " [0.09842348]\n",
      " [0.49364445]\n",
      " [0.38165092]\n",
      " [0.21214595]\n",
      " [0.46574804]\n",
      " [0.33806646]\n",
      " [0.09615093]\n",
      " [0.6243863 ]\n",
      " [0.0136556 ]\n",
      " [0.5353297 ]\n",
      " [0.44867167]\n",
      " [0.09600672]\n",
      " [0.6610155 ]\n",
      " [0.17123538]\n",
      " [0.48279047]\n",
      " [0.6761787 ]\n",
      " [0.16936448]\n",
      " [0.72069305]\n",
      " [0.09222424]\n",
      " [0.8129121 ]\n",
      " [0.6447343 ]\n",
      " [0.02433807]\n",
      " [0.5431157 ]\n",
      " [0.5345179 ]\n",
      " [0.45738196]\n",
      " [0.31784937]\n",
      " [0.48027074]\n",
      " [0.07666707]\n",
      " [0.5596372 ]\n",
      " [0.11314017]\n",
      " [0.59811294]\n",
      " [0.16064093]\n",
      " [0.60732275]\n",
      " [0.6438135 ]\n",
      " [0.6107853 ]\n",
      " [0.35216993]\n",
      " [0.83399224]\n",
      " [0.04010931]\n",
      " [0.02757537]\n",
      " [0.7180742 ]\n",
      " [0.2100282 ]\n",
      " [0.27385283]\n",
      " [0.6121601 ]\n",
      " [0.4686939 ]\n",
      " [0.27120405]\n",
      " [0.3119778 ]\n",
      " [0.4875701 ]\n",
      " [0.6894561 ]\n",
      " [0.659478  ]\n",
      " [0.31813505]\n",
      " [0.1450266 ]\n",
      " [0.46574804]\n",
      " [0.2853324 ]\n",
      " [0.71164185]\n",
      " [0.72615445]\n",
      " [0.37073973]\n",
      " [0.30780077]\n",
      " [0.53706086]\n",
      " [0.6204734 ]\n",
      " [0.37249458]\n",
      " [0.32828262]\n",
      " [0.36610842]\n",
      " [0.03237057]\n",
      " [0.53488874]\n",
      " [0.46574804]\n",
      " [0.16319877]\n",
      " [0.09732226]\n",
      " [0.14303541]\n",
      " [0.4364003 ]\n",
      " [0.1040695 ]\n",
      " [0.7611333 ]\n",
      " [0.6103517 ]\n",
      " [0.10759202]\n",
      " [0.04150563]\n",
      " [0.3419215 ]\n",
      " [0.55441475]\n",
      " [0.7120959 ]\n",
      " [0.46574804]\n",
      " [0.06104037]\n",
      " [0.05974948]\n",
      " [0.5465575 ]\n",
      " [0.53946596]\n",
      " [0.8082827 ]\n",
      " [0.35217   ]\n",
      " [0.08569568]\n",
      " [0.6664181 ]\n",
      " [0.03485775]\n",
      " [0.21374509]\n",
      " [0.14477295]\n",
      " [0.50169706]\n",
      " [0.4856181 ]\n",
      " [0.39316833]\n",
      " [0.43499917]\n",
      " [0.07775185]\n",
      " [0.16320786]\n",
      " [0.09675473]\n",
      " [0.5278161 ]\n",
      " [0.42604885]\n",
      " [0.20272627]\n",
      " [0.4428757 ]\n",
      " [0.6849333 ]\n",
      " [0.1804862 ]\n",
      " [0.55760103]\n",
      " [0.16533136]\n",
      " [0.06230202]\n",
      " [0.29018992]\n",
      " [0.33835143]\n",
      " [0.24408075]\n",
      " [0.20120367]\n",
      " [0.48279047]\n",
      " [0.7543211 ]\n",
      " [0.32394746]\n",
      " [0.10441506]\n",
      " [0.49299008]\n",
      " [0.6211854 ]\n",
      " [0.10727969]\n",
      " [0.1723918 ]\n",
      " [0.6026462 ]\n",
      " [0.2506758 ]\n",
      " [0.07339388]\n",
      " [0.01447237]\n",
      " [0.67699254]\n",
      " [0.49187696]\n",
      " [0.05082178]\n",
      " [0.46050942]\n",
      " [0.11930683]\n",
      " [0.32895815]\n",
      " [0.07212019]\n",
      " [0.48279047]\n",
      " [0.137963  ]\n",
      " [0.6907884 ]\n",
      " [0.16804582]\n",
      " [0.06058687]\n",
      " [0.2479325 ]\n",
      " [0.2368345 ]\n",
      " [0.4625835 ]\n",
      " [0.16240233]\n",
      " [0.31267738]\n",
      " [0.4347325 ]\n",
      " [0.141076  ]\n",
      " [0.29711685]\n",
      " [0.40681174]\n",
      " [0.36292362]\n",
      " [0.63294077]\n",
      " [0.1993067 ]\n",
      " [0.30257955]\n",
      " [0.611282  ]\n",
      " [0.4800948 ]\n",
      " [0.25939474]\n",
      " [0.36399898]\n",
      " [0.54518735]\n",
      " [0.6038526 ]\n",
      " [0.6423004 ]\n",
      " [0.16279042]\n",
      " [0.27941984]\n",
      " [0.37357396]\n",
      " [0.53660315]\n",
      " [0.16593757]\n",
      " [0.5827382 ]\n",
      " [0.51044357]\n",
      " [0.11392292]\n",
      " [0.7812319 ]\n",
      " [0.6245911 ]\n",
      " [0.46574804]\n",
      " [0.46043992]\n",
      " [0.54847634]\n",
      " [0.46574804]\n",
      " [0.4928437 ]\n",
      " [0.03358638]\n",
      " [0.04339638]\n",
      " [0.3615777 ]\n",
      " [0.01879838]\n",
      " [0.04221892]\n",
      " [0.2385895 ]\n",
      " [0.41544193]\n",
      " [0.08394396]\n",
      " [0.37915498]\n",
      " [0.64508164]\n",
      " [0.33075717]\n",
      " [0.0439651 ]\n",
      " [0.11779946]\n",
      " [0.1119321 ]\n",
      " [0.25355303]\n",
      " [0.20374769]\n",
      " [0.54880524]\n",
      " [0.17568207]\n",
      " [0.75310034]\n",
      " [0.4809219 ]\n",
      " [0.6191152 ]\n",
      " [0.36854088]\n",
      " [0.09626058]\n",
      " [0.3517335 ]\n",
      " [0.24668315]\n",
      " [0.46574804]\n",
      " [0.10883752]\n",
      " [0.46467552]\n",
      " [0.17069465]\n",
      " [0.03516194]\n",
      " [0.38988724]\n",
      " [0.46127784]\n",
      " [0.39287207]\n",
      " [0.45025733]\n",
      " [0.42064577]\n",
      " [0.07847041]\n",
      " [0.12045026]\n",
      " [0.52602184]\n",
      " [0.7621212 ]\n",
      " [0.03614259]\n",
      " [0.688139  ]\n",
      " [0.03273168]\n",
      " [0.23654622]\n",
      " [0.54898906]\n",
      " [0.57732475]\n",
      " [0.06561202]\n",
      " [0.08478245]\n",
      " [0.58359   ]\n",
      " [0.5158936 ]\n",
      " [0.45025733]\n",
      " [0.35832703]\n",
      " [0.7021827 ]\n",
      " [0.08713302]\n",
      " [0.6139792 ]\n",
      " [0.15234601]\n",
      " [0.60121995]\n",
      " [0.13988143]\n",
      " [0.66006774]\n",
      " [0.7006798 ]\n",
      " [0.37198538]\n",
      " [0.46574804]\n",
      " [0.58275557]\n",
      " [0.6333607 ]\n",
      " [0.40016487]\n",
      " [0.2858017 ]\n",
      " [0.41018975]\n",
      " [0.16593757]\n",
      " [0.13842365]\n",
      " [0.05114806]\n",
      " [0.10110682]\n",
      " [0.38496098]\n",
      " [0.46510312]\n",
      " [0.24507576]\n",
      " [0.05142838]\n",
      " [0.6212076 ]\n",
      " [0.34549695]\n",
      " [0.0699966 ]\n",
      " [0.14470771]\n",
      " [0.69178516]\n",
      " [0.63106537]\n",
      " [0.26585054]\n",
      " [0.06318131]\n",
      " [0.09994978]\n",
      " [0.61263824]\n",
      " [0.675205  ]\n",
      " [0.55897915]\n",
      " [0.4797487 ]\n",
      " [0.07495669]\n",
      " [0.33832294]\n",
      " [0.1317023 ]\n",
      " [0.9074923 ]\n",
      " [0.30996767]\n",
      " [0.24973291]\n",
      " [0.5007523 ]\n",
      " [0.68101156]\n",
      " [0.5894191 ]\n",
      " [0.07025069]\n",
      " [0.6359519 ]\n",
      " [0.34961158]\n",
      " [0.15961578]\n",
      " [0.05058968]\n",
      " [0.55983865]\n",
      " [0.42485738]\n",
      " [0.40527448]\n",
      " [0.6459045 ]\n",
      " [0.6991679 ]\n",
      " [0.69503057]\n",
      " [0.36548465]\n",
      " [0.56538373]\n",
      " [0.89437604]\n",
      " [0.254243  ]\n",
      " [0.14553231]\n",
      " [0.40512854]\n",
      " [0.31673458]]\n"
     ]
    }
   ],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tag(threshold, predictions=predictions):\n",
    "    return [[1 if j > threshold else 0 for j in i.tolist()] for i in predictions]\n",
    "\n",
    "def get_tag_flat(threshold, predictions=predictions):\n",
    "    return [1 if j > threshold else 0 for i in predictions for j in i]\n",
    "predictions_flushed = get_tag(0.4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_tp_tn_fp_fn(y_test, y_pred, classes):\n",
    "    '''\n",
    "    Return:\n",
    "    pre_score = {\n",
    "        'tag_1': {\n",
    "            'index': ,\n",
    "            'tp': ,\n",
    "            'tn': ,\n",
    "            'fp': ,\n",
    "            'fn': \n",
    "        }\n",
    "    }\n",
    "    '''\n",
    "    # Create dictionary of tags \n",
    "    pre_score = {}\n",
    "    for index_tag, tag in enumerate(classes):\n",
    "        pre_score[tag] = {\n",
    "            'index':index_tag,\n",
    "            'tp': 0,\n",
    "            'tn': 0,\n",
    "            'fp': 0,\n",
    "            'fn': 0\n",
    "        }\n",
    "    for transcript_index, transcript_value in enumerate(y_test):\n",
    "        if transcript_value == y_pred[transcript_index][0] and transcript_value == 1:\n",
    "            pre_score[classes[0]]['tp'] += 1\n",
    "        elif transcript_value == y_pred[transcript_index][0] and transcript_value == 0:\n",
    "            pre_score[classes[0]]['tn'] += 1\n",
    "        elif transcript_value != y_pred[transcript_index][0] and transcript_value == 1:\n",
    "            pre_score[classes[0]]['fn'] += 1\n",
    "        elif transcript_value != y_pred[transcript_index][0] and transcript_value == 0:\n",
    "            pre_score[classes[0]]['fp'] += 1\n",
    "    return pre_score\n",
    "scores_preprocess = compute_tp_tn_fp_fn(valid_y, predictions_flushed, ['culture'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'culture': {'index': 0, 'tp': 74, 'tn': 242, 'fp': 58, 'fn': 208, 'precision': 0.56, 'recall': 0.26, 'f1': 0.36}}\n"
     ]
    }
   ],
   "source": [
    "def compute_precision_recall_f1(preprocessed_scores):\n",
    "    for key, value in preprocessed_scores.items():\n",
    "        try:\n",
    "            precision = value['tp']/(value['tp']+value['fp'])\n",
    "        except:\n",
    "            print('precision issue: {}'.format(key))\n",
    "            precision = 0.0\n",
    "        try:\n",
    "            recall = value['tp']/(value['tp']+value['fn'])\n",
    "        except:\n",
    "            print('recall issue: {}'.format(key))\n",
    "            recall = 0.0\n",
    "        try:\n",
    "            f1 = (2 * precision * recall)/(precision + recall)\n",
    "        except:\n",
    "            print('f1 issue: {}'.format(key))\n",
    "            f1=0.0\n",
    "        preprocessed_scores[key]['precision'] = round(precision,2)\n",
    "        preprocessed_scores[key]['recall'] = round(recall,2)\n",
    "        preprocessed_scores[key]['f1'] = round(f1,2)\n",
    "    return preprocessed_scores\n",
    "final_scores = compute_precision_recall_f1(scores_preprocess)\n",
    "print(final_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_full_dataframe(x):\n",
    "    pd.set_option('display.max_rows', len(x))\n",
    "    print(x)\n",
    "    pd.reset_option('display.max_rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     class  precision  recall    f1  accuracy\n",
      "0  culture       0.56    0.26  0.36  0.542955\n"
     ]
    }
   ],
   "source": [
    "def format_scores_df(tag_classes, final_scores=final_scores):\n",
    "    precision = []\n",
    "    recall = []\n",
    "    f1 = []\n",
    "    accuracy = []\n",
    "    for index, value in enumerate(tag_classes):\n",
    "        precision.append(final_scores[value]['precision'])\n",
    "        recall.append(final_scores[value]['recall'])\n",
    "        f1.append(final_scores[value]['f1'])\n",
    "        accuracy.append((final_scores[value]['tp'] + final_scores[value]['tn'])/(final_scores[value]['tp'] + final_scores[value]['tn'] + final_scores[value]['fp'] + final_scores[value]['fn']))\n",
    "    df_result = pd.DataFrame(list(zip(tag_classes, precision, recall, f1, accuracy)), \n",
    "               columns =['class', 'precision', 'recall', 'f1', 'accuracy']) \n",
    "    return df_result\n",
    "df_results = format_scores_df(['culture'], final_scores)\n",
    "print_full_dataframe(df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3\n",
      "{'culture': {'index': 0, 'tp': 190, 'tn': 128, 'fp': 172, 'fn': 92, 'precision': 0.52, 'recall': 0.67, 'f1': 0.59}}\n",
      "     class  precision  recall    f1  accuracy\n",
      "0  culture       0.52    0.67  0.59  0.546392\n",
      "\n",
      "\n",
      "0.31\n",
      "{'culture': {'index': 0, 'tp': 187, 'tn': 133, 'fp': 167, 'fn': 95, 'precision': 0.53, 'recall': 0.66, 'f1': 0.59}}\n",
      "     class  precision  recall    f1  accuracy\n",
      "0  culture       0.53    0.66  0.59  0.549828\n",
      "\n",
      "\n",
      "0.32\n",
      "{'culture': {'index': 0, 'tp': 185, 'tn': 138, 'fp': 162, 'fn': 97, 'precision': 0.53, 'recall': 0.66, 'f1': 0.59}}\n",
      "     class  precision  recall    f1  accuracy\n",
      "0  culture       0.53    0.66  0.59  0.554983\n",
      "\n",
      "\n",
      "0.33\n",
      "{'culture': {'index': 0, 'tp': 183, 'tn': 141, 'fp': 159, 'fn': 99, 'precision': 0.54, 'recall': 0.65, 'f1': 0.59}}\n",
      "     class  precision  recall    f1  accuracy\n",
      "0  culture       0.54    0.65  0.59  0.556701\n",
      "\n",
      "\n",
      "0.34\n",
      "{'culture': {'index': 0, 'tp': 180, 'tn': 149, 'fp': 151, 'fn': 102, 'precision': 0.54, 'recall': 0.64, 'f1': 0.59}}\n",
      "     class  precision  recall    f1  accuracy\n",
      "0  culture       0.54    0.64  0.59  0.565292\n",
      "\n",
      "\n",
      "0.35\n",
      "{'culture': {'index': 0, 'tp': 178, 'tn': 154, 'fp': 146, 'fn': 104, 'precision': 0.55, 'recall': 0.63, 'f1': 0.59}}\n",
      "     class  precision  recall    f1  accuracy\n",
      "0  culture       0.55    0.63  0.59  0.570447\n",
      "\n",
      "\n",
      "0.36\n",
      "{'culture': {'index': 0, 'tp': 176, 'tn': 158, 'fp': 142, 'fn': 106, 'precision': 0.55, 'recall': 0.62, 'f1': 0.59}}\n",
      "     class  precision  recall    f1  accuracy\n",
      "0  culture       0.55    0.62  0.59  0.573883\n",
      "\n",
      "\n",
      "0.37\n",
      "{'culture': {'index': 0, 'tp': 171, 'tn': 163, 'fp': 137, 'fn': 111, 'precision': 0.56, 'recall': 0.61, 'f1': 0.58}}\n",
      "     class  precision  recall    f1  accuracy\n",
      "0  culture       0.56    0.61  0.58  0.573883\n",
      "\n",
      "\n",
      "0.38\n",
      "{'culture': {'index': 0, 'tp': 170, 'tn': 170, 'fp': 130, 'fn': 112, 'precision': 0.57, 'recall': 0.6, 'f1': 0.58}}\n",
      "     class  precision  recall    f1  accuracy\n",
      "0  culture       0.57     0.6  0.58  0.584192\n",
      "\n",
      "\n",
      "0.39\n",
      "{'culture': {'index': 0, 'tp': 167, 'tn': 175, 'fp': 125, 'fn': 115, 'precision': 0.57, 'recall': 0.59, 'f1': 0.58}}\n",
      "     class  precision  recall    f1  accuracy\n",
      "0  culture       0.57    0.59  0.58  0.587629\n",
      "\n",
      "\n",
      "0.4\n",
      "{'culture': {'index': 0, 'tp': 163, 'tn': 176, 'fp': 124, 'fn': 119, 'precision': 0.57, 'recall': 0.58, 'f1': 0.57}}\n",
      "     class  precision  recall    f1  accuracy\n",
      "0  culture       0.57    0.58  0.57  0.582474\n",
      "\n",
      "\n",
      "0.41\n",
      "{'culture': {'index': 0, 'tp': 159, 'tn': 181, 'fp': 119, 'fn': 123, 'precision': 0.57, 'recall': 0.56, 'f1': 0.57}}\n",
      "     class  precision  recall    f1  accuracy\n",
      "0  culture       0.57    0.56  0.57  0.584192\n",
      "\n",
      "\n",
      "0.42\n",
      "{'culture': {'index': 0, 'tp': 155, 'tn': 182, 'fp': 118, 'fn': 127, 'precision': 0.57, 'recall': 0.55, 'f1': 0.56}}\n",
      "     class  precision  recall    f1  accuracy\n",
      "0  culture       0.57    0.55  0.56  0.579038\n",
      "\n",
      "\n",
      "0.43\n",
      "{'culture': {'index': 0, 'tp': 153, 'tn': 184, 'fp': 116, 'fn': 129, 'precision': 0.57, 'recall': 0.54, 'f1': 0.56}}\n",
      "     class  precision  recall    f1  accuracy\n",
      "0  culture       0.57    0.54  0.56  0.579038\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(30, 44):\n",
    "    i = i/100\n",
    "    print(i)\n",
    "    predictions_flushed = get_tag(i)\n",
    "    scores_preprocess = compute_tp_tn_fp_fn(valid_y, predictions_flushed, ['culture'])\n",
    "    final_scores = compute_precision_recall_f1(scores_preprocess)\n",
    "    print(final_scores)\n",
    "    df_results = format_scores_df(['culture'], final_scores)\n",
    "    print(df_results)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "def evaluate_on_training_set(y_test, y_pred):\n",
    "  # Calculate AUC\n",
    "  print(\"AUC is: \", roc_auc_score(y_test, y_pred))\n",
    "  # print out recall and precision\n",
    "  print(classification_report(y_test, y_pred))\n",
    "  # print out confusion matrix\n",
    "  print(\"Confusion Matrix: \\n\", confusion_matrix(y_test, y_pred))\n",
    "  # # calculate points for ROC curve\n",
    "  fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "  # Plot ROC curve\n",
    "  plt.plot(fpr, tpr, label='ROC curve (area = %0.3f)' % roc_auc_score(y_test, y_pred)) \n",
    "  plt.plot([0, 1], [0, 1], 'k--') # random predictions curve\n",
    "  plt.xlim([0.0, 1.0])\n",
    "  plt.ylim([0.0, 1.0])\n",
    "  plt.xlabel('False Positive Rate or (1 - Specifity)')\n",
    "  plt.ylabel('True Positive Rate or (Sensitivity)')\n",
    "  plt.title('Receiver Operating Characteristic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC is:  0.5823404255319149\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.59      0.59       300\n",
      "           1       0.57      0.58      0.57       282\n",
      "\n",
      "    accuracy                           0.58       582\n",
      "   macro avg       0.58      0.58      0.58       582\n",
      "weighted avg       0.58      0.58      0.58       582\n",
      "\n",
      "Confusion Matrix: \n",
      " [[176 124]\n",
      " [119 163]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluate_on_training_set(valid_y, get_tag_flat(0.4))\n",
    "#print(valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
