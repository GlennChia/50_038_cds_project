{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. References\n",
    "\n",
    "Title: Multi-Label Text Classification Using Scikit-multilearn: a Case Study with StackOverflow Questions\n",
    "\n",
    "Link: https://medium.com/towards-artificial-intelligence/multi-label-text-classification-using-scikit-multilearn-case-study-with-stackoverflow-questions-768cb487ad12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA_DIR = \"../../data/raw/\"\n",
    "DATA_DIR = \"../../data/processed/\"\n",
    "#INPUT_FILE_NAME = 'cleaned.parquet'\n",
    "INPUT_FILE_NAME = 'cleaned_squashed1.parquet'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker</th>\n",
       "      <th>headline</th>\n",
       "      <th>description</th>\n",
       "      <th>duration</th>\n",
       "      <th>tags</th>\n",
       "      <th>transcript</th>\n",
       "      <th>WC</th>\n",
       "      <th>clean_transcript</th>\n",
       "      <th>clean_transcript_string</th>\n",
       "      <th>squash_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Al Gore</td>\n",
       "      <td>Averting the climate crisis</td>\n",
       "      <td>With the same humor and humanity he exuded in ...</td>\n",
       "      <td>0:16:17</td>\n",
       "      <td>cars,alternative energy,culture,politics,scien...</td>\n",
       "      <td>0:14\\r\\r\\rThank you so much, Chris.\\rAnd it's ...</td>\n",
       "      <td>2281.0</td>\n",
       "      <td>[thank, chris, truly, great, honor, opportunit...</td>\n",
       "      <td>thank chris truly great honor opportunity come...</td>\n",
       "      <td>culture,politics,science,climate change,enviro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Amy Smith</td>\n",
       "      <td>Simple designs to save a life</td>\n",
       "      <td>Fumes from indoor cooking fires kill more than...</td>\n",
       "      <td>0:15:06</td>\n",
       "      <td>MacArthur grant,simplicity,industrial design,a...</td>\n",
       "      <td>0:11\\r\\r\\rIn terms of invention,\\rI'd like to ...</td>\n",
       "      <td>2687.0</td>\n",
       "      <td>[term, invention, like, tell, tale, favorite, ...</td>\n",
       "      <td>term invention like tell tale favorite project...</td>\n",
       "      <td>invention,engineering,design,global issues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ashraf Ghani</td>\n",
       "      <td>How to rebuild a broken state</td>\n",
       "      <td>Ashraf Ghani's passionate and powerful 10-minu...</td>\n",
       "      <td>0:18:45</td>\n",
       "      <td>corruption,poverty,economics,investment,milita...</td>\n",
       "      <td>0:12\\r\\r\\rA public, Dewey long ago observed,\\r...</td>\n",
       "      <td>2506.0</td>\n",
       "      <td>[public, dewey, long, ago, observe, constitute...</td>\n",
       "      <td>public dewey long ago observe constitute discu...</td>\n",
       "      <td>poverty,economics,culture,politics,policy,glob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Burt Rutan</td>\n",
       "      <td>The real future of space exploration</td>\n",
       "      <td>In this passionate talk, legendary spacecraft ...</td>\n",
       "      <td>0:19:37</td>\n",
       "      <td>aircraft,flight,industrial design,NASA,rocket ...</td>\n",
       "      <td>0:11\\r\\r\\rI want to start off by saying, Houst...</td>\n",
       "      <td>3092.0</td>\n",
       "      <td>[want, start, say, houston, problem, enter, se...</td>\n",
       "      <td>want start say houston problem enter second ge...</td>\n",
       "      <td>invention,engineering,entrepreneur,design,busi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chris Bangle</td>\n",
       "      <td>Great cars are great art</td>\n",
       "      <td>American designer Chris Bangle explains his ph...</td>\n",
       "      <td>0:20:04</td>\n",
       "      <td>cars,industrial design,transportation,inventio...</td>\n",
       "      <td>0:12\\r\\r\\rWhat I want to talk about is, as bac...</td>\n",
       "      <td>3781.0</td>\n",
       "      <td>[want, talk, background, idea, car, art, actua...</td>\n",
       "      <td>want talk background idea car art actually mea...</td>\n",
       "      <td>invention,design,technology,business,art</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        speaker                              headline  \\\n",
       "0       Al Gore           Averting the climate crisis   \n",
       "1     Amy Smith         Simple designs to save a life   \n",
       "2  Ashraf Ghani         How to rebuild a broken state   \n",
       "3    Burt Rutan  The real future of space exploration   \n",
       "4  Chris Bangle              Great cars are great art   \n",
       "\n",
       "                                         description duration  \\\n",
       "0  With the same humor and humanity he exuded in ...  0:16:17   \n",
       "1  Fumes from indoor cooking fires kill more than...  0:15:06   \n",
       "2  Ashraf Ghani's passionate and powerful 10-minu...  0:18:45   \n",
       "3  In this passionate talk, legendary spacecraft ...  0:19:37   \n",
       "4  American designer Chris Bangle explains his ph...  0:20:04   \n",
       "\n",
       "                                                tags  \\\n",
       "0  cars,alternative energy,culture,politics,scien...   \n",
       "1  MacArthur grant,simplicity,industrial design,a...   \n",
       "2  corruption,poverty,economics,investment,milita...   \n",
       "3  aircraft,flight,industrial design,NASA,rocket ...   \n",
       "4  cars,industrial design,transportation,inventio...   \n",
       "\n",
       "                                          transcript      WC  \\\n",
       "0  0:14\\r\\r\\rThank you so much, Chris.\\rAnd it's ...  2281.0   \n",
       "1  0:11\\r\\r\\rIn terms of invention,\\rI'd like to ...  2687.0   \n",
       "2  0:12\\r\\r\\rA public, Dewey long ago observed,\\r...  2506.0   \n",
       "3  0:11\\r\\r\\rI want to start off by saying, Houst...  3092.0   \n",
       "4  0:12\\r\\r\\rWhat I want to talk about is, as bac...  3781.0   \n",
       "\n",
       "                                    clean_transcript  \\\n",
       "0  [thank, chris, truly, great, honor, opportunit...   \n",
       "1  [term, invention, like, tell, tale, favorite, ...   \n",
       "2  [public, dewey, long, ago, observe, constitute...   \n",
       "3  [want, start, say, houston, problem, enter, se...   \n",
       "4  [want, talk, background, idea, car, art, actua...   \n",
       "\n",
       "                             clean_transcript_string  \\\n",
       "0  thank chris truly great honor opportunity come...   \n",
       "1  term invention like tell tale favorite project...   \n",
       "2  public dewey long ago observe constitute discu...   \n",
       "3  want start say houston problem enter second ge...   \n",
       "4  want talk background idea car art actually mea...   \n",
       "\n",
       "                                         squash_tags  \n",
       "0  culture,politics,science,climate change,enviro...  \n",
       "1         invention,engineering,design,global issues  \n",
       "2  poverty,economics,culture,politics,policy,glob...  \n",
       "3  invention,engineering,entrepreneur,design,busi...  \n",
       "4           invention,design,technology,business,art  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet(DATA_DIR + INPUT_FILE_NAME)\n",
    "# df = df[:200]  # same as df.head(10)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2382 entries, 0 to 2381\n",
      "Data columns (total 10 columns):\n",
      "speaker                    2378 non-null object\n",
      "headline                   2378 non-null object\n",
      "description                2378 non-null object\n",
      "duration                   2378 non-null object\n",
      "tags                       2378 non-null object\n",
      "transcript                 2378 non-null object\n",
      "WC                         2378 non-null float64\n",
      "clean_transcript           2378 non-null object\n",
      "clean_transcript_string    2378 non-null object\n",
      "squash_tags                2378 non-null object\n",
      "dtypes: float64(1), object(9)\n",
      "memory usage: 204.7+ KB\n"
     ]
    }
   ],
   "source": [
    "# df = df[:150]\n",
    "# print(df)\n",
    "# Temp delete\n",
    "df.iloc[:,:10].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2378 entries, 0 to 2377\n",
      "Data columns (total 10 columns):\n",
      "speaker                    2378 non-null object\n",
      "headline                   2378 non-null object\n",
      "description                2378 non-null object\n",
      "duration                   2378 non-null object\n",
      "tags                       2378 non-null object\n",
      "transcript                 2378 non-null object\n",
      "WC                         2378 non-null float64\n",
      "clean_transcript           2378 non-null object\n",
      "clean_transcript_string    2378 non-null object\n",
      "squash_tags                2378 non-null object\n",
      "dtypes: float64(1), object(9)\n",
      "memory usage: 185.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df = df.dropna(subset=['squash_tags'])\n",
    "df = df.reset_index(drop=True)\n",
    "df.iloc[:,:10].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      squash_tags  counts  no_count     ratio  overall_ratio\n",
      "0      technology     693      1685  0.411276       0.291421\n",
      "1         science     522      1856  0.281250       0.219512\n",
      "2   global issues     483      1895  0.254881       0.203112\n",
      "3         culture     470      1908  0.246331       0.197645\n",
      "4          design     399      1979  0.201617       0.167788\n",
      "..            ...     ...       ...       ...            ...\n",
      "95        illness      50      2328  0.021478       0.021026\n",
      "96      parenting      49      2329  0.021039       0.020606\n",
      "97         policy      49      2329  0.021039       0.020606\n",
      "98         family      48      2330  0.020601       0.020185\n",
      "99      adventure      47      2331  0.020163       0.019765\n",
      "\n",
      "[100 rows x 5 columns]\n",
      "           squash_tags  counts  no_count     ratio  overall_ratio\n",
      "0           technology     693      1685  0.411276       0.291421\n",
      "1              science     522      1856  0.281250       0.219512\n",
      "2        global issues     483      1895  0.254881       0.203112\n",
      "3              culture     470      1908  0.246331       0.197645\n",
      "4               design     399      1979  0.201617       0.167788\n",
      "5             business     329      2049  0.160566       0.138352\n",
      "6        entertainment     285      2093  0.136168       0.119849\n",
      "7               health     226      2152  0.105019       0.095038\n",
      "8           innovation     211      2167  0.097370       0.088730\n",
      "9            education     206      2172  0.094843       0.086627\n",
      "10                 art     203      2175  0.093333       0.085366\n",
      "11             society     201      2177  0.092329       0.084525\n",
      "12       social change     198      2180  0.090826       0.083263\n",
      "13       communication     184      2194  0.083865       0.077376\n",
      "14            politics     183      2195  0.083371       0.076955\n",
      "15              future     180      2198  0.081893       0.075694\n",
      "16          creativity     174      2204  0.078947       0.073171\n",
      "17             biology     174      2204  0.078947       0.073171\n",
      "18            humanity     162      2216  0.073105       0.068124\n",
      "19       collaboration     162      2216  0.073105       0.068124\n",
      "20         environment     155      2223  0.069726       0.065181\n",
      "21            medicine     154      2224  0.069245       0.064760\n",
      "22           economics     154      2224  0.069245       0.064760\n",
      "23            activism     147      2231  0.065890       0.061817\n",
      "24               brain     147      2231  0.065890       0.061817\n",
      "25           community     136      2242  0.060660       0.057191\n",
      "26            children     135      2243  0.060187       0.056770\n",
      "27             history     135      2243  0.060187       0.056770\n",
      "28           invention     135      2243  0.060187       0.056770\n",
      "29         health care     130      2248  0.057829       0.054668\n",
      "30               music     119      2259  0.052678       0.050042\n",
      "31               women     115      2263  0.050817       0.048360\n",
      "32              cities     113      2265  0.049890       0.047519\n",
      "33        storytelling     112      2266  0.049426       0.047098\n",
      "34             animals     108      2270  0.047577       0.045416\n",
      "35                 war     108      2270  0.047577       0.045416\n",
      "36          leadership     107      2271  0.047116       0.044996\n",
      "37            identity     106      2272  0.046655       0.044575\n",
      "38              nature     106      2272  0.046655       0.044575\n",
      "39         engineering     106      2272  0.046655       0.044575\n",
      "40           computers     105      2273  0.046194       0.044155\n",
      "41          psychology     104      2274  0.045734       0.043734\n",
      "42               humor      99      2279  0.043440       0.041632\n",
      "43         performance      98      2280  0.042982       0.041211\n",
      "44                life      98      2280  0.042982       0.041211\n",
      "45         exploration      96      2282  0.042068       0.040370\n",
      "46              africa      94      2284  0.041156       0.039529\n",
      "47                data      89      2289  0.038882       0.037426\n",
      "48         photography      88      2290  0.038428       0.037006\n",
      "49    medical research      86      2292  0.037522       0.036165\n",
      "50          inequality      86      2292  0.037522       0.036165\n",
      "51          government      83      2295  0.036166       0.034903\n",
      "52     personal growth      83      2295  0.036166       0.034903\n",
      "53        neuroscience      83      2295  0.036166       0.034903\n",
      "54      climate change      81      2297  0.035263       0.034062\n",
      "55      visualizations      80      2298  0.034813       0.033642\n",
      "56            internet      77      2301  0.033464       0.032380\n",
      "57        architecture      76      2302  0.033015       0.031960\n",
      "58      sustainability      74      2304  0.032118       0.031119\n",
      "59              oceans      73      2305  0.031670       0.030698\n",
      "60             disease      72      2306  0.031223       0.030278\n",
      "61               green      71      2307  0.030776       0.029857\n",
      "62           happiness      71      2307  0.030776       0.029857\n",
      "63             biotech      70      2308  0.030329       0.029437\n",
      "64           potential      69      2309  0.029883       0.029016\n",
      "65                work      68      2310  0.029437       0.028595\n",
      "66             physics      67      2311  0.028992       0.028175\n",
      "67               media      66      2312  0.028547       0.027754\n",
      "68                film      66      2312  0.028547       0.027754\n",
      "69            violence      65      2313  0.028102       0.027334\n",
      "70                mind      64      2314  0.027658       0.026913\n",
      "71           evolution      64      2314  0.027658       0.026913\n",
      "72        big problems      63      2315  0.027214       0.026493\n",
      "73             writing      61      2317  0.026327       0.025652\n",
      "74        biodiversity      60      2318  0.025884       0.025231\n",
      "75          motivation      60      2318  0.025884       0.025231\n",
      "76          philosophy      60      2318  0.025884       0.025231\n",
      "77          live music      60      2318  0.025884       0.025231\n",
      "78            genetics      59      2319  0.025442       0.024811\n",
      "79        entrepreneur      59      2319  0.025442       0.024811\n",
      "80  global development      58      2320  0.025000       0.024390\n",
      "81       mental health      58      2320  0.025000       0.024390\n",
      "82            language      58      2320  0.025000       0.024390\n",
      "83               space      56      2322  0.024117       0.023549\n",
      "84              robots      55      2323  0.023676       0.023129\n",
      "85              beauty      55      2323  0.023676       0.023129\n",
      "86                food      55      2323  0.023676       0.023129\n",
      "87   cognitive science      54      2324  0.023236       0.022708\n",
      "88                math      53      2325  0.022796       0.022288\n",
      "89               peace      52      2326  0.022356       0.021867\n",
      "90             ecology      52      2326  0.022356       0.021867\n",
      "91            religion      52      2326  0.022356       0.021867\n",
      "92             poverty      51      2327  0.021917       0.021447\n",
      "93                demo      51      2327  0.021917       0.021447\n",
      "94              energy      51      2327  0.021917       0.021447\n",
      "95             illness      50      2328  0.021478       0.021026\n",
      "96           parenting      49      2329  0.021039       0.020606\n",
      "97              policy      49      2329  0.021039       0.020606\n",
      "98              family      48      2330  0.020601       0.020185\n",
      "99           adventure      47      2331  0.020163       0.019765\n"
     ]
    }
   ],
   "source": [
    "def print_full_dataframe(x):\n",
    "    pd.set_option('display.max_rows', len(x))\n",
    "    print(x)\n",
    "    pd.reset_option('display.max_rows')\n",
    "    \n",
    "def compute_tag_ratio(target_column, df=df):\n",
    "    tags = df[target_column].str.replace(', ',',').str.lower().str.strip()\n",
    "    split_tags = tags.str.split(',')\n",
    "    tag_counts_per_talk = split_tags.apply(len)\n",
    "\n",
    "    joined_tags = tags.str.cat(sep=',').split(',')\n",
    "    all_tags = pd.Series(joined_tags)\n",
    "\n",
    "    tag_counts = all_tags.value_counts().rename_axis(target_column).reset_index(name='counts')\n",
    "    tag_counts['no_count'] = len(df)-tag_counts['counts']\n",
    "    tag_counts['ratio'] = tag_counts['counts']/tag_counts['no_count']\n",
    "    tag_counts['overall_ratio'] = tag_counts['counts']/(tag_counts['no_count'] + tag_counts['counts'])\n",
    "    return tag_counts\n",
    "\n",
    "print(compute_tag_ratio('squash_tags', df))\n",
    "squashed_tag_counts = compute_tag_ratio('squash_tags', df)\n",
    "print_full_dataframe(squashed_tag_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x = df[['headline', 'clean_transcript_string']]\n",
    "df_y = df[['squash_tags']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "Empty DataFrame\n",
      "Columns: [squash_tags]\n",
      "Index: []\n",
      "speaker                                                      Janine Shepherd\n",
      "headline                                 A broken body isn't a broken person\n",
      "description                Cross-country skier Janine Shepherd hoped for ...\n",
      "duration                                                             0:18:57\n",
      "tags                       body language,health,health care,TEDx,storytel...\n",
      "transcript                 0:11\\r\\r\\rLife is about opportunities \\rcreati...\n",
      "WC                                                                      3091\n",
      "clean_transcript           [life, opportunity, create, embrace, olympic, ...\n",
      "clean_transcript_string    life opportunity create embrace olympic dream ...\n",
      "squash_tags                         health,health care,storytelling,identity\n",
      "Name: 1307, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df_y.isnull().values.any())\n",
    "print(df_y[df_y['squash_tags'].isnull()])\n",
    "print(df.iloc[1307])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "y = []\n",
    "for index, row in df_y.iterrows():\n",
    "    y.append(set(row['squash_tags'].split(',')))\n",
    "    \n",
    "mlb = MultiLabelBinarizer()\n",
    "encoded_y = mlb.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0]\n",
      "100\n",
      "[('climate change', 'culture', 'environment', 'global issues', 'politics', 'science', 'sustainability', 'technology'), ('design', 'engineering', 'global issues', 'invention'), ('business', 'culture', 'economics', 'entrepreneur', 'global development', 'global issues', 'policy', 'politics', 'poverty'), ('business', 'design', 'engineering', 'entrepreneur', 'invention'), ('art', 'business', 'design', 'invention', 'technology'), ('biodiversity', 'biology', 'biotech', 'ecology', 'entrepreneur', 'genetics', 'invention', 'oceans', 'science', 'technology'), ('computers', 'entertainment', 'media', 'music', 'performance', 'technology'), ('architecture', 'cities', 'collaboration', 'culture', 'design'), ('business', 'education', 'innovation', 'invention', 'robots', 'science', 'social change', 'sustainability', 'technology'), ('culture', 'disease', 'food', 'global issues', 'health', 'health care', 'science')]\n"
     ]
    }
   ],
   "source": [
    "print(encoded_y[0])\n",
    "print(len(encoded_y[0]))\n",
    "print(mlb.inverse_transform(encoded_y)[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import TaggedDocument, Doc2Vec\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn import utils as skl_utils\n",
    "from tqdm import tqdm\n",
    "\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "\n",
    "from gensim import utils\n",
    "import gensim.parsing.preprocessing as gsp\n",
    "\n",
    "filters = [\n",
    "           gsp.strip_tags, \n",
    "           gsp.strip_punctuation,\n",
    "           gsp.strip_multiple_whitespaces,\n",
    "           gsp.strip_numeric,\n",
    "           gsp.remove_stopwords, \n",
    "           gsp.strip_short, \n",
    "           gsp.stem_text\n",
    "          ]\n",
    "\n",
    "def clean_text(s):\n",
    "    s = s.lower()\n",
    "    s = utils.to_unicode(s)\n",
    "    for f in filters:\n",
    "        s = f(s)\n",
    "    return s\n",
    "\n",
    "class Doc2VecTransformer(BaseEstimator):\n",
    "\n",
    "    def __init__(self, vector_size=100, learning_rate=0.02, epochs=20, field=None):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self._model = None\n",
    "        self.vector_size = vector_size\n",
    "        self.workers = multiprocessing.cpu_count() - 1\n",
    "        self.field = field\n",
    "\n",
    "    def fit(self, df_x, df_y=None):\n",
    "        tagged_x = [TaggedDocument(clean_text(row[str(self.field)]).split(), [index]) for index, row in df_x.iterrows()]\n",
    "        model = Doc2Vec(documents=tagged_x, vector_size=self.vector_size, workers=self.workers)\n",
    "\n",
    "        for epoch in range(self.epochs):\n",
    "            model.train(skl_utils.shuffle([x for x in tqdm(tagged_x)]), total_examples=len(tagged_x), epochs=1)\n",
    "            model.alpha -= self.learning_rate\n",
    "            model.min_alpha = model.alpha\n",
    "\n",
    "        self._model = model\n",
    "        return self\n",
    "\n",
    "    def transform(self, df_x):\n",
    "        return np.asmatrix(np.array([self._model.infer_vector(clean_text(row[str(self.field)]).split())\n",
    "                                     for index, row in df_x.iterrows()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_x, test_x, train_y, test_y = train_test_split(df_x, encoded_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "fu = FeatureUnion(transformer_list=[('title_doc2vec',Doc2VecTransformer(field='headline')),\n",
    "                                    ('body_doc2vec',Doc2VecTransformer(field='clean_transcript_string'))])\n",
    "binary_rel_model = BinaryRelevance(RandomForestClassifier(n_jobs=-1, n_estimators=10))\n",
    "\n",
    "multi_label_rf_br_model = Pipeline(steps=[\n",
    "                           ('feature_union', fu),\n",
    "                           ('binary_relevance', binary_rel_model)\n",
    "                        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics\n",
    "\n",
    "def hamming_loss(multi_label_model_pipeline,train_x, train_y, test_x, test_y):\n",
    "    predictions_test_y = multi_label_model_pipeline.predict(test_x)\n",
    "    return metrics.hamming_loss(y_true=test_y, y_pred=predictions_test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1789/1789 [00:00<00:00, 2151881.23it/s]\n",
      "100%|██████████| 1789/1789 [00:00<00:00, 2439405.02it/s]\n",
      "100%|██████████| 1789/1789 [00:00<00:00, 2280039.46it/s]\n",
      "100%|██████████| 1789/1789 [00:00<00:00, 3079035.64it/s]\n",
      "100%|██████████| 1789/1789 [00:00<00:00, 3148808.16it/s]\n",
      "100%|██████████| 1789/1789 [00:00<00:00, 2388163.54it/s]\n",
      "100%|██████████| 1789/1789 [00:00<00:00, 2461814.26it/s]\n",
      "100%|██████████| 1789/1789 [00:00<00:00, 2787373.65it/s]\n",
      "100%|██████████| 1789/1789 [00:00<00:00, 2019270.68it/s]\n",
      "100%|██████████| 1789/1789 [00:00<00:00, 1988764.87it/s]\n",
      "100%|██████████| 1789/1789 [00:00<00:00, 2590131.12it/s]\n",
      "100%|██████████| 1789/1789 [00:00<00:00, 2247935.85it/s]\n",
      "100%|██████████| 1789/1789 [00:00<00:00, 2776030.28it/s]\n",
      "100%|██████████| 1789/1789 [00:00<00:00, 979200.03it/s]\n",
      "100%|██████████| 1789/1789 [00:00<00:00, 2790483.40it/s]\n",
      "100%|██████████| 1789/1789 [00:00<00:00, 2181281.93it/s]\n",
      "100%|██████████| 1789/1789 [00:00<00:00, 2536717.33it/s]\n",
      "100%|██████████| 1789/1789 [00:00<00:00, 2726602.42it/s]\n",
      "100%|██████████| 1789/1789 [00:00<00:00, 1509780.66it/s]\n",
      "100%|██████████| 1789/1789 [00:00<00:00, 2862880.52it/s]\n",
      "100%|██████████| 1789/1789 [00:00<00:00, 2076836.38it/s]\n",
      "100%|██████████| 1789/1789 [00:00<00:00, 2067679.76it/s]\n",
      "100%|██████████| 1789/1789 [00:00<00:00, 2146955.61it/s]\n",
      "100%|██████████| 1789/1789 [00:00<00:00, 2041243.16it/s]\n",
      "100%|██████████| 1789/1789 [00:00<00:00, 2818786.57it/s]\n",
      "100%|██████████| 1789/1789 [00:00<00:00, 2487934.30it/s]\n",
      "100%|██████████| 1789/1789 [00:00<00:00, 2446563.37it/s]\n",
      "100%|██████████| 1789/1789 [00:00<00:00, 1439955.83it/s]\n",
      "100%|██████████| 1789/1789 [00:00<00:00, 2525617.59it/s]\n",
      "100%|██████████| 1789/1789 [00:00<00:00, 2757666.25it/s]\n",
      "100%|██████████| 1789/1789 [00:00<00:00, 2860697.62it/s]\n",
      "100%|██████████| 1789/1789 [00:00<00:00, 2430712.62it/s]\n",
      "100%|██████████| 1789/1789 [00:00<00:00, 1813780.48it/s]\n",
      "100%|██████████| 1789/1789 [00:00<00:00, 2122061.61it/s]\n",
      "100%|██████████| 1789/1789 [00:00<00:00, 2737544.64it/s]\n",
      "100%|██████████| 1789/1789 [00:00<00:00, 2225929.95it/s]\n",
      "100%|██████████| 1789/1789 [00:00<00:00, 2021991.34it/s]\n",
      "100%|██████████| 1789/1789 [00:00<00:00, 2437028.21it/s]\n",
      "100%|██████████| 1789/1789 [00:00<00:00, 2408863.52it/s]\n",
      "100%|██████████| 1789/1789 [00:00<00:00, 1914186.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming loss for test data : 0.03740303004781823\n"
     ]
    }
   ],
   "source": [
    "multi_label_rf_br_model.fit(train_x, train_y)\n",
    "print('Hamming loss for test data :', hamming_loss(multi_label_rf_br_model,train_x,train_y,test_x,test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "predictions_test_y = multi_label_rf_br_model.predict(test_x)\n",
    "print(predictions_test_y.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n103  want year opportunity close conference incredi...  \\n31   think podium bite scar chris ask tell structur...  \\n41   music music end end hi sirena year old connect...  \\n93   thank get story arrive plane long journey west...  \\n152  go try view world problem opportunity face ask...  \\n2    public dewey long ago observe constitute discu...  \\n154                                              music  \\n124  consider storyteller tell story usual way sens...  \\n94 \\n'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(predictions_test_y.toarray()[-3])\n",
    "# print(encoded_y[154])\n",
    "# print(mlb.inverse_transform(predictions_test_y.toarray()))\n",
    "print(test_y[27])\n",
    "'''\n",
    "103  want year opportunity close conference incredi...  \n",
    "31   think podium bite scar chris ask tell structur...  \n",
    "41   music music end end hi sirena year old connect...  \n",
    "93   thank get story arrive plane long journey west...  \n",
    "152  go try view world problem opportunity face ask...  \n",
    "2    public dewey long ago observe constitute discu...  \n",
    "154                                              music  \n",
    "124  consider storyteller tell story usual way sens...  \n",
    "94 \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "('design', 'green', 'sustainability')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('technology',)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = -1\n",
    "print(test_y[index])\n",
    "print(mlb.inverse_transform(test_y)[index])\n",
    "mlb.inverse_transform(predictions_test_y)[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['clean_transcript_string']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, encoded_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# Trying to fix onevsrest param forwarding\n",
    "\n",
    "class OVR(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, clf=None):\n",
    "        self.clf = OneVsRestClassifier(clf())\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        if self.clf is not None:\n",
    "            self.clf.fit(X, y)\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.clf.predict(X)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        return self.clf.predict_proba(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On why we need to use estimator__ as name\n",
    "\n",
    "https://stackoverflow.com/questions/12632992/gridsearch-for-an-estimator-inside-a-onevsrestclassifier/12637528#12637528"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set grid search params\n",
    "\n",
    "# param_range = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "param_range = [1, 2, 3, 4, 5]\n",
    "param_range_fl = [1.0, 0.5, 0.1]\n",
    "\n",
    "cv_grid_params = [{'vectorizer__min_df': np.linspace(0.005, 0.05, 5),\n",
    "                   'vectorizer__ngram_range': ((1, 1),(1, 2))\n",
    "                  }] # Not implemened yet\n",
    "\n",
    "tfidf_grid_params = [] # Not implemented yet\n",
    "\n",
    "lr_grid_params = [{'clf__estimator__penalty': ['l1', 'l2'],\n",
    "                   'clf__estimator__C': param_range_fl,\n",
    "                   'clf__estimator__solver': ['liblinear']\n",
    "                  }] \n",
    "\n",
    "rf_grid_params = [{'clf__estimator__criterion': ['gini', 'entropy'],\n",
    "                   'clf__estimator__min_samples_leaf': param_range,\n",
    "                   'clf__estimator__max_depth': param_range,\n",
    "                   'clf__estimator__min_samples_split': param_range[1:],\n",
    "                   'clf__estimator__n_estimators': [10]\n",
    "                  }]\n",
    "\n",
    "svm_grid_params = [{'clf__estimator__kernel': ['linear', 'rbf'], \n",
    "                    'clf__estimator__C': param_range, # np.logspace(-1, 2, 10),\n",
    "                    'clf__estimator__gamma': ['auto'], # np.logspace(-1, 1, 10)\n",
    "                    'clf__estimator__probability': [True]\n",
    "                   }]\n",
    "\n",
    "mnb_grid_params = []\n",
    "\n",
    "scoring = 'accuracy'\n",
    "folds = 5\n",
    "njobs = -1\n",
    "\n",
    "\n",
    "# Instantiate vectorizer and desired models\n",
    "\n",
    "# OVR\n",
    "    ## logistic regression\n",
    "cv_lr_ovr = Pipeline([('vectorizer', CountVectorizer()),\n",
    "                      ('clf', OneVsRestClassifier(LogisticRegression()))\n",
    "                     ]\n",
    "                    )\n",
    "gs_cv_lr_ovr = GridSearchCV(estimator=cv_lr_ovr,\n",
    "                            param_grid=lr_grid_params,\n",
    "                            scoring=scoring,\n",
    "                            cv=folds) \n",
    "\n",
    "\n",
    "tfidf_lr_ovr = Pipeline([('vectorizer', TfidfVectorizer()),\n",
    "                        ('clf', OneVsRestClassifier(LogisticRegression()))\n",
    "                       ]\n",
    "                      )\n",
    "gs_tfidf_lr_ovr = GridSearchCV(estimator=tfidf_lr_ovr,\n",
    "                               param_grid=lr_grid_params,\n",
    "                               scoring=scoring,\n",
    "                               cv=folds) \n",
    "\n",
    "\n",
    "    ## random forest\n",
    "# cv_rf_ovr = Pipeline([('vectorizer', CountVectorizer()),\n",
    "#                       ('clf', OVR(RandomForestClassifier()))\n",
    "#                      ]\n",
    "#                     )\n",
    "cv_rf_ovr = Pipeline([('vectorizer', CountVectorizer()),\n",
    "                      ('clf', OneVsRestClassifier(RandomForestClassifier()))\n",
    "                     ]\n",
    "                    )\n",
    "gs_cv_rf_ovr = GridSearchCV(estimator=cv_rf_ovr,\n",
    "                            param_grid=rf_grid_params,\n",
    "                            scoring=scoring,\n",
    "                            cv=folds, \n",
    "                            n_jobs=njobs)\n",
    "\n",
    "\n",
    "# tfidf_rf_ovr = Pipeline([('vectorizer', TfidfVectorizer()),\n",
    "#                         ('clf', OVR(RandomForestClassifier()))\n",
    "#                        ]\n",
    "#                       )\n",
    "tfidf_rf_ovr = Pipeline([('vectorizer', TfidfVectorizer()),\n",
    "                        ('clf', OneVsRestClassifier(RandomForestClassifier()))\n",
    "                       ]\n",
    "                      )\n",
    "gs_tfidf_rf_ovr = GridSearchCV(estimator=tfidf_rf_ovr,\n",
    "                               param_grid=rf_grid_params,\n",
    "                               scoring=scoring,\n",
    "                               cv=folds, \n",
    "                               n_jobs=njobs)\n",
    "\n",
    "\n",
    "    ## support vector classifier\n",
    "cv_svm_ovr = Pipeline([('vectorizer', CountVectorizer()),\n",
    "                       ('clf', OneVsRestClassifier(SVC()))\n",
    "                      ]\n",
    "                     )\n",
    "gs_cv_svm_ovr = GridSearchCV(estimator=cv_svm_ovr,\n",
    "                             param_grid=svm_grid_params,\n",
    "                             scoring=scoring,\n",
    "                             cv=folds,\n",
    "                             n_jobs=njobs)\n",
    "\n",
    "\n",
    "tfidf_svm_ovr = Pipeline([('vectorizer', TfidfVectorizer()),\n",
    "                          ('clf', OneVsRestClassifier(SVC()))\n",
    "                         ]\n",
    "                        )\n",
    "gs_tfidf_svm_ovr = GridSearchCV(estimator=tfidf_svm_ovr,\n",
    "                                param_grid=svm_grid_params,\n",
    "                                scoring=scoring,\n",
    "                                cv=folds,\n",
    "                                n_jobs=njobs)\n",
    "\n",
    "\n",
    "    ## multinomial naive bayes\n",
    "cv_mnb_ovr = Pipeline([('vectorizer', CountVectorizer()),\n",
    "                       ('clf', OneVsRestClassifier(MultinomialNB()))\n",
    "                      ]\n",
    "                     )\n",
    "gs_cv_svm_ovr = GridSearchCV(estimator=cv_mnb_ovr,\n",
    "                             param_grid=mnb_grid_params,\n",
    "                             scoring=scoring,\n",
    "                             cv=folds,\n",
    "                             n_jobs=njobs)\n",
    "\n",
    "\n",
    "tfidf_mnb_ovr = Pipeline([('vectorizer', TfidfVectorizer()),\n",
    "                          ('clf', OneVsRestClassifier(MultinomialNB()))\n",
    "                         ]\n",
    "                        )\n",
    "gs_tfidf_mnb_ovr = GridSearchCV(estimator=tfidf_mnb_ovr,\n",
    "                                param_grid=mnb_grid_params,\n",
    "                                scoring=scoring,\n",
    "                                cv=folds,\n",
    "                                n_jobs=njobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This style might be more efficient, \n",
    "http://scikit.ml/api/skmultilearn.problem_transform.br.html\n",
    "\n",
    "https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "\n",
    "http://scikit.ml/stratification.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: \n",
    "# 1. Check if TfidfTransformer use_idf=False is the same as Countvectorizer? or there are other metrics to suppress\n",
    "# 2. Get scoring function to work, hamming? -- kinda done\n",
    "# 3. Balanced class labels\n",
    "\n",
    "# Binaryrelevance\n",
    "\n",
    "# param_range = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "param_range = [1, 2, 3, 4, 5]\n",
    "param_range_lr = [1.0, 0.5, 0.1]\n",
    "\n",
    "# Set params, comment out as see fit\n",
    "\n",
    "vectorizer_params = {\n",
    "#     'vectorizer__min_df': np.linspace(0.005, 0.05, 5),\n",
    "#     'vectorizer__ngram_range': [(1, 1), (1, 2)], # This shit blows up your memory\n",
    "#     'tfidf__norm': ('l1', 'l2'),\n",
    "    'tfidf__use_idf': [True, False],\n",
    "}\n",
    "\n",
    "lr_params = {\n",
    "    'clf__classifier': [LogisticRegression()],\n",
    "        'clf__classifier__penalty': ['l1', 'l2'],\n",
    "        'clf__classifier__C': param_range_lr,\n",
    "        'clf__classifier__solver': ['liblinear']\n",
    "}\n",
    "\n",
    "svc_params = {\n",
    "    'clf__classifier': [SVC()],\n",
    "        'clf__classifier__kernel': ['linear', 'rbf'],\n",
    "        'clf__classifier__C': param_range, # np.logspace(-1, 2, 10),\n",
    "        'clf__classifier__gamma': ['auto'], # np.logspace(-1, 1, 10)\n",
    "        'clf__classifier__probability': [True],\n",
    "}\n",
    "\n",
    "rf_params = {\n",
    "    'clf__classifier': [RandomForestClassifier()],\n",
    "        'clf__classifier__criterion': ['gini', 'entropy'],\n",
    "        'clf__classifier__min_samples_leaf': param_range,\n",
    "        'clf__classifier__max_depth': param_range,\n",
    "        'clf__classifier__min_samples_split': param_range[1:],\n",
    "        'clf__classifier__n_estimators': [10],\n",
    "}\n",
    "\n",
    "mnb_params = {\n",
    "    'clf__classifier': [MultinomialNB()],\n",
    "        'clf__classifier__alpha': [0.7, 1.0],\n",
    "}\n",
    "\n",
    "## Stack params\n",
    "parameters = [\n",
    "#     {**vectorizer_params, **lr_params},\n",
    "#     {**vectorizer_params, **svc_params},\n",
    "#     {**vectorizer_params, **rf_params},\n",
    "    {**vectorizer_params, **mnb_params}\n",
    "]\n",
    "\n",
    "br_pipeline = Pipeline([('vectorizer', CountVectorizer()),\n",
    "                        ('tfidf', TfidfTransformer()),\n",
    "                        ('clf', BinaryRelevance()),\n",
    "#                         ('clf', OneVsRestClassifier()),\n",
    "                       ]\n",
    "                      )\n",
    "\n",
    "# Gridsearch settings\n",
    "# scoring = make_scorer(f1_score, average='micro') # possible scorings 'f1_micro' 'f1_macro'\n",
    "# scoring = 'f1_micro'\n",
    "scoring = make_scorer(hamming_loss)\n",
    "folds = 3\n",
    "njobs = -1\n",
    "\n",
    "model = GridSearchCV(br_pipeline, parameters, scoring=scoring, cv=folds, n_jobs=njobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train,y_train)\n",
    "print (model.best_params_, model.best_score_)\n",
    "pd.DataFrame(model.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipelines = [cv_lr_ovr, tfidf_lr_ovr, \n",
    "#              cv_rf_ovr, tfidf_rf_ovr, \n",
    "#              cv_svm_ovr, tfidf_svm_ovr]\n",
    "\n",
    "# pipelines = [cv_rf_ovr, tfidf_rf_ovr]\n",
    "pipelines = [cv_lr_ovr, tfidf_lr_ovr]\n",
    "# grids = [gs_cv_lr_ovr, gs_tfidf_lr_ovr,\n",
    "#          gs_cv_rf_ovr, gs_tfidf_rf_ovr,\n",
    "#          gs_cv_svm_ovr, gs_tfidf_svm_ovr]\n",
    "grids = [gs_cv_lr_ovr, gs_tfidf_lr_ovr]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beware the next line\n",
    "\n",
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 14min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# for pipe in pipelines:\n",
    "#     pipe.fit(X_train, y_train)\n",
    "\n",
    "for model in grids:\n",
    "    model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 pipeline test accuracy: 0.386\n",
      "1 pipeline test accuracy: 0.389\n"
     ]
    }
   ],
   "source": [
    "for idx, clf in enumerate(grids):\n",
    "    y_pred_prob = clf.predict_proba(X_test)\n",
    "    t = 0.1 # threshold value\n",
    "    y_pred_new = (y_pred_prob >= t).astype(int)\n",
    "    scoring = f1_score(y_test, y_pred_new, average=\"micro\")\n",
    "    print('%s pipeline test accuracy: %.3f' % (idx, scoring))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ai',\n",
       " 'computers',\n",
       " 'culture',\n",
       " 'entertainment',\n",
       " 'future',\n",
       " 'global issues',\n",
       " 'humanity',\n",
       " 'innovation',\n",
       " 'intelligence',\n",
       " 'science',\n",
       " 'technology',\n",
       " 'tedx')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlb.inverse_transform(y_pred_new)[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_acc = 0.0\n",
    "best_clf = 0\n",
    "best_pipe = ''\n",
    "for idx, clf in enumerate(pipelines):\n",
    "    if clf.score(X_test, y_test) > best_acc:\n",
    "        best_acc = clf.score(X_test, y_test)\n",
    "        best_pipe = clf\n",
    "print(f'Classifier with best accuracy: {best_pipe.named_steps} \\n with accuracy of {best_acc}')\n",
    "# joblib.dump(best_pipe, 'best_classifier.pkl', compress=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 1, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 1, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('education', 'family', 'global issues', 'women')\n",
      "('activism', 'children', 'culture', 'education', 'entertainment', 'family', 'global issues', 'humanity', 'inequality', 'parenting', 'social change', 'women')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['activism',\n",
       " 'adventure',\n",
       " 'africa',\n",
       " 'animals',\n",
       " 'architecture',\n",
       " 'art',\n",
       " 'beauty',\n",
       " 'big problems',\n",
       " 'biodiversity',\n",
       " 'biology',\n",
       " 'biotech',\n",
       " 'brain',\n",
       " 'business',\n",
       " 'children',\n",
       " 'cities',\n",
       " 'climate change',\n",
       " 'cognitive science',\n",
       " 'collaboration',\n",
       " 'communication',\n",
       " 'community',\n",
       " 'computers',\n",
       " 'creativity',\n",
       " 'culture',\n",
       " 'data',\n",
       " 'demo',\n",
       " 'design',\n",
       " 'disease',\n",
       " 'ecology',\n",
       " 'economics',\n",
       " 'education',\n",
       " 'energy',\n",
       " 'engineering',\n",
       " 'entertainment',\n",
       " 'entrepreneur',\n",
       " 'environment',\n",
       " 'evolution',\n",
       " 'exploration',\n",
       " 'family',\n",
       " 'film',\n",
       " 'food',\n",
       " 'future',\n",
       " 'genetics',\n",
       " 'global development',\n",
       " 'global issues',\n",
       " 'government',\n",
       " 'green',\n",
       " 'happiness',\n",
       " 'health',\n",
       " 'health care',\n",
       " 'history',\n",
       " 'humanity',\n",
       " 'humor',\n",
       " 'identity',\n",
       " 'illness',\n",
       " 'inequality',\n",
       " 'innovation',\n",
       " 'internet',\n",
       " 'invention',\n",
       " 'language',\n",
       " 'leadership',\n",
       " 'life',\n",
       " 'live music',\n",
       " 'math',\n",
       " 'media',\n",
       " 'medical research',\n",
       " 'medicine',\n",
       " 'mental health',\n",
       " 'mind',\n",
       " 'motivation',\n",
       " 'music',\n",
       " 'nature',\n",
       " 'neuroscience',\n",
       " 'oceans',\n",
       " 'parenting',\n",
       " 'peace',\n",
       " 'performance',\n",
       " 'personal growth',\n",
       " 'philosophy',\n",
       " 'photography',\n",
       " 'physics',\n",
       " 'policy',\n",
       " 'politics',\n",
       " 'potential',\n",
       " 'poverty',\n",
       " 'psychology',\n",
       " 'religion',\n",
       " 'robots',\n",
       " 'science',\n",
       " 'social change',\n",
       " 'society',\n",
       " 'space',\n",
       " 'storytelling',\n",
       " 'sustainability',\n",
       " 'technology',\n",
       " 'violence',\n",
       " 'visualizations',\n",
       " 'war',\n",
       " 'women',\n",
       " 'work',\n",
       " 'writing']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(mlb.inverse_transform(y_test)[2])\n",
    "print(mlb.inverse_transform(y_pred_new)[2])\n",
    "list(mlb.classes_) # So that we can map back the precision, recall and F1 to each tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_tp_tn_fp_fn(y_test, y_pred, classes):\n",
    "    '''\n",
    "    Return:\n",
    "    pre_score = {\n",
    "        'tag_1': {\n",
    "            'index': ,\n",
    "            'tp': ,\n",
    "            'tn': ,\n",
    "            'fp': ,\n",
    "            'fn': \n",
    "        }\n",
    "    }\n",
    "    '''\n",
    "    # Create dictionary of tags \n",
    "    pre_score = {}\n",
    "    for index_tag, tag in enumerate(classes):\n",
    "        pre_score[tag] = {\n",
    "            'index':index_tag,\n",
    "            'tp': 0,\n",
    "            'tn': 0,\n",
    "            'fp': 0,\n",
    "            'fn': 0\n",
    "        }\n",
    "    for transcript_index, transcript_value in enumerate(y_test):\n",
    "        for tag_index, tag_value_test in enumerate(transcript_value):\n",
    "            if tag_value_test == y_pred[transcript_index][tag_index] and tag_value_test == 1:\n",
    "                pre_score[classes[tag_index]]['tp'] += 1\n",
    "            elif tag_value_test == y_pred[transcript_index][tag_index] and tag_value_test == 0:\n",
    "                pre_score[classes[tag_index]]['tn'] += 1\n",
    "            elif tag_value_test != y_pred[transcript_index][tag_index] and tag_value_test == 1:\n",
    "                pre_score[classes[tag_index]]['fn'] += 1\n",
    "            elif tag_value_test != y_pred[transcript_index][tag_index] and tag_value_test == 0:\n",
    "                pre_score[classes[tag_index]]['fp'] += 1\n",
    "    return pre_score\n",
    "scores_preprocess = compute_tp_tn_fp_fn(y_test, y_pred_new, mlb.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activism': {'index': 0, 'tp': 2, 'tn': 534, 'fp': 26, 'fn': 33}, 'adventure': {'index': 1, 'tp': 0, 'tn': 587, 'fp': 1, 'fn': 7}, 'africa': {'index': 2, 'tp': 13, 'tn': 563, 'fp': 7, 'fn': 12}, 'animals': {'index': 3, 'tp': 15, 'tn': 546, 'fp': 19, 'fn': 15}, 'architecture': {'index': 4, 'tp': 7, 'tn': 566, 'fp': 12, 'fn': 10}, 'art': {'index': 5, 'tp': 37, 'tn': 499, 'fp': 46, 'fn': 13}, 'beauty': {'index': 6, 'tp': 0, 'tn': 581, 'fp': 1, 'fn': 13}, 'big problems': {'index': 7, 'tp': 2, 'tn': 582, 'fp': 2, 'fn': 9}, 'biodiversity': {'index': 8, 'tp': 5, 'tn': 569, 'fp': 8, 'fn': 13}, 'biology': {'index': 9, 'tp': 37, 'tn': 497, 'fp': 47, 'fn': 14}, 'biotech': {'index': 10, 'tp': 6, 'tn': 564, 'fp': 7, 'fn': 18}, 'brain': {'index': 11, 'tp': 29, 'tn': 533, 'fp': 19, 'fn': 14}, 'business': {'index': 12, 'tp': 54, 'tn': 356, 'fp': 173, 'fn': 12}, 'children': {'index': 13, 'tp': 14, 'tn': 534, 'fp': 31, 'fn': 16}, 'cities': {'index': 14, 'tp': 15, 'tn': 558, 'fp': 13, 'fn': 9}, 'climate change': {'index': 15, 'tp': 4, 'tn': 571, 'fp': 9, 'fn': 11}, 'cognitive science': {'index': 16, 'tp': 4, 'tn': 569, 'fp': 12, 'fn': 10}, 'collaboration': {'index': 17, 'tp': 3, 'tn': 533, 'fp': 18, 'fn': 41}, 'communication': {'index': 18, 'tp': 16, 'tn': 504, 'fp': 49, 'fn': 26}, 'community': {'index': 19, 'tp': 6, 'tn': 543, 'fp': 21, 'fn': 25}, 'computers': {'index': 20, 'tp': 8, 'tn': 552, 'fp': 19, 'fn': 16}, 'creativity': {'index': 21, 'tp': 15, 'tn': 504, 'fp': 47, 'fn': 29}, 'culture': {'index': 22, 'tp': 134, 'tn': 9, 'fp': 450, 'fn': 2}, 'data': {'index': 23, 'tp': 5, 'tn': 562, 'fp': 14, 'fn': 14}, 'demo': {'index': 24, 'tp': 0, 'tn': 580, 'fp': 0, 'fn': 15}, 'design': {'index': 25, 'tp': 96, 'tn': 248, 'fp': 241, 'fn': 10}, 'disease': {'index': 26, 'tp': 8, 'tn': 560, 'fp': 11, 'fn': 16}, 'ecology': {'index': 27, 'tp': 3, 'tn': 579, 'fp': 4, 'fn': 9}, 'economics': {'index': 28, 'tp': 22, 'tn': 515, 'fp': 49, 'fn': 9}, 'education': {'index': 29, 'tp': 35, 'tn': 511, 'fp': 32, 'fn': 17}, 'energy': {'index': 30, 'tp': 9, 'tn': 579, 'fp': 2, 'fn': 5}, 'engineering': {'index': 31, 'tp': 6, 'tn': 551, 'fp': 21, 'fn': 17}, 'entertainment': {'index': 32, 'tp': 57, 'tn': 336, 'fp': 190, 'fn': 12}, 'entrepreneur': {'index': 33, 'tp': 1, 'tn': 577, 'fp': 0, 'fn': 17}, 'environment': {'index': 34, 'tp': 22, 'tn': 517, 'fp': 42, 'fn': 14}, 'evolution': {'index': 35, 'tp': 6, 'tn': 569, 'fp': 6, 'fn': 14}, 'exploration': {'index': 36, 'tp': 4, 'tn': 564, 'fp': 12, 'fn': 15}, 'family': {'index': 37, 'tp': 2, 'tn': 582, 'fp': 4, 'fn': 7}, 'film': {'index': 38, 'tp': 6, 'tn': 574, 'fp': 6, 'fn': 9}, 'food': {'index': 39, 'tp': 8, 'tn': 581, 'fp': 2, 'fn': 4}, 'future': {'index': 40, 'tp': 15, 'tn': 493, 'fp': 61, 'fn': 26}, 'genetics': {'index': 41, 'tp': 13, 'tn': 567, 'fp': 6, 'fn': 9}, 'global development': {'index': 42, 'tp': 5, 'tn': 571, 'fp': 8, 'fn': 11}, 'global issues': {'index': 43, 'tp': 127, 'tn': 112, 'fp': 355, 'fn': 1}, 'government': {'index': 44, 'tp': 3, 'tn': 573, 'fp': 5, 'fn': 14}, 'green': {'index': 45, 'tp': 6, 'tn': 571, 'fp': 10, 'fn': 8}, 'happiness': {'index': 46, 'tp': 7, 'tn': 570, 'fp': 7, 'fn': 11}, 'health': {'index': 47, 'tp': 45, 'tn': 491, 'fp': 40, 'fn': 19}, 'health care': {'index': 48, 'tp': 24, 'tn': 534, 'fp': 23, 'fn': 14}, 'history': {'index': 49, 'tp': 1, 'tn': 551, 'fp': 11, 'fn': 32}, 'humanity': {'index': 50, 'tp': 12, 'tn': 515, 'fp': 43, 'fn': 25}, 'humor': {'index': 51, 'tp': 2, 'tn': 568, 'fp': 4, 'fn': 21}, 'identity': {'index': 52, 'tp': 1, 'tn': 567, 'fp': 3, 'fn': 24}, 'illness': {'index': 53, 'tp': 2, 'tn': 570, 'fp': 12, 'fn': 11}, 'inequality': {'index': 54, 'tp': 1, 'tn': 558, 'fp': 15, 'fn': 21}, 'innovation': {'index': 55, 'tp': 23, 'tn': 465, 'fp': 69, 'fn': 38}, 'internet': {'index': 56, 'tp': 5, 'tn': 571, 'fp': 8, 'fn': 11}, 'invention': {'index': 57, 'tp': 3, 'tn': 538, 'fp': 16, 'fn': 38}, 'language': {'index': 58, 'tp': 10, 'tn': 576, 'fp': 1, 'fn': 8}, 'leadership': {'index': 59, 'tp': 8, 'tn': 559, 'fp': 16, 'fn': 12}, 'life': {'index': 60, 'tp': 7, 'tn': 554, 'fp': 12, 'fn': 22}, 'live music': {'index': 61, 'tp': 6, 'tn': 574, 'fp': 6, 'fn': 9}, 'math': {'index': 62, 'tp': 5, 'tn': 580, 'fp': 0, 'fn': 10}, 'media': {'index': 63, 'tp': 4, 'tn': 578, 'fp': 2, 'fn': 11}, 'medical research': {'index': 64, 'tp': 16, 'tn': 547, 'fp': 24, 'fn': 8}, 'medicine': {'index': 65, 'tp': 24, 'tn': 521, 'fp': 32, 'fn': 18}, 'mental health': {'index': 66, 'tp': 6, 'tn': 569, 'fp': 7, 'fn': 13}, 'mind': {'index': 67, 'tp': 4, 'tn': 566, 'fp': 13, 'fn': 12}, 'motivation': {'index': 68, 'tp': 0, 'tn': 578, 'fp': 0, 'fn': 17}, 'music': {'index': 69, 'tp': 20, 'tn': 552, 'fp': 15, 'fn': 8}, 'nature': {'index': 70, 'tp': 10, 'tn': 545, 'fp': 29, 'fn': 11}, 'neuroscience': {'index': 71, 'tp': 16, 'tn': 557, 'fp': 9, 'fn': 13}, 'oceans': {'index': 72, 'tp': 10, 'tn': 573, 'fp': 7, 'fn': 5}, 'parenting': {'index': 73, 'tp': 1, 'tn': 582, 'fp': 3, 'fn': 9}, 'peace': {'index': 74, 'tp': 0, 'tn': 576, 'fp': 0, 'fn': 19}, 'performance': {'index': 75, 'tp': 12, 'tn': 562, 'fp': 7, 'fn': 14}, 'personal growth': {'index': 76, 'tp': 0, 'tn': 578, 'fp': 1, 'fn': 16}, 'philosophy': {'index': 77, 'tp': 1, 'tn': 579, 'fp': 2, 'fn': 13}, 'photography': {'index': 78, 'tp': 5, 'tn': 561, 'fp': 12, 'fn': 17}, 'physics': {'index': 79, 'tp': 7, 'tn': 581, 'fp': 5, 'fn': 2}, 'policy': {'index': 80, 'tp': 1, 'tn': 574, 'fp': 7, 'fn': 13}, 'politics': {'index': 81, 'tp': 28, 'tn': 512, 'fp': 43, 'fn': 12}, 'potential': {'index': 82, 'tp': 0, 'tn': 577, 'fp': 0, 'fn': 18}, 'poverty': {'index': 83, 'tp': 2, 'tn': 579, 'fp': 1, 'fn': 13}, 'psychology': {'index': 84, 'tp': 4, 'tn': 552, 'fp': 14, 'fn': 25}, 'religion': {'index': 85, 'tp': 4, 'tn': 577, 'fp': 1, 'fn': 13}, 'robots': {'index': 86, 'tp': 5, 'tn': 584, 'fp': 4, 'fn': 2}, 'science': {'index': 87, 'tp': 135, 'tn': 101, 'fp': 356, 'fn': 3}, 'social change': {'index': 88, 'tp': 16, 'tn': 459, 'fp': 95, 'fn': 25}, 'society': {'index': 89, 'tp': 12, 'tn': 460, 'fp': 84, 'fn': 39}, 'space': {'index': 90, 'tp': 5, 'tn': 578, 'fp': 0, 'fn': 12}, 'storytelling': {'index': 91, 'tp': 8, 'tn': 558, 'fp': 7, 'fn': 22}, 'sustainability': {'index': 92, 'tp': 3, 'tn': 565, 'fp': 14, 'fn': 13}, 'technology': {'index': 93, 'tp': 164, 'tn': 23, 'fp': 408, 'fn': 0}, 'violence': {'index': 94, 'tp': 6, 'tn': 573, 'fp': 4, 'fn': 12}, 'visualizations': {'index': 95, 'tp': 2, 'tn': 572, 'fp': 1, 'fn': 20}, 'war': {'index': 96, 'tp': 18, 'tn': 549, 'fp': 14, 'fn': 14}, 'women': {'index': 97, 'tp': 17, 'tn': 563, 'fp': 9, 'fn': 6}, 'work': {'index': 98, 'tp': 6, 'tn': 567, 'fp': 16, 'fn': 6}, 'writing': {'index': 99, 'tp': 5, 'tn': 572, 'fp': 8, 'fn': 10}}\n"
     ]
    }
   ],
   "source": [
    " print(scores_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 issue: 0.06349206349206349\n",
      "f1 issue: 0.556390977443609\n",
      "precision issue: demo\n",
      "f1 issue: 0.2631578947368421\n",
      "precision issue: motivation\n",
      "f1 issue: 0.24242424242424243\n",
      "precision issue: peace\n",
      "f1 issue: 0.14285714285714288\n",
      "f1 issue: 0.5333333333333333\n",
      "precision issue: potential\n",
      "f1 issue: 0.5045045045045045\n",
      "{'activism': {'index': 0, 'tp': 2, 'tn': 534, 'fp': 26, 'fn': 33, 'precision': 0.07, 'recall': 0.06, 'f1': 0.06}, 'adventure': {'index': 1, 'tp': 0, 'tn': 587, 'fp': 1, 'fn': 7, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0}, 'africa': {'index': 2, 'tp': 13, 'tn': 563, 'fp': 7, 'fn': 12, 'precision': 0.65, 'recall': 0.52, 'f1': 0.58}, 'animals': {'index': 3, 'tp': 15, 'tn': 546, 'fp': 19, 'fn': 15, 'precision': 0.44, 'recall': 0.5, 'f1': 0.47}, 'architecture': {'index': 4, 'tp': 7, 'tn': 566, 'fp': 12, 'fn': 10, 'precision': 0.37, 'recall': 0.41, 'f1': 0.39}, 'art': {'index': 5, 'tp': 37, 'tn': 499, 'fp': 46, 'fn': 13, 'precision': 0.45, 'recall': 0.74, 'f1': 0.56}, 'beauty': {'index': 6, 'tp': 0, 'tn': 581, 'fp': 1, 'fn': 13, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0}, 'big problems': {'index': 7, 'tp': 2, 'tn': 582, 'fp': 2, 'fn': 9, 'precision': 0.5, 'recall': 0.18, 'f1': 0.27}, 'biodiversity': {'index': 8, 'tp': 5, 'tn': 569, 'fp': 8, 'fn': 13, 'precision': 0.38, 'recall': 0.28, 'f1': 0.32}, 'biology': {'index': 9, 'tp': 37, 'tn': 497, 'fp': 47, 'fn': 14, 'precision': 0.44, 'recall': 0.73, 'f1': 0.55}, 'biotech': {'index': 10, 'tp': 6, 'tn': 564, 'fp': 7, 'fn': 18, 'precision': 0.46, 'recall': 0.25, 'f1': 0.32}, 'brain': {'index': 11, 'tp': 29, 'tn': 533, 'fp': 19, 'fn': 14, 'precision': 0.6, 'recall': 0.67, 'f1': 0.64}, 'business': {'index': 12, 'tp': 54, 'tn': 356, 'fp': 173, 'fn': 12, 'precision': 0.24, 'recall': 0.82, 'f1': 0.37}, 'children': {'index': 13, 'tp': 14, 'tn': 534, 'fp': 31, 'fn': 16, 'precision': 0.31, 'recall': 0.47, 'f1': 0.37}, 'cities': {'index': 14, 'tp': 15, 'tn': 558, 'fp': 13, 'fn': 9, 'precision': 0.54, 'recall': 0.62, 'f1': 0.58}, 'climate change': {'index': 15, 'tp': 4, 'tn': 571, 'fp': 9, 'fn': 11, 'precision': 0.31, 'recall': 0.27, 'f1': 0.29}, 'cognitive science': {'index': 16, 'tp': 4, 'tn': 569, 'fp': 12, 'fn': 10, 'precision': 0.25, 'recall': 0.29, 'f1': 0.27}, 'collaboration': {'index': 17, 'tp': 3, 'tn': 533, 'fp': 18, 'fn': 41, 'precision': 0.14, 'recall': 0.07, 'f1': 0.09}, 'communication': {'index': 18, 'tp': 16, 'tn': 504, 'fp': 49, 'fn': 26, 'precision': 0.25, 'recall': 0.38, 'f1': 0.3}, 'community': {'index': 19, 'tp': 6, 'tn': 543, 'fp': 21, 'fn': 25, 'precision': 0.22, 'recall': 0.19, 'f1': 0.21}, 'computers': {'index': 20, 'tp': 8, 'tn': 552, 'fp': 19, 'fn': 16, 'precision': 0.3, 'recall': 0.33, 'f1': 0.31}, 'creativity': {'index': 21, 'tp': 15, 'tn': 504, 'fp': 47, 'fn': 29, 'precision': 0.24, 'recall': 0.34, 'f1': 0.28}, 'culture': {'index': 22, 'tp': 134, 'tn': 9, 'fp': 450, 'fn': 2, 'precision': 0.23, 'recall': 0.99, 'f1': 0.37}, 'data': {'index': 23, 'tp': 5, 'tn': 562, 'fp': 14, 'fn': 14, 'precision': 0.26, 'recall': 0.26, 'f1': 0.26}, 'demo': {'index': 24, 'tp': 0, 'tn': 580, 'fp': 0, 'fn': 15, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0}, 'design': {'index': 25, 'tp': 96, 'tn': 248, 'fp': 241, 'fn': 10, 'precision': 0.28, 'recall': 0.91, 'f1': 0.43}, 'disease': {'index': 26, 'tp': 8, 'tn': 560, 'fp': 11, 'fn': 16, 'precision': 0.42, 'recall': 0.33, 'f1': 0.37}, 'ecology': {'index': 27, 'tp': 3, 'tn': 579, 'fp': 4, 'fn': 9, 'precision': 0.43, 'recall': 0.25, 'f1': 0.32}, 'economics': {'index': 28, 'tp': 22, 'tn': 515, 'fp': 49, 'fn': 9, 'precision': 0.31, 'recall': 0.71, 'f1': 0.43}, 'education': {'index': 29, 'tp': 35, 'tn': 511, 'fp': 32, 'fn': 17, 'precision': 0.52, 'recall': 0.67, 'f1': 0.59}, 'energy': {'index': 30, 'tp': 9, 'tn': 579, 'fp': 2, 'fn': 5, 'precision': 0.82, 'recall': 0.64, 'f1': 0.72}, 'engineering': {'index': 31, 'tp': 6, 'tn': 551, 'fp': 21, 'fn': 17, 'precision': 0.22, 'recall': 0.26, 'f1': 0.24}, 'entertainment': {'index': 32, 'tp': 57, 'tn': 336, 'fp': 190, 'fn': 12, 'precision': 0.23, 'recall': 0.83, 'f1': 0.36}, 'entrepreneur': {'index': 33, 'tp': 1, 'tn': 577, 'fp': 0, 'fn': 17, 'precision': 1.0, 'recall': 0.06, 'f1': 0.11}, 'environment': {'index': 34, 'tp': 22, 'tn': 517, 'fp': 42, 'fn': 14, 'precision': 0.34, 'recall': 0.61, 'f1': 0.44}, 'evolution': {'index': 35, 'tp': 6, 'tn': 569, 'fp': 6, 'fn': 14, 'precision': 0.5, 'recall': 0.3, 'f1': 0.37}, 'exploration': {'index': 36, 'tp': 4, 'tn': 564, 'fp': 12, 'fn': 15, 'precision': 0.25, 'recall': 0.21, 'f1': 0.23}, 'family': {'index': 37, 'tp': 2, 'tn': 582, 'fp': 4, 'fn': 7, 'precision': 0.33, 'recall': 0.22, 'f1': 0.27}, 'film': {'index': 38, 'tp': 6, 'tn': 574, 'fp': 6, 'fn': 9, 'precision': 0.5, 'recall': 0.4, 'f1': 0.44}, 'food': {'index': 39, 'tp': 8, 'tn': 581, 'fp': 2, 'fn': 4, 'precision': 0.8, 'recall': 0.67, 'f1': 0.73}, 'future': {'index': 40, 'tp': 15, 'tn': 493, 'fp': 61, 'fn': 26, 'precision': 0.2, 'recall': 0.37, 'f1': 0.26}, 'genetics': {'index': 41, 'tp': 13, 'tn': 567, 'fp': 6, 'fn': 9, 'precision': 0.68, 'recall': 0.59, 'f1': 0.63}, 'global development': {'index': 42, 'tp': 5, 'tn': 571, 'fp': 8, 'fn': 11, 'precision': 0.38, 'recall': 0.31, 'f1': 0.34}, 'global issues': {'index': 43, 'tp': 127, 'tn': 112, 'fp': 355, 'fn': 1, 'precision': 0.26, 'recall': 0.99, 'f1': 0.42}, 'government': {'index': 44, 'tp': 3, 'tn': 573, 'fp': 5, 'fn': 14, 'precision': 0.38, 'recall': 0.18, 'f1': 0.24}, 'green': {'index': 45, 'tp': 6, 'tn': 571, 'fp': 10, 'fn': 8, 'precision': 0.38, 'recall': 0.43, 'f1': 0.4}, 'happiness': {'index': 46, 'tp': 7, 'tn': 570, 'fp': 7, 'fn': 11, 'precision': 0.5, 'recall': 0.39, 'f1': 0.44}, 'health': {'index': 47, 'tp': 45, 'tn': 491, 'fp': 40, 'fn': 19, 'precision': 0.53, 'recall': 0.7, 'f1': 0.6}, 'health care': {'index': 48, 'tp': 24, 'tn': 534, 'fp': 23, 'fn': 14, 'precision': 0.51, 'recall': 0.63, 'f1': 0.56}, 'history': {'index': 49, 'tp': 1, 'tn': 551, 'fp': 11, 'fn': 32, 'precision': 0.08, 'recall': 0.03, 'f1': 0.04}, 'humanity': {'index': 50, 'tp': 12, 'tn': 515, 'fp': 43, 'fn': 25, 'precision': 0.22, 'recall': 0.32, 'f1': 0.26}, 'humor': {'index': 51, 'tp': 2, 'tn': 568, 'fp': 4, 'fn': 21, 'precision': 0.33, 'recall': 0.09, 'f1': 0.14}, 'identity': {'index': 52, 'tp': 1, 'tn': 567, 'fp': 3, 'fn': 24, 'precision': 0.25, 'recall': 0.04, 'f1': 0.07}, 'illness': {'index': 53, 'tp': 2, 'tn': 570, 'fp': 12, 'fn': 11, 'precision': 0.14, 'recall': 0.15, 'f1': 0.15}, 'inequality': {'index': 54, 'tp': 1, 'tn': 558, 'fp': 15, 'fn': 21, 'precision': 0.06, 'recall': 0.05, 'f1': 0.05}, 'innovation': {'index': 55, 'tp': 23, 'tn': 465, 'fp': 69, 'fn': 38, 'precision': 0.25, 'recall': 0.38, 'f1': 0.3}, 'internet': {'index': 56, 'tp': 5, 'tn': 571, 'fp': 8, 'fn': 11, 'precision': 0.38, 'recall': 0.31, 'f1': 0.34}, 'invention': {'index': 57, 'tp': 3, 'tn': 538, 'fp': 16, 'fn': 38, 'precision': 0.16, 'recall': 0.07, 'f1': 0.1}, 'language': {'index': 58, 'tp': 10, 'tn': 576, 'fp': 1, 'fn': 8, 'precision': 0.91, 'recall': 0.56, 'f1': 0.69}, 'leadership': {'index': 59, 'tp': 8, 'tn': 559, 'fp': 16, 'fn': 12, 'precision': 0.33, 'recall': 0.4, 'f1': 0.36}, 'life': {'index': 60, 'tp': 7, 'tn': 554, 'fp': 12, 'fn': 22, 'precision': 0.37, 'recall': 0.24, 'f1': 0.29}, 'live music': {'index': 61, 'tp': 6, 'tn': 574, 'fp': 6, 'fn': 9, 'precision': 0.5, 'recall': 0.4, 'f1': 0.44}, 'math': {'index': 62, 'tp': 5, 'tn': 580, 'fp': 0, 'fn': 10, 'precision': 1.0, 'recall': 0.33, 'f1': 0.5}, 'media': {'index': 63, 'tp': 4, 'tn': 578, 'fp': 2, 'fn': 11, 'precision': 0.67, 'recall': 0.27, 'f1': 0.38}, 'medical research': {'index': 64, 'tp': 16, 'tn': 547, 'fp': 24, 'fn': 8, 'precision': 0.4, 'recall': 0.67, 'f1': 0.5}, 'medicine': {'index': 65, 'tp': 24, 'tn': 521, 'fp': 32, 'fn': 18, 'precision': 0.43, 'recall': 0.57, 'f1': 0.49}, 'mental health': {'index': 66, 'tp': 6, 'tn': 569, 'fp': 7, 'fn': 13, 'precision': 0.46, 'recall': 0.32, 'f1': 0.37}, 'mind': {'index': 67, 'tp': 4, 'tn': 566, 'fp': 13, 'fn': 12, 'precision': 0.24, 'recall': 0.25, 'f1': 0.24}, 'motivation': {'index': 68, 'tp': 0, 'tn': 578, 'fp': 0, 'fn': 17, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0}, 'music': {'index': 69, 'tp': 20, 'tn': 552, 'fp': 15, 'fn': 8, 'precision': 0.57, 'recall': 0.71, 'f1': 0.63}, 'nature': {'index': 70, 'tp': 10, 'tn': 545, 'fp': 29, 'fn': 11, 'precision': 0.26, 'recall': 0.48, 'f1': 0.33}, 'neuroscience': {'index': 71, 'tp': 16, 'tn': 557, 'fp': 9, 'fn': 13, 'precision': 0.64, 'recall': 0.55, 'f1': 0.59}, 'oceans': {'index': 72, 'tp': 10, 'tn': 573, 'fp': 7, 'fn': 5, 'precision': 0.59, 'recall': 0.67, 'f1': 0.62}, 'parenting': {'index': 73, 'tp': 1, 'tn': 582, 'fp': 3, 'fn': 9, 'precision': 0.25, 'recall': 0.1, 'f1': 0.14}, 'peace': {'index': 74, 'tp': 0, 'tn': 576, 'fp': 0, 'fn': 19, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0}, 'performance': {'index': 75, 'tp': 12, 'tn': 562, 'fp': 7, 'fn': 14, 'precision': 0.63, 'recall': 0.46, 'f1': 0.53}, 'personal growth': {'index': 76, 'tp': 0, 'tn': 578, 'fp': 1, 'fn': 16, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0}, 'philosophy': {'index': 77, 'tp': 1, 'tn': 579, 'fp': 2, 'fn': 13, 'precision': 0.33, 'recall': 0.07, 'f1': 0.12}, 'photography': {'index': 78, 'tp': 5, 'tn': 561, 'fp': 12, 'fn': 17, 'precision': 0.29, 'recall': 0.23, 'f1': 0.26}, 'physics': {'index': 79, 'tp': 7, 'tn': 581, 'fp': 5, 'fn': 2, 'precision': 0.58, 'recall': 0.78, 'f1': 0.67}, 'policy': {'index': 80, 'tp': 1, 'tn': 574, 'fp': 7, 'fn': 13, 'precision': 0.12, 'recall': 0.07, 'f1': 0.09}, 'politics': {'index': 81, 'tp': 28, 'tn': 512, 'fp': 43, 'fn': 12, 'precision': 0.39, 'recall': 0.7, 'f1': 0.5}, 'potential': {'index': 82, 'tp': 0, 'tn': 577, 'fp': 0, 'fn': 18, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0}, 'poverty': {'index': 83, 'tp': 2, 'tn': 579, 'fp': 1, 'fn': 13, 'precision': 0.67, 'recall': 0.13, 'f1': 0.22}, 'psychology': {'index': 84, 'tp': 4, 'tn': 552, 'fp': 14, 'fn': 25, 'precision': 0.22, 'recall': 0.14, 'f1': 0.17}, 'religion': {'index': 85, 'tp': 4, 'tn': 577, 'fp': 1, 'fn': 13, 'precision': 0.8, 'recall': 0.24, 'f1': 0.36}, 'robots': {'index': 86, 'tp': 5, 'tn': 584, 'fp': 4, 'fn': 2, 'precision': 0.56, 'recall': 0.71, 'f1': 0.63}, 'science': {'index': 87, 'tp': 135, 'tn': 101, 'fp': 356, 'fn': 3, 'precision': 0.27, 'recall': 0.98, 'f1': 0.43}, 'social change': {'index': 88, 'tp': 16, 'tn': 459, 'fp': 95, 'fn': 25, 'precision': 0.14, 'recall': 0.39, 'f1': 0.21}, 'society': {'index': 89, 'tp': 12, 'tn': 460, 'fp': 84, 'fn': 39, 'precision': 0.12, 'recall': 0.24, 'f1': 0.16}, 'space': {'index': 90, 'tp': 5, 'tn': 578, 'fp': 0, 'fn': 12, 'precision': 1.0, 'recall': 0.29, 'f1': 0.45}, 'storytelling': {'index': 91, 'tp': 8, 'tn': 558, 'fp': 7, 'fn': 22, 'precision': 0.53, 'recall': 0.27, 'f1': 0.36}, 'sustainability': {'index': 92, 'tp': 3, 'tn': 565, 'fp': 14, 'fn': 13, 'precision': 0.18, 'recall': 0.19, 'f1': 0.18}, 'technology': {'index': 93, 'tp': 164, 'tn': 23, 'fp': 408, 'fn': 0, 'precision': 0.29, 'recall': 1.0, 'f1': 0.45}, 'violence': {'index': 94, 'tp': 6, 'tn': 573, 'fp': 4, 'fn': 12, 'precision': 0.6, 'recall': 0.33, 'f1': 0.43}, 'visualizations': {'index': 95, 'tp': 2, 'tn': 572, 'fp': 1, 'fn': 20, 'precision': 0.67, 'recall': 0.09, 'f1': 0.16}, 'war': {'index': 96, 'tp': 18, 'tn': 549, 'fp': 14, 'fn': 14, 'precision': 0.56, 'recall': 0.56, 'f1': 0.56}, 'women': {'index': 97, 'tp': 17, 'tn': 563, 'fp': 9, 'fn': 6, 'precision': 0.65, 'recall': 0.74, 'f1': 0.69}, 'work': {'index': 98, 'tp': 6, 'tn': 567, 'fp': 16, 'fn': 6, 'precision': 0.27, 'recall': 0.5, 'f1': 0.35}, 'writing': {'index': 99, 'tp': 5, 'tn': 572, 'fp': 8, 'fn': 10, 'precision': 0.38, 'recall': 0.33, 'f1': 0.36}}\n"
     ]
    }
   ],
   "source": [
    "def compute_precision_recall_f1(preprocessed_scores):\n",
    "    for key, value in preprocessed_scores.items():\n",
    "        try:\n",
    "            precision = value['tp']/(value['tp']+value['fp'])\n",
    "        except:\n",
    "            print('precision issue: {}'.format(key))\n",
    "            precision = 0.0\n",
    "        try:\n",
    "            recall = value['tp']/(value['tp']+value['fn'])\n",
    "        except:\n",
    "            print('recall issue: {}'.format(key))\n",
    "            recall = 0.0\n",
    "        try:\n",
    "            f1 = (2 * precision * recall)/(precision + recall)\n",
    "        except:\n",
    "            print('f1 issue: {}'.format(f1))\n",
    "            f1=0.0\n",
    "        preprocessed_scores[key]['precision'] = round(precision,2)\n",
    "        preprocessed_scores[key]['recall'] = round(recall,2)\n",
    "        preprocessed_scores[key]['f1'] = round(f1,2)\n",
    "    return preprocessed_scores\n",
    "final_scores = compute_precision_recall_f1(scores_preprocess)\n",
    "print(final_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 class  precision  recall    f1\n",
      "0             activism       0.07    0.06  0.06\n",
      "1            adventure       0.00    0.00  0.00\n",
      "2               africa       0.65    0.52  0.58\n",
      "3              animals       0.44    0.50  0.47\n",
      "4         architecture       0.37    0.41  0.39\n",
      "5                  art       0.45    0.74  0.56\n",
      "6               beauty       0.00    0.00  0.00\n",
      "7         big problems       0.50    0.18  0.27\n",
      "8         biodiversity       0.38    0.28  0.32\n",
      "9              biology       0.44    0.73  0.55\n",
      "10             biotech       0.46    0.25  0.32\n",
      "11               brain       0.60    0.67  0.64\n",
      "12            business       0.24    0.82  0.37\n",
      "13            children       0.31    0.47  0.37\n",
      "14              cities       0.54    0.62  0.58\n",
      "15      climate change       0.31    0.27  0.29\n",
      "16   cognitive science       0.25    0.29  0.27\n",
      "17       collaboration       0.14    0.07  0.09\n",
      "18       communication       0.25    0.38  0.30\n",
      "19           community       0.22    0.19  0.21\n",
      "20           computers       0.30    0.33  0.31\n",
      "21          creativity       0.24    0.34  0.28\n",
      "22             culture       0.23    0.99  0.37\n",
      "23                data       0.26    0.26  0.26\n",
      "24                demo       0.00    0.00  0.00\n",
      "25              design       0.28    0.91  0.43\n",
      "26             disease       0.42    0.33  0.37\n",
      "27             ecology       0.43    0.25  0.32\n",
      "28           economics       0.31    0.71  0.43\n",
      "29           education       0.52    0.67  0.59\n",
      "30              energy       0.82    0.64  0.72\n",
      "31         engineering       0.22    0.26  0.24\n",
      "32       entertainment       0.23    0.83  0.36\n",
      "33        entrepreneur       1.00    0.06  0.11\n",
      "34         environment       0.34    0.61  0.44\n",
      "35           evolution       0.50    0.30  0.37\n",
      "36         exploration       0.25    0.21  0.23\n",
      "37              family       0.33    0.22  0.27\n",
      "38                film       0.50    0.40  0.44\n",
      "39                food       0.80    0.67  0.73\n",
      "40              future       0.20    0.37  0.26\n",
      "41            genetics       0.68    0.59  0.63\n",
      "42  global development       0.38    0.31  0.34\n",
      "43       global issues       0.26    0.99  0.42\n",
      "44          government       0.38    0.18  0.24\n",
      "45               green       0.38    0.43  0.40\n",
      "46           happiness       0.50    0.39  0.44\n",
      "47              health       0.53    0.70  0.60\n",
      "48         health care       0.51    0.63  0.56\n",
      "49             history       0.08    0.03  0.04\n",
      "50            humanity       0.22    0.32  0.26\n",
      "51               humor       0.33    0.09  0.14\n",
      "52            identity       0.25    0.04  0.07\n",
      "53             illness       0.14    0.15  0.15\n",
      "54          inequality       0.06    0.05  0.05\n",
      "55          innovation       0.25    0.38  0.30\n",
      "56            internet       0.38    0.31  0.34\n",
      "57           invention       0.16    0.07  0.10\n",
      "58            language       0.91    0.56  0.69\n",
      "59          leadership       0.33    0.40  0.36\n",
      "60                life       0.37    0.24  0.29\n",
      "61          live music       0.50    0.40  0.44\n",
      "62                math       1.00    0.33  0.50\n",
      "63               media       0.67    0.27  0.38\n",
      "64    medical research       0.40    0.67  0.50\n",
      "65            medicine       0.43    0.57  0.49\n",
      "66       mental health       0.46    0.32  0.37\n",
      "67                mind       0.24    0.25  0.24\n",
      "68          motivation       0.00    0.00  0.00\n",
      "69               music       0.57    0.71  0.63\n",
      "70              nature       0.26    0.48  0.33\n",
      "71        neuroscience       0.64    0.55  0.59\n",
      "72              oceans       0.59    0.67  0.62\n",
      "73           parenting       0.25    0.10  0.14\n",
      "74               peace       0.00    0.00  0.00\n",
      "75         performance       0.63    0.46  0.53\n",
      "76     personal growth       0.00    0.00  0.00\n",
      "77          philosophy       0.33    0.07  0.12\n",
      "78         photography       0.29    0.23  0.26\n",
      "79             physics       0.58    0.78  0.67\n",
      "80              policy       0.12    0.07  0.09\n",
      "81            politics       0.39    0.70  0.50\n",
      "82           potential       0.00    0.00  0.00\n",
      "83             poverty       0.67    0.13  0.22\n",
      "84          psychology       0.22    0.14  0.17\n",
      "85            religion       0.80    0.24  0.36\n",
      "86              robots       0.56    0.71  0.63\n",
      "87             science       0.27    0.98  0.43\n",
      "88       social change       0.14    0.39  0.21\n",
      "89             society       0.12    0.24  0.16\n",
      "90               space       1.00    0.29  0.45\n",
      "91        storytelling       0.53    0.27  0.36\n",
      "92      sustainability       0.18    0.19  0.18\n",
      "93          technology       0.29    1.00  0.45\n",
      "94            violence       0.60    0.33  0.43\n",
      "95      visualizations       0.67    0.09  0.16\n",
      "96                 war       0.56    0.56  0.56\n",
      "97               women       0.65    0.74  0.69\n",
      "98                work       0.27    0.50  0.35\n",
      "99             writing       0.38    0.33  0.36\n"
     ]
    }
   ],
   "source": [
    "def format_scores_df(final_scores=final_scores, tag_classes=mlb.classes_):\n",
    "    precision = []\n",
    "    recall = []\n",
    "    f1 = []\n",
    "    for index, value in enumerate(tag_classes):\n",
    "        precision.append(final_scores[value]['precision'])\n",
    "        recall.append(final_scores[value]['recall'])\n",
    "        f1.append(final_scores[value]['f1'])\n",
    "    df_result = pd.DataFrame(list(zip(tag_classes, precision, recall, f1)), \n",
    "               columns =['class', 'precision', 'recall', 'f1']) \n",
    "    return df_result\n",
    "df_results = format_scores_df()\n",
    "print_full_dataframe(df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
