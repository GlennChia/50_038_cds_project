{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"../../data/processed/\"\n",
    "INPUT_FILE_NAME = 'final_squash15_with_pos_ner_tm.parquet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker</th>\n",
       "      <th>headline</th>\n",
       "      <th>description</th>\n",
       "      <th>duration</th>\n",
       "      <th>tags</th>\n",
       "      <th>transcript</th>\n",
       "      <th>WC</th>\n",
       "      <th>clean_transcript</th>\n",
       "      <th>clean_transcript_string</th>\n",
       "      <th>sim_tags</th>\n",
       "      <th>squash15_tags</th>\n",
       "      <th>pos_sequence</th>\n",
       "      <th>ner_sequence</th>\n",
       "      <th>tm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Al Gore</td>\n",
       "      <td>Averting the climate crisis</td>\n",
       "      <td>With the same humor and humanity he exuded in ...</td>\n",
       "      <td>0:16:17</td>\n",
       "      <td>cars,alternative energy,culture,politics,scien...</td>\n",
       "      <td>0:14\\r\\r\\rThank you so much, Chris.\\rAnd it's ...</td>\n",
       "      <td>2281.0</td>\n",
       "      <td>b'[\"thank\", \"chris\", \"truly\", \"great\", \"honor\"...</td>\n",
       "      <td>thank chris truly great honor opportunity come...</td>\n",
       "      <td>cars,solar system,energy,culture,politics,scie...</td>\n",
       "      <td>culture,politics,science,global issues,technology</td>\n",
       "      <td>VERB PROPN ADV ADJ NOUN NOUN VERB NOUN ADV ADV...</td>\n",
       "      <td>PERSON ORG ORG GPE LOC ORG PRODUCT GPE GPE PER...</td>\n",
       "      <td>[0.04325945698517057, 0.0, 0.00142482934694180...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Amy Smith</td>\n",
       "      <td>Simple designs to save a life</td>\n",
       "      <td>Fumes from indoor cooking fires kill more than...</td>\n",
       "      <td>0:15:06</td>\n",
       "      <td>MacArthur grant,simplicity,industrial design,a...</td>\n",
       "      <td>0:11\\r\\r\\rIn terms of invention,\\rI'd like to ...</td>\n",
       "      <td>2687.0</td>\n",
       "      <td>b'[\"term\", \"invention\", \"like\", \"tell\", \"tale\"...</td>\n",
       "      <td>term invention like tell tale favorite project...</td>\n",
       "      <td>macarthur grant,simplicity,design,solar system...</td>\n",
       "      <td>design,global issues</td>\n",
       "      <td>NOUN NOUN SCONJ VERB PROPN ADJ NOUN VERB NOUN ...</td>\n",
       "      <td>GPE DATE CARDINAL DATE ORG PERSON LOC ORG GPE ...</td>\n",
       "      <td>[0.013287880838036227, 0.0, 0.0, 0.00511725094...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ashraf Ghani</td>\n",
       "      <td>How to rebuild a broken state</td>\n",
       "      <td>Ashraf Ghani's passionate and powerful 10-minu...</td>\n",
       "      <td>0:18:45</td>\n",
       "      <td>corruption,poverty,economics,investment,milita...</td>\n",
       "      <td>0:12\\r\\r\\rA public, Dewey long ago observed,\\r...</td>\n",
       "      <td>2506.0</td>\n",
       "      <td>b'[\"public\", \"dewey\", \"long\", \"ago\", \"observe\"...</td>\n",
       "      <td>public dewey long ago observe constitute discu...</td>\n",
       "      <td>corruption,inequality,science,investment,war,c...</td>\n",
       "      <td>science,culture,politics,global issues,business</td>\n",
       "      <td>ADJ PROPN ADV ADV VERB ADJ NOUN NOUN PROPN PRO...</td>\n",
       "      <td>DATE NORP ORDINAL DATE MONEY DATE DATE DATE EV...</td>\n",
       "      <td>[0.0, 0.006699599134802422, 0.0, 0.00564851883...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Burt Rutan</td>\n",
       "      <td>The real future of space exploration</td>\n",
       "      <td>In this passionate talk, legendary spacecraft ...</td>\n",
       "      <td>0:19:37</td>\n",
       "      <td>aircraft,flight,industrial design,NASA,rocket ...</td>\n",
       "      <td>0:11\\r\\r\\rI want to start off by saying, Houst...</td>\n",
       "      <td>3092.0</td>\n",
       "      <td>b'[\"want\", \"start\", \"say\", \"houston\", \"problem...</td>\n",
       "      <td>want start say houston problem enter second ge...</td>\n",
       "      <td>flight,design,nasa,science,invention,entrepren...</td>\n",
       "      <td>design,science,business</td>\n",
       "      <td>VERB NOUN VERB PROPN NOUN VERB ADJ NOUN NOUN N...</td>\n",
       "      <td>GPE ORDINAL ORG PERSON DATE DATE DATE TIME PER...</td>\n",
       "      <td>[0.040282108339079505, 0.03732895646484358, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chris Bangle</td>\n",
       "      <td>Great cars are great art</td>\n",
       "      <td>American designer Chris Bangle explains his ph...</td>\n",
       "      <td>0:20:04</td>\n",
       "      <td>cars,industrial design,transportation,inventio...</td>\n",
       "      <td>0:12\\r\\r\\rWhat I want to talk about is, as bac...</td>\n",
       "      <td>3781.0</td>\n",
       "      <td>b'[\"want\", \"talk\", \"background\", \"idea\", \"car\"...</td>\n",
       "      <td>want talk background idea car art actually mea...</td>\n",
       "      <td>cars,design,transportation,invention,technolog...</td>\n",
       "      <td>design,technology,business,science</td>\n",
       "      <td>VERB NOUN NOUN NOUN NOUN NOUN ADV ADJ NOUN NOU...</td>\n",
       "      <td>PERSON PRODUCT ORG ORG PERSON PERSON PERSON OR...</td>\n",
       "      <td>[0.08049208168957463, 0.0, 0.0, 0.008031187136...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        speaker                              headline  \\\n",
       "0       Al Gore           Averting the climate crisis   \n",
       "1     Amy Smith         Simple designs to save a life   \n",
       "2  Ashraf Ghani         How to rebuild a broken state   \n",
       "3    Burt Rutan  The real future of space exploration   \n",
       "4  Chris Bangle              Great cars are great art   \n",
       "\n",
       "                                         description duration  \\\n",
       "0  With the same humor and humanity he exuded in ...  0:16:17   \n",
       "1  Fumes from indoor cooking fires kill more than...  0:15:06   \n",
       "2  Ashraf Ghani's passionate and powerful 10-minu...  0:18:45   \n",
       "3  In this passionate talk, legendary spacecraft ...  0:19:37   \n",
       "4  American designer Chris Bangle explains his ph...  0:20:04   \n",
       "\n",
       "                                                tags  \\\n",
       "0  cars,alternative energy,culture,politics,scien...   \n",
       "1  MacArthur grant,simplicity,industrial design,a...   \n",
       "2  corruption,poverty,economics,investment,milita...   \n",
       "3  aircraft,flight,industrial design,NASA,rocket ...   \n",
       "4  cars,industrial design,transportation,inventio...   \n",
       "\n",
       "                                          transcript      WC  \\\n",
       "0  0:14\\r\\r\\rThank you so much, Chris.\\rAnd it's ...  2281.0   \n",
       "1  0:11\\r\\r\\rIn terms of invention,\\rI'd like to ...  2687.0   \n",
       "2  0:12\\r\\r\\rA public, Dewey long ago observed,\\r...  2506.0   \n",
       "3  0:11\\r\\r\\rI want to start off by saying, Houst...  3092.0   \n",
       "4  0:12\\r\\r\\rWhat I want to talk about is, as bac...  3781.0   \n",
       "\n",
       "                                    clean_transcript  \\\n",
       "0  b'[\"thank\", \"chris\", \"truly\", \"great\", \"honor\"...   \n",
       "1  b'[\"term\", \"invention\", \"like\", \"tell\", \"tale\"...   \n",
       "2  b'[\"public\", \"dewey\", \"long\", \"ago\", \"observe\"...   \n",
       "3  b'[\"want\", \"start\", \"say\", \"houston\", \"problem...   \n",
       "4  b'[\"want\", \"talk\", \"background\", \"idea\", \"car\"...   \n",
       "\n",
       "                             clean_transcript_string  \\\n",
       "0  thank chris truly great honor opportunity come...   \n",
       "1  term invention like tell tale favorite project...   \n",
       "2  public dewey long ago observe constitute discu...   \n",
       "3  want start say houston problem enter second ge...   \n",
       "4  want talk background idea car art actually mea...   \n",
       "\n",
       "                                            sim_tags  \\\n",
       "0  cars,solar system,energy,culture,politics,scie...   \n",
       "1  macarthur grant,simplicity,design,solar system...   \n",
       "2  corruption,inequality,science,investment,war,c...   \n",
       "3  flight,design,nasa,science,invention,entrepren...   \n",
       "4  cars,design,transportation,invention,technolog...   \n",
       "\n",
       "                                       squash15_tags  \\\n",
       "0  culture,politics,science,global issues,technology   \n",
       "1                               design,global issues   \n",
       "2    science,culture,politics,global issues,business   \n",
       "3                            design,science,business   \n",
       "4                 design,technology,business,science   \n",
       "\n",
       "                                        pos_sequence  \\\n",
       "0  VERB PROPN ADV ADJ NOUN NOUN VERB NOUN ADV ADV...   \n",
       "1  NOUN NOUN SCONJ VERB PROPN ADJ NOUN VERB NOUN ...   \n",
       "2  ADJ PROPN ADV ADV VERB ADJ NOUN NOUN PROPN PRO...   \n",
       "3  VERB NOUN VERB PROPN NOUN VERB ADJ NOUN NOUN N...   \n",
       "4  VERB NOUN NOUN NOUN NOUN NOUN ADV ADJ NOUN NOU...   \n",
       "\n",
       "                                        ner_sequence  \\\n",
       "0  PERSON ORG ORG GPE LOC ORG PRODUCT GPE GPE PER...   \n",
       "1  GPE DATE CARDINAL DATE ORG PERSON LOC ORG GPE ...   \n",
       "2  DATE NORP ORDINAL DATE MONEY DATE DATE DATE EV...   \n",
       "3  GPE ORDINAL ORG PERSON DATE DATE DATE TIME PER...   \n",
       "4  PERSON PRODUCT ORG ORG PERSON PERSON PERSON OR...   \n",
       "\n",
       "                                                  tm  \n",
       "0  [0.04325945698517057, 0.0, 0.00142482934694180...  \n",
       "1  [0.013287880838036227, 0.0, 0.0, 0.00511725094...  \n",
       "2  [0.0, 0.006699599134802422, 0.0, 0.00564851883...  \n",
       "3  [0.040282108339079505, 0.03732895646484358, 0....  \n",
       "4  [0.08049208168957463, 0.0, 0.0, 0.008031187136...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet(DATA_DIR + INPUT_FILE_NAME)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    squash15_tags  counts  no_count     ratio  overall_ratio\n",
      "0         science    1467       846  1.734043       0.634241\n",
      "1         culture    1155      1158  0.997409       0.499351\n",
      "2      technology     787      1526  0.515727       0.340251\n",
      "3   global issues     679      1634  0.415545       0.293558\n",
      "4          design     477      1836  0.259804       0.206226\n",
      "5         history     385      1928  0.199689       0.166450\n",
      "6        business     349      1964  0.177699       0.150886\n",
      "7   entertainment     285      2028  0.140533       0.123217\n",
      "8           media     279      2034  0.137168       0.120623\n",
      "9    biomechanics     220      2093  0.105112       0.095115\n",
      "10   biodiversity     218      2095  0.104057       0.094250\n",
      "11         future     218      2095  0.104057       0.094250\n",
      "12       humanity     217      2096  0.103531       0.093818\n",
      "13       politics     199      2114  0.094134       0.086035\n",
      "14  communication     185      2128  0.086936       0.079983\n"
     ]
    }
   ],
   "source": [
    "def print_full_dataframe(x):\n",
    "    pd.set_option('display.max_rows', len(x))\n",
    "    print(x)\n",
    "    pd.reset_option('display.max_rows')\n",
    "    \n",
    "def compute_tag_ratio(target_column, df=df):\n",
    "    tags = df[target_column].str.replace(', ',',').str.lower().str.strip()\n",
    "    split_tags = tags.str.split(',')\n",
    "    tag_counts_per_talk = split_tags.apply(len)\n",
    "\n",
    "    joined_tags = tags.str.cat(sep=',').split(',')\n",
    "    all_tags = pd.Series(joined_tags)\n",
    "\n",
    "    tag_counts = all_tags.value_counts().rename_axis(target_column).reset_index(name='counts')\n",
    "    tag_counts['no_count'] = len(df)-tag_counts['counts']\n",
    "    tag_counts['ratio'] = tag_counts['counts']/tag_counts['no_count']\n",
    "    tag_counts['overall_ratio'] = tag_counts['counts']/(tag_counts['no_count'] + tag_counts['counts'])\n",
    "    return tag_counts\n",
    "\n",
    "#print(compute_tag_ratio('squash3_tags', df))\n",
    "squashed_tag_counts = compute_tag_ratio('squash15_tags', df)\n",
    "print_full_dataframe(squashed_tag_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['culture', 'politics', 'science', 'global issues', 'technology', 'design', 'business', 'biomechanics', 'biodiversity', 'media', 'entertainment', 'history', 'future', 'communication', 'humanity']\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "joined_tags = df['squash15_tags'].str.cat(sep=',').split(',')\n",
    "all_tags = pd.Series(joined_tags).str.strip().str.lower()\n",
    "all_tags = list(dict.fromkeys(all_tags))\n",
    "try:\n",
    "    all_tags.remove('')\n",
    "except:\n",
    "    pass\n",
    "print(all_tags)\n",
    "print(len(all_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_one_hot_encode(df=df):\n",
    "    complete_transcripts_tags = []\n",
    "    for rows, value in df.iterrows():\n",
    "        one_hot_encoding = [0] * len(all_tags)\n",
    "        headline = [value['headline']]\n",
    "        transcript = [value['clean_transcript_string']]\n",
    "        pos_sequence = [value['pos_sequence']]\n",
    "        ner_sequence = [value['ner_sequence']]\n",
    "        indiv_tags = value['squash15_tags'].split(',')\n",
    "        for tags in indiv_tags:\n",
    "            if tags == '':\n",
    "                continue\n",
    "            index = all_tags.index(tags.lower().lstrip(' '))\n",
    "            one_hot_encoding[index] = 1\n",
    "        indiv_transcript_tags = headline + transcript + pos_sequence + ner_sequence + one_hot_encoding\n",
    "        complete_transcripts_tags.append(indiv_transcript_tags)\n",
    "    return pd.DataFrame(complete_transcripts_tags, columns=['headline', 'transcript', 'pos_sequence', 'ner_sequence'] + all_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>transcript</th>\n",
       "      <th>pos_sequence</th>\n",
       "      <th>ner_sequence</th>\n",
       "      <th>culture</th>\n",
       "      <th>politics</th>\n",
       "      <th>science</th>\n",
       "      <th>global issues</th>\n",
       "      <th>technology</th>\n",
       "      <th>design</th>\n",
       "      <th>business</th>\n",
       "      <th>biomechanics</th>\n",
       "      <th>biodiversity</th>\n",
       "      <th>media</th>\n",
       "      <th>entertainment</th>\n",
       "      <th>history</th>\n",
       "      <th>future</th>\n",
       "      <th>communication</th>\n",
       "      <th>humanity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Averting the climate crisis</td>\n",
       "      <td>thank chris truly great honor opportunity come...</td>\n",
       "      <td>VERB PROPN ADV ADJ NOUN NOUN VERB NOUN ADV ADV...</td>\n",
       "      <td>PERSON ORG ORG GPE LOC ORG PRODUCT GPE GPE PER...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Simple designs to save a life</td>\n",
       "      <td>term invention like tell tale favorite project...</td>\n",
       "      <td>NOUN NOUN SCONJ VERB PROPN ADJ NOUN VERB NOUN ...</td>\n",
       "      <td>GPE DATE CARDINAL DATE ORG PERSON LOC ORG GPE ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How to rebuild a broken state</td>\n",
       "      <td>public dewey long ago observe constitute discu...</td>\n",
       "      <td>ADJ PROPN ADV ADV VERB ADJ NOUN NOUN PROPN PRO...</td>\n",
       "      <td>DATE NORP ORDINAL DATE MONEY DATE DATE DATE EV...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The real future of space exploration</td>\n",
       "      <td>want start say houston problem enter second ge...</td>\n",
       "      <td>VERB NOUN VERB PROPN NOUN VERB ADJ NOUN NOUN N...</td>\n",
       "      <td>GPE ORDINAL ORG PERSON DATE DATE DATE TIME PER...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Great cars are great art</td>\n",
       "      <td>want talk background idea car art actually mea...</td>\n",
       "      <td>VERB NOUN NOUN NOUN NOUN NOUN ADV ADJ NOUN NOU...</td>\n",
       "      <td>PERSON PRODUCT ORG ORG PERSON PERSON PERSON OR...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2308</th>\n",
       "      <td>Why glass towers are bad for city life -- and ...</td>\n",
       "      <td>imagine walk even discover everybody room look...</td>\n",
       "      <td>VERB NOUN ADV VERB PRON NOUN VERB ADV NOUN NOU...</td>\n",
       "      <td>ORG GPE ORG GPE GPE GPE GPE GPE GPE GPE GPE PE...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2309</th>\n",
       "      <td>What happens in your brain when you pay attent...</td>\n",
       "      <td>pay close attention easy attention pull differ...</td>\n",
       "      <td>VERB ADJ NOUN ADJ NOUN VERB ADJ NOUN NOUN NOUN...</td>\n",
       "      <td>ORDINAL PERSON PRODUCT DATE DATE</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2310</th>\n",
       "      <td>Why you should define your fears instead of yo...</td>\n",
       "      <td>happy pic take senior college right dance prac...</td>\n",
       "      <td>ADJ PROPN VERB ADJ NOUN ADJ NOUN NOUN ADJ VERB...</td>\n",
       "      <td>DATE PERSON ORG PERSON PERSON GPE PERSON GPE O...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2311</th>\n",
       "      <td>12 truths I learned from life and writing</td>\n",
       "      <td>sevenyearold grandson sleep hall wake lot morn...</td>\n",
       "      <td>PROPN PROPN PROPN PROPN VERB NOUN NOUN VERB VE...</td>\n",
       "      <td>PERSON PERSON PERSON PERSON PERSON DATE CARDIN...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2312</th>\n",
       "      <td>How I built a jet suit</td>\n",
       "      <td>michael brown engineer innovator inventor insp...</td>\n",
       "      <td>PROPN PROPN PROPN PROPN PROPN PROPN PROPN NOUN...</td>\n",
       "      <td>PERSON DATE DATE PERSON GPE CARDINAL GPE GPE O...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2313 rows Ã— 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               headline  \\\n",
       "0                           Averting the climate crisis   \n",
       "1                         Simple designs to save a life   \n",
       "2                         How to rebuild a broken state   \n",
       "3                  The real future of space exploration   \n",
       "4                              Great cars are great art   \n",
       "...                                                 ...   \n",
       "2308  Why glass towers are bad for city life -- and ...   \n",
       "2309  What happens in your brain when you pay attent...   \n",
       "2310  Why you should define your fears instead of yo...   \n",
       "2311          12 truths I learned from life and writing   \n",
       "2312                             How I built a jet suit   \n",
       "\n",
       "                                             transcript  \\\n",
       "0     thank chris truly great honor opportunity come...   \n",
       "1     term invention like tell tale favorite project...   \n",
       "2     public dewey long ago observe constitute discu...   \n",
       "3     want start say houston problem enter second ge...   \n",
       "4     want talk background idea car art actually mea...   \n",
       "...                                                 ...   \n",
       "2308  imagine walk even discover everybody room look...   \n",
       "2309  pay close attention easy attention pull differ...   \n",
       "2310  happy pic take senior college right dance prac...   \n",
       "2311  sevenyearold grandson sleep hall wake lot morn...   \n",
       "2312  michael brown engineer innovator inventor insp...   \n",
       "\n",
       "                                           pos_sequence  \\\n",
       "0     VERB PROPN ADV ADJ NOUN NOUN VERB NOUN ADV ADV...   \n",
       "1     NOUN NOUN SCONJ VERB PROPN ADJ NOUN VERB NOUN ...   \n",
       "2     ADJ PROPN ADV ADV VERB ADJ NOUN NOUN PROPN PRO...   \n",
       "3     VERB NOUN VERB PROPN NOUN VERB ADJ NOUN NOUN N...   \n",
       "4     VERB NOUN NOUN NOUN NOUN NOUN ADV ADJ NOUN NOU...   \n",
       "...                                                 ...   \n",
       "2308  VERB NOUN ADV VERB PRON NOUN VERB ADV NOUN NOU...   \n",
       "2309  VERB ADJ NOUN ADJ NOUN VERB ADJ NOUN NOUN NOUN...   \n",
       "2310  ADJ PROPN VERB ADJ NOUN ADJ NOUN NOUN ADJ VERB...   \n",
       "2311  PROPN PROPN PROPN PROPN VERB NOUN NOUN VERB VE...   \n",
       "2312  PROPN PROPN PROPN PROPN PROPN PROPN PROPN NOUN...   \n",
       "\n",
       "                                           ner_sequence  culture  politics  \\\n",
       "0     PERSON ORG ORG GPE LOC ORG PRODUCT GPE GPE PER...        1         1   \n",
       "1     GPE DATE CARDINAL DATE ORG PERSON LOC ORG GPE ...        0         0   \n",
       "2     DATE NORP ORDINAL DATE MONEY DATE DATE DATE EV...        1         1   \n",
       "3     GPE ORDINAL ORG PERSON DATE DATE DATE TIME PER...        0         0   \n",
       "4     PERSON PRODUCT ORG ORG PERSON PERSON PERSON OR...        0         0   \n",
       "...                                                 ...      ...       ...   \n",
       "2308  ORG GPE ORG GPE GPE GPE GPE GPE GPE GPE GPE PE...        1         0   \n",
       "2309                   ORDINAL PERSON PRODUCT DATE DATE        0         0   \n",
       "2310  DATE PERSON ORG PERSON PERSON GPE PERSON GPE O...        1         0   \n",
       "2311  PERSON PERSON PERSON PERSON PERSON DATE CARDIN...        1         0   \n",
       "2312  PERSON DATE DATE PERSON GPE CARDINAL GPE GPE O...        1         0   \n",
       "\n",
       "      science  global issues  technology  design  business  biomechanics  \\\n",
       "0           1              1           1       0         0             0   \n",
       "1           0              1           0       1         0             0   \n",
       "2           1              1           0       0         1             0   \n",
       "3           1              0           0       1         1             0   \n",
       "4           1              0           1       1         1             0   \n",
       "...       ...            ...         ...     ...       ...           ...   \n",
       "2308        1              0           0       0         0             0   \n",
       "2309        1              0           1       0         0             0   \n",
       "2310        0              0           0       0         0             0   \n",
       "2311        1              0           0       0         0             0   \n",
       "2312        0              0           1       1         0             0   \n",
       "\n",
       "      biodiversity  media  entertainment  history  future  communication  \\\n",
       "0                0      0              0        0       0              0   \n",
       "1                0      0              0        0       0              0   \n",
       "2                0      0              0        0       0              0   \n",
       "3                0      0              0        0       0              0   \n",
       "4                0      0              0        0       0              0   \n",
       "...            ...    ...            ...      ...     ...            ...   \n",
       "2308             0      0              0        1       0              0   \n",
       "2309             0      0              0        0       0              0   \n",
       "2310             0      0              0        0       0              0   \n",
       "2311             0      0              0        1       0              1   \n",
       "2312             0      0              0        0       1              0   \n",
       "\n",
       "      humanity  \n",
       "0            0  \n",
       "1            0  \n",
       "2            0  \n",
       "3            0  \n",
       "4            0  \n",
       "...        ...  \n",
       "2308         0  \n",
       "2309         0  \n",
       "2310         1  \n",
       "2311         1  \n",
       "2312         0  \n",
       "\n",
       "[2313 rows x 19 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = create_one_hot_encode()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "# Predictions flushed to 1\n",
    "predictions = [1] *len(df)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tag(threshold, predictions=predictions):\n",
    "    return [[1 if j > threshold else 0 for j in i.tolist()] for i in predictions]\n",
    "\n",
    "def get_tag_flat(threshold, predictions=predictions):\n",
    "    return [1 if j > threshold else 0 for i in predictions for j in i]\n",
    "predictions_flushed = get_tag(0.4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_tp_tn_fp_fn(y_test, y_pred, classes):\n",
    "    '''\n",
    "    Return:\n",
    "    pre_score = {\n",
    "        'tag_1': {\n",
    "            'index': ,\n",
    "            'tp': ,\n",
    "            'tn': ,\n",
    "            'fp': ,\n",
    "            'fn': \n",
    "        }\n",
    "    }\n",
    "    '''\n",
    "    # Create dictionary of tags \n",
    "    pre_score = {}\n",
    "    for index_tag, tag in enumerate(classes):\n",
    "        pre_score[tag] = {\n",
    "            'index':index_tag,\n",
    "            'tp': 0,\n",
    "            'tn': 0,\n",
    "            'fp': 0,\n",
    "            'fn': 0\n",
    "        }\n",
    "    for transcript_index, transcript_value in enumerate(y_test):\n",
    "        if transcript_value == y_pred[transcript_index] and transcript_value == 1:\n",
    "            pre_score[classes[0]]['tp'] += 1\n",
    "        elif transcript_value == y_pred[transcript_index] and transcript_value == 0:\n",
    "            pre_score[classes[0]]['tn'] += 1\n",
    "        elif transcript_value != y_pred[transcript_index] and transcript_value == 1:\n",
    "            pre_score[classes[0]]['fn'] += 1\n",
    "        elif transcript_value != y_pred[transcript_index] and transcript_value == 0:\n",
    "            pre_score[classes[0]]['fp'] += 1\n",
    "    return pre_score\n",
    "# scores_preprocess = compute_tp_tn_fp_fn(valid_y, predictions_flushed, ['culture'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_precision_recall_f1(preprocessed_scores):\n",
    "    for key, value in preprocessed_scores.items():\n",
    "        try:\n",
    "            precision = value['tp']/(value['tp']+value['fp'])\n",
    "        except:\n",
    "            print('precision issue: {}'.format(key))\n",
    "            precision = 0.0\n",
    "        try:\n",
    "            recall = value['tp']/(value['tp']+value['fn'])\n",
    "        except:\n",
    "            print('recall issue: {}'.format(key))\n",
    "            recall = 0.0\n",
    "        try:\n",
    "            f1 = (2 * precision * recall)/(precision + recall)\n",
    "        except:\n",
    "            print('f1 issue: {}'.format(key))\n",
    "            f1=0.0\n",
    "        preprocessed_scores[key]['precision'] = round(precision,2)\n",
    "        preprocessed_scores[key]['recall'] = round(recall,2)\n",
    "        preprocessed_scores[key]['f1'] = round(f1,2)\n",
    "    return preprocessed_scores\n",
    "#final_scores = compute_precision_recall_f1(scores_preprocess)\n",
    "#print(final_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_full_dataframe(x):\n",
    "    pd.set_option('display.max_rows', len(x))\n",
    "    print(x)\n",
    "    pd.reset_option('display.max_rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            class  precision  recall    f1  accuracy\n",
      "0         culture       0.50     1.0  0.67  0.499351\n",
      "1        politics       0.09     1.0  0.16  0.086035\n",
      "2         science       0.63     1.0  0.78  0.634241\n",
      "3   global issues       0.29     1.0  0.45  0.293558\n",
      "4      technology       0.34     1.0  0.51  0.340251\n",
      "5          design       0.21     1.0  0.34  0.206226\n",
      "6        business       0.15     1.0  0.26  0.150886\n",
      "7    biomechanics       0.10     1.0  0.17  0.095115\n",
      "8    biodiversity       0.09     1.0  0.17  0.094250\n",
      "9           media       0.12     1.0  0.22  0.120623\n",
      "10  entertainment       0.12     1.0  0.22  0.123217\n",
      "11        history       0.17     1.0  0.29  0.166450\n",
      "12         future       0.09     1.0  0.17  0.094250\n",
      "13  communication       0.08     1.0  0.15  0.079983\n",
      "14       humanity       0.09     1.0  0.17  0.093818\n"
     ]
    }
   ],
   "source": [
    "def format_scores_df(tag_classes):\n",
    "    precision = []\n",
    "    recall = []\n",
    "    f1 = []\n",
    "    accuracy = []\n",
    "    for index, value in enumerate(tag_classes):\n",
    "        final_scores = compute_precision_recall_f1(compute_tp_tn_fp_fn(df[value].tolist(), predictions, [value]))\n",
    "        precision.append(final_scores[value]['precision'])\n",
    "        recall.append(final_scores[value]['recall'])\n",
    "        f1.append(final_scores[value]['f1'])\n",
    "        accuracy.append((final_scores[value]['tp'] + final_scores[value]['tn'])/(final_scores[value]['tp'] + final_scores[value]['tn'] + final_scores[value]['fp'] + final_scores[value]['fn']))\n",
    "    df_result = pd.DataFrame(list(zip(tag_classes, precision, recall, f1, accuracy)), \n",
    "               columns =['class', 'precision', 'recall', 'f1', 'accuracy']) \n",
    "    return df_result\n",
    "# for tag in all_tags:\n",
    "#     df_results = format_scores_df([tag], compute_precision_recall_f1(compute_tp_tn_fp_fn(df[tag].tolist(), predictions, [tag])))\n",
    "#     print_full_dataframe(df_results)\n",
    "df_results = format_scores_df(all_tags)\n",
    "print_full_dataframe(df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
