{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IN_DATA_DIR = \"../../data/raw/\"\n",
    "INPUT_FILE_NAME = 'cleaned.parquet'\n",
    "OUT_DATA_DIR = \"../../data/processed/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2386"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet(IN_DATA_DIR + INPUT_FILE_NAME)\n",
    "df.head()\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_tags(tag_column):\n",
    "    tags = tag_column.str.replace(', ', ',').str.lower().str.strip()\n",
    "    joined_tags = tags.str.cat(sep=',').split(',')\n",
    "    all_tags_w_dup = pd.Series(joined_tags)\n",
    "\n",
    "    tag_counts = all_tags_w_dup.value_counts()\n",
    "    tag_list = list(tag_counts.index)\n",
    "    return tag_counts, tag_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split_tags = tags.str.split(',')\n",
    "# tag_counts_per_talk = split_tags.apply(len)\n",
    "\n",
    "tags, tag_list = count_tags(df['tags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#remove ted tags\n",
    "def remove_ted_tags(tags,tag_list):\n",
    "    ted_tags=[]\n",
    "    for tag in tag_list:\n",
    "        if 'ted' in tag:\n",
    "            ted_tags.append(tag)\n",
    "    print(ted_tags)\n",
    "    tags = tags.drop(labels = ted_tags)\n",
    "    tag_list = list(tags.index.values)\n",
    "    return tags, tag_list, ted_tags\n",
    "\n",
    "def remove_tags(original_tags,remove_list):\n",
    "    tags = original_tags.replace(', ', ',').lower().strip()\n",
    "    split_tags = tags.split(',')\n",
    "    \n",
    "    final_tags = []\n",
    "    for tag in split_tags:\n",
    "        if tag not in remove_list:\n",
    "            \n",
    "            final_tags.append(tag)\n",
    "    final_string = ','.join(final_tags)\n",
    "    return final_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tedx', 'ted fellows', 'ted brain trust', 'ted prize', 'united states', 'tedyouth', 'tedmed', 'ted books', 'ted residency', 'augmented reality', 'ted en espa√±ol', 'ted en espanol', 'ted-ed']\n"
     ]
    }
   ],
   "source": [
    "tags, tag_list, ted_tags = remove_ted_tags(tags,tag_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "technology         695\n",
       "science            522\n",
       "global issues      483\n",
       "culture            470\n",
       "design             400\n",
       "business           329\n",
       "entertainment      285\n",
       "health             226\n",
       "innovation         212\n",
       "education          206\n",
       "art                204\n",
       "society            202\n",
       "social change      198\n",
       "communication      185\n",
       "politics           183\n",
       "future             181\n",
       "creativity         174\n",
       "biology            174\n",
       "humanity           164\n",
       "collaboration      163\n",
       "environment        155\n",
       "economics          154\n",
       "medicine           154\n",
       "brain              148\n",
       "activism           147\n",
       "invention          136\n",
       "community          136\n",
       "children           135\n",
       "history            135\n",
       "health care        130\n",
       "                  ... \n",
       "sleep                3\n",
       "microsoft            3\n",
       "trust                3\n",
       "ants                 3\n",
       "ptsd                 3\n",
       "pandemic             3\n",
       "apes                 3\n",
       "moon                 2\n",
       "cello                2\n",
       "driverless cars      2\n",
       "grammar              2\n",
       "anthropocene         2\n",
       "arts                 2\n",
       "novel                2\n",
       "syria                2\n",
       "origami              2\n",
       "evil                 2\n",
       "testing              1\n",
       "alzheimer's          1\n",
       "skateboarding        1\n",
       "epidemiology         1\n",
       "nonviolence          1\n",
       "asteroid             1\n",
       "gay                  1\n",
       "cloud                1\n",
       "crispr               1\n",
       "blockchain           1\n",
       "telescopes           1\n",
       "surveillance         1\n",
       "                     1\n",
       "Length: 405, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squashing (x,squash_list):\n",
    "    original_tags = x\n",
    "#     print(x)\n",
    "    tags = original_tags.replace(', ', ',').lower().strip()\n",
    "    split_tags = tags.split(',')\n",
    "    final_tags = []\n",
    "    for tag in split_tags:\n",
    "        if tag in squash_list:\n",
    "            \n",
    "            final_tags.append(tag)\n",
    "    final_string = ','.join(final_tags)\n",
    "    return final_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_list = []\n",
    "for i in range(len(tag_list)):\n",
    "    nlp_list.append(nlp(tag_list[i]))\n",
    "# print(nlp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "simlist = []\n",
    "tagsimcount = [0]*len(tag_list)\n",
    "tagsimdict = {el:[] for el in tag_list}\n",
    "for outer in range(len(nlp_list)):\n",
    "    for inner in range(len(nlp_list)):\n",
    "        if inner<outer:\n",
    "            sim = nlp_list[outer].similarity(nlp_list[inner])\n",
    "            if sim > 0.65:\n",
    "                ow = tag_list[outer]\n",
    "                iw = tag_list[inner]\n",
    "                ow_count = tags.at[ow]\n",
    "                iw_count = tags.at[iw]\n",
    "                simlist.append([ow,iw,sim])\n",
    "                tagsimcount[outer] += 1\n",
    "                tagsimcount[inner] += 1\n",
    "                tagsimdict[ow].append(iw)\n",
    "                tagsimdict[iw].append(ow)\n",
    "                \n",
    "items =list(tagsimdict.items())\n",
    "\n",
    "for k,v in items:\n",
    "    if v == []:\n",
    "        del tagsimdict[k]             \n",
    "\n",
    "# print(simlist)\n",
    "# print(tagsimcount)\n",
    "# print(tagsimdict)\n",
    "sim_tags = list(tagsimdict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# replace tags\n",
    "# GENERALISE: 'education','teaching' -> 'education'\n",
    "# REMAIN: 'africa', 'asia' -> 'africa', 'asia'\n",
    "\n",
    "#anything with ted remove hahaha\n",
    "print(tagsimcount)\n",
    "print(tagsimdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_counts(a):\n",
    "#     print(a)\n",
    "    a_count=tags.at[a]\n",
    "    all_tags = [a]\n",
    "    all_count = [a_count]\n",
    "    b = tagsimdict[a]\n",
    "    for word in b:\n",
    "        b_count=tags.at[word]\n",
    "        all_tags.append(word)\n",
    "        all_count.append(b_count)\n",
    "    max_count = max(all_count)\n",
    "    max_index = all_count.index(max_count)\n",
    "    major = all_tags[max_index]\n",
    "    minor = all_tags\n",
    "    minor.remove(major)\n",
    "    final = [major]+minor\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_tags_ordered = []\n",
    "for tag in tag_list:\n",
    "    if tag in sim_tags:\n",
    "        sim_tags_ordered.append(tag)\n",
    "# print(sim_tags_ordered)\n",
    "sim_tags_reversed = sim_tags_ordered\n",
    "sim_tags_reversed.reverse()\n",
    "print(sim_tags_reversed)\n",
    "print(len(sim_tags),len(sim_tags_reversed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_replacement = {}\n",
    "for i in range(len(sim_tags_reversed)):\n",
    "    tag = sim_tags_reversed[i]\n",
    "    sims = tagsimdict[tag]\n",
    "    #check if words that main tag is similar too have similar words too\n",
    "    for sim in sims:\n",
    "        if sim in final_replacement.keys():\n",
    "            simlist = final_replacement[sim]\n",
    "            sims+=simlist\n",
    "            del final_replacement[sim]\n",
    "    #remove duplicates\n",
    "    sims = list(dict.fromkeys(sims))\n",
    "    final_replacement[tag]=sims\n",
    "print(final_replacement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_replacement.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replacing (x):\n",
    "    original_tags = x\n",
    "    tags = original_tags.replace(', ', ',').lower().strip()\n",
    "    split_tags = tags.split(',')\n",
    "    final_tags = []\n",
    "    for tag in split_tags:\n",
    "        if tag in final_replacement.keys():\n",
    "            #tag is a major\n",
    "            final_tags.append(tag)\n",
    "        else:\n",
    "            #tag is a minor\n",
    "            r = []\n",
    "            for k,v in final_replacement.items():\n",
    "                if tag in v:\n",
    "                    #tag is a minor w/ a major\n",
    "                    r.append(k)\n",
    "            if r == []:\n",
    "                r.append(tag)\n",
    "            final_tags += r\n",
    "    final_tags = list(dict.fromkeys(final_tags))\n",
    "    final_string = ','.join(final_tags)\n",
    "    return final_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.copy()\n",
    "df1['sim_tags'] = df1['tags']\n",
    "df1['sim_tags'] = df1['sim_tags'].map(lambda x: replacing(x))\n",
    "df1['sim_tags'] = df1['sim_tags'].map(lambda x: remove_tags(x,ted_tags))\n",
    "df1 = df1[df1['sim_tags']!='']\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags1,tag1_list = count_tags(df1['sim_tags'])\n",
    "tags1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_cutoff05 = int(0.05*len(df1.index))\n",
    "\n",
    "squashed_tags05 = pd.DataFrame(tags1)\n",
    "squashed_tags05 = squashed_tags05[(squashed_tags05[0]>tag_cutoff05)]\n",
    "squash_list05 = list(squashed_tags05.index.values)\n",
    "print(len(squash_list05))\n",
    "squashed_tags05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df1.copy()\n",
    "df2['squash29_tags'] = df2['sim_tags']\n",
    "df2['squash29_tags'] = df2['squash29_tags'].map(lambda x: squashing(x,squash_list05))\n",
    "df2 = df2[df2['squash29_tags']!='']\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tags2,tag2_list = count_tags(df2['squash29_tags'])\n",
    "tags2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_cutoff075 = int(0.075*len(df1.index))\n",
    "\n",
    "squashed_tags075 = pd.DataFrame(tags1)\n",
    "squashed_tags075 = squashed_tags075[(squashed_tags075[0]>tag_cutoff075)]\n",
    "squash_list075 = list(squashed_tags075.index.values)\n",
    "print(len(squash_list075))\n",
    "squashed_tags075"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df1.copy()\n",
    "df3['squash15_tags'] = df3['sim_tags']\n",
    "df3['squash15_tags'] = df3['squash15_tags'].map(lambda x: squashing(x,squash_list075))\n",
    "df3 = df3[df3['squash15_tags']!='']\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags3,tag3_list = count_tags(df3['squash15_tags'])\n",
    "tags3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1 = df1.reset_index(drop=True)\n",
    "# df2 = df2.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2.to_parquet(OUT_DATA_DIR+'cleaned_squashed_final.parquet')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
