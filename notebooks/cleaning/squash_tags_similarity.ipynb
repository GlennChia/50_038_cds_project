{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IN_DATA_DIR = \"../../data/raw/\"\n",
    "INPUT_FILE_NAME = 'cleaned.parquet'\n",
    "OUT_DATA_DIR = \"../../data/processed/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(IN_DATA_DIR + INPUT_FILE_NAME)\n",
    "df.head()\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_tags(tag_column):\n",
    "    tags = tag_column.str.replace(', ', ',').str.lower().str.strip()\n",
    "    joined_tags = tags.str.cat(sep=',').split(',')\n",
    "    all_tags_w_dup = pd.Series(joined_tags)\n",
    "\n",
    "    tag_counts = all_tags_w_dup.value_counts()\n",
    "    tag_list = list(tag_counts.index)\n",
    "    return tag_counts, tag_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split_tags = tags.str.split(',')\n",
    "# tag_counts_per_talk = split_tags.apply(len)\n",
    "\n",
    "tag_counts, tag_list = count_tags(df['tags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_cutoff = int(0.02*len(df.index))\n",
    "\n",
    "squashed_tags = pd.DataFrame(tag_counts)\n",
    "squashed_tags = squashed_tags[(squashed_tags[0]>tag_cutoff)]\n",
    "squash_list = list(squashed_tags.index.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "squashed_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#remove ted tags\n",
    "ted_tags=[]\n",
    "for tag in squash_list:\n",
    "    if 'ted' in tag:\n",
    "        ted_tags.append(tag)\n",
    "print(ted_tags)\n",
    "squashed_tags = squashed_tags.drop(labels = ted_tags)\n",
    "squash_list = list(squashed_tags.index.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "squashed_tags\n",
    "print(squash_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squashing (x,squash_list):\n",
    "    original_tags = x\n",
    "#     print(x)\n",
    "    tags = original_tags.replace(', ', ',').lower().strip()\n",
    "    split_tags = tags.split(',')\n",
    "    final_tags = []\n",
    "    for tag in split_tags:\n",
    "        if tag in squash_list:\n",
    "            \n",
    "            final_tags.append(tag)\n",
    "    final_string = ','.join(final_tags)\n",
    "    return final_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.copy()\n",
    "df1['squash_tags'] = df1['tags']\n",
    "df1['squash_tags'] = df1['squash_tags'].map(lambda x: squashing(x,squash_list))\n",
    "df1 = df1[df1['squash_tags']!='']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1[df1['squash_tags']==float('nan')]\n",
    "df1[df1['squash_tags']==None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_list = []\n",
    "for i in range(len(squash_list)):\n",
    "    nlp_list.append(nlp(squash_list[i]))\n",
    "# print(nlp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "simlist = []\n",
    "tagsimcount = [0]*len(squash_list)\n",
    "tagsimdict = {el:[] for el in squash_list}\n",
    "for outer in range(len(nlp_list)):\n",
    "    for inner in range(len(nlp_list)):\n",
    "        if inner<outer:\n",
    "            sim = nlp_list[outer].similarity(nlp_list[inner])\n",
    "            if sim > 0.65:\n",
    "                ow = squash_list[outer]\n",
    "                iw = squash_list[inner]\n",
    "                ow_count = tag_counts.at[ow]\n",
    "                iw_count = tag_counts.at[iw]\n",
    "                simlist.append([ow,iw,sim])\n",
    "                tagsimcount[outer] += 1\n",
    "                tagsimcount[inner] += 1\n",
    "                tagsimdict[ow].append(iw)\n",
    "                tagsimdict[iw].append(ow)\n",
    "                \n",
    "items =list(tagsimdict.items())\n",
    "\n",
    "for k,v in items:\n",
    "    if v == []:\n",
    "        del tagsimdict[k]             \n",
    "\n",
    "# print(simlist)\n",
    "# print(tagsimcount)\n",
    "# print(tagsimdict)\n",
    "sim_tags = list(tagsimdict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# replace tags\n",
    "# GENERALISE: 'education','teaching' -> 'education'\n",
    "# REMAIN: 'africa', 'asia' -> 'africa', 'asia'\n",
    "\n",
    "#anything with ted remove hahaha\n",
    "print(tagsimcount)\n",
    "print(tagsimdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_counts(a):\n",
    "#     print(a)\n",
    "    a_count=tag_counts.at[a]\n",
    "    all_tags = [a]\n",
    "    all_count = [a_count]\n",
    "    b = tagsimdict[a]\n",
    "    for word in b:\n",
    "        b_count=tag_counts.at[word]\n",
    "        all_tags.append(word)\n",
    "        all_count.append(b_count)\n",
    "    max_count = max(all_count)\n",
    "    max_index = all_count.index(max_count)\n",
    "    major = all_tags[max_index]\n",
    "    minor = all_tags\n",
    "    minor.remove(major)\n",
    "    final = [major]+minor\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_tags_ordered = []\n",
    "for tag in squash_list:\n",
    "    if tag in sim_tags:\n",
    "        sim_tags_ordered.append(tag)\n",
    "# print(sim_tags_ordered)\n",
    "sim_tags_reversed = sim_tags_ordered\n",
    "sim_tags_reversed.reverse()\n",
    "print(sim_tags_reversed)\n",
    "print(len(sim_tags),len(sim_tags_reversed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_replacement = {}\n",
    "for i in range(len(sim_tags_reversed)):\n",
    "    tag = sim_tags_reversed[i]\n",
    "    sims = tagsimdict[tag]\n",
    "    #check if words that main tag is similar too have similar words too\n",
    "    for sim in sims:\n",
    "        if sim in final_replacement.keys():\n",
    "            simlist = final_replacement[sim]\n",
    "            sims+=simlist\n",
    "            del final_replacement[sim]\n",
    "    #remove duplicates\n",
    "    sims = list(dict.fromkeys(sims))\n",
    "    final_replacement[tag]=sims\n",
    "print(final_replacement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_replacement.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replacing (x):\n",
    "    original_tags = x\n",
    "    tags = original_tags.replace(', ', ',').lower().strip()\n",
    "    split_tags = tags.split(',')\n",
    "    final_tags = []\n",
    "    for tag in split_tags:\n",
    "        if tag in final_replacement.keys():\n",
    "            #tag is a major\n",
    "            final_tags.append(tag)\n",
    "        else:\n",
    "            #tag is a minor\n",
    "            r = []\n",
    "            for k,v in final_replacement.items():\n",
    "                if tag in v:\n",
    "                    #tag is a minor w/ a major\n",
    "                    r.append(k)\n",
    "            if r == []:\n",
    "                r.append(tag)\n",
    "            final_tags += r\n",
    "    final_tags = list(dict.fromkeys(final_tags))\n",
    "    final_string = ','.join(final_tags)\n",
    "    return final_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df1.copy()\n",
    "df2['squash2_tags'] = df2['squash_tags']\n",
    "df2['squash2_tags'] = df2['squash2_tags'].map(lambda x: replacing(x))\n",
    "df2 = df2[df2['squash2_tags']!='']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[df2['squash2_tags']==float('nan')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_tag_counts,s_tag_list = count_tags(df2['squash2_tags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(s_tag_list))\n",
    "s_tag_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tag_cutoff3 = int(0.05*len(df2.index))\n",
    "\n",
    "squashed_tags3 = pd.DataFrame(s_tag_counts)\n",
    "squashed_tags3 = squashed_tags3[(squashed_tags3[0]>tag_cutoff3)]\n",
    "squash_list3 = list(squashed_tags3.index.values)\n",
    "print(len(squash_list3))\n",
    "squashed_tags3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df2.copy()\n",
    "df3['squash3_tags'] = df3['squash2_tags']\n",
    "df3['squash3_tags'] = df3['squash3_tags'].map(lambda x: squashing(x,squash_list3))\n",
    "df3 = df3[df3['squash3_tags']!='']\n",
    "\n",
    "s3_tag_counts,s3_tag_list = count_tags(df3['squash3_tags'])\n",
    "s3_tag_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df3[df3['squash3_tags']==df3['squash3_tags'][149]]\n",
    "# df3[df3['squash3_tags']==float('nan')]\n",
    "# df3[df3['speaker']=='Norman Foster']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_cutoff4 = 200\n",
    "\n",
    "squashed_tags4 = pd.DataFrame(s_tag_counts)\n",
    "squashed_tags4 = squashed_tags4[(squashed_tags4[0]>tag_cutoff4)]\n",
    "squash_list4 = list(squashed_tags4.index.values)\n",
    "print(len(squash_list4))\n",
    "squashed_tags4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df3.copy()\n",
    "df4['squash4_tags'] = df4['squash3_tags']\n",
    "df4['squash4_tags'] = df4['squash4_tags'].map(lambda x: squashing(x,squash_list4))\n",
    "df4 = df4[df4['squash4_tags']!='']\n",
    "\n",
    "s4_tag_counts,s4_tag_list = count_tags(df4['squash4_tags'])\n",
    "s4_tag_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cutting(x,cutlist):\n",
    "#     print(x)\n",
    "    have = False\n",
    "    for tag in cutlist:\n",
    "#         print(tag)\n",
    "        if tag in x:\n",
    "            have = True\n",
    "    if have:\n",
    "        return x\n",
    "    else:\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4_cut = df4.copy()\n",
    "df4_cut['squash4_tags'] = df4_cut['squash4_tags'].map(lambda x: cutting(x,['entertainment','art','future','biodiversity','education']))\n",
    "df4_cut = df4_cut[df4_cut['squash4_tags']!='']\n",
    "df4_cut\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s4cut_tag_counts,s4cut_tag_list = count_tags(df4_cut['squash4_tags'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s4cut_tag_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_cutoff5 = 300\n",
    "\n",
    "squashed_tags5 = pd.DataFrame(s_tag_counts)\n",
    "squashed_tags5 = squashed_tags5[(squashed_tags5[0]>tag_cutoff5)]\n",
    "squash_list5 = list(squashed_tags5.index.values)\n",
    "print(len(squash_list5))\n",
    "squashed_tags5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = df4.copy()\n",
    "df5['squash5_tags'] = df5['squash4_tags']\n",
    "df5['squash5_tags'] = df5['squash5_tags'].map(lambda x: squashing(x,squash_list5))\n",
    "df5 = df5[df5['squash5_tags']!='']\n",
    "\n",
    "s5_tag_counts,s5_tag_list = count_tags(df5['squash5_tags'])\n",
    "s5_tag_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.reset_index(drop=True)\n",
    "df2 = df2.reset_index(drop=True)\n",
    "df3 = df3.reset_index(drop=True)\n",
    "df4 = df4.reset_index(drop=True)\n",
    "df5 = df5.reindex(list(range(len(df5))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1.to_parquet(OUT_DATA_DIR+'cleaned_squashed1.parquet')\n",
    "# df2.to_parquet(OUT_DATA_DIR+'cleaned_squashed2.parquet')\n",
    "# df3.to_parquet(OUT_DATA_DIR+'cleaned_squashed3.parquet')\n",
    "# df4.to_parquet(OUT_DATA_DIR+'cleaned_squashed4.parquet')\n",
    "# df5.to_parquet(OUT_DATA_DIR+'cleaned_squashed4.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.iloc[140:150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.DataFrame(['a','b','c'])\n",
    "d = d.drop(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = d.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.iloc[145:150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
