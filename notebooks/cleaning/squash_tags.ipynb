{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"../../data/raw/\"\n",
    "INPUT_FILE_NAME = 'cleaned.parquet'\n",
    "OUTPUT_FILE_NAME = 'cleaned_squashed.parquet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker</th>\n",
       "      <th>headline</th>\n",
       "      <th>description</th>\n",
       "      <th>duration</th>\n",
       "      <th>tags</th>\n",
       "      <th>transcript</th>\n",
       "      <th>WC</th>\n",
       "      <th>clean_transcript</th>\n",
       "      <th>clean_transcript_string</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Al Gore</td>\n",
       "      <td>Averting the climate crisis</td>\n",
       "      <td>With the same humor and humanity he exuded in ...</td>\n",
       "      <td>0:16:17</td>\n",
       "      <td>cars,alternative energy,culture,politics,scien...</td>\n",
       "      <td>0:14\\r\\r\\rThank you so much, Chris.\\rAnd it's ...</td>\n",
       "      <td>2281.0</td>\n",
       "      <td>[thank, chris, truly, great, honor, opportunit...</td>\n",
       "      <td>thank chris truly great honor opportunity come...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Amy Smith</td>\n",
       "      <td>Simple designs to save a life</td>\n",
       "      <td>Fumes from indoor cooking fires kill more than...</td>\n",
       "      <td>0:15:06</td>\n",
       "      <td>MacArthur grant,simplicity,industrial design,a...</td>\n",
       "      <td>0:11\\r\\r\\rIn terms of invention,\\rI'd like to ...</td>\n",
       "      <td>2687.0</td>\n",
       "      <td>[term, invention, like, tell, tale, favorite, ...</td>\n",
       "      <td>term invention like tell tale favorite project...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ashraf Ghani</td>\n",
       "      <td>How to rebuild a broken state</td>\n",
       "      <td>Ashraf Ghani's passionate and powerful 10-minu...</td>\n",
       "      <td>0:18:45</td>\n",
       "      <td>corruption,poverty,economics,investment,milita...</td>\n",
       "      <td>0:12\\r\\r\\rA public, Dewey long ago observed,\\r...</td>\n",
       "      <td>2506.0</td>\n",
       "      <td>[public, dewey, long, ago, observe, constitute...</td>\n",
       "      <td>public dewey long ago observe constitute discu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Burt Rutan</td>\n",
       "      <td>The real future of space exploration</td>\n",
       "      <td>In this passionate talk, legendary spacecraft ...</td>\n",
       "      <td>0:19:37</td>\n",
       "      <td>aircraft,flight,industrial design,NASA,rocket ...</td>\n",
       "      <td>0:11\\r\\r\\rI want to start off by saying, Houst...</td>\n",
       "      <td>3092.0</td>\n",
       "      <td>[want, start, say, houston, problem, enter, se...</td>\n",
       "      <td>want start say houston problem enter second ge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chris Bangle</td>\n",
       "      <td>Great cars are great art</td>\n",
       "      <td>American designer Chris Bangle explains his ph...</td>\n",
       "      <td>0:20:04</td>\n",
       "      <td>cars,industrial design,transportation,inventio...</td>\n",
       "      <td>0:12\\r\\r\\rWhat I want to talk about is, as bac...</td>\n",
       "      <td>3781.0</td>\n",
       "      <td>[want, talk, background, idea, car, art, actua...</td>\n",
       "      <td>want talk background idea car art actually mea...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        speaker                              headline  \\\n",
       "0       Al Gore           Averting the climate crisis   \n",
       "1     Amy Smith         Simple designs to save a life   \n",
       "2  Ashraf Ghani         How to rebuild a broken state   \n",
       "3    Burt Rutan  The real future of space exploration   \n",
       "4  Chris Bangle              Great cars are great art   \n",
       "\n",
       "                                         description duration  \\\n",
       "0  With the same humor and humanity he exuded in ...  0:16:17   \n",
       "1  Fumes from indoor cooking fires kill more than...  0:15:06   \n",
       "2  Ashraf Ghani's passionate and powerful 10-minu...  0:18:45   \n",
       "3  In this passionate talk, legendary spacecraft ...  0:19:37   \n",
       "4  American designer Chris Bangle explains his ph...  0:20:04   \n",
       "\n",
       "                                                tags  \\\n",
       "0  cars,alternative energy,culture,politics,scien...   \n",
       "1  MacArthur grant,simplicity,industrial design,a...   \n",
       "2  corruption,poverty,economics,investment,milita...   \n",
       "3  aircraft,flight,industrial design,NASA,rocket ...   \n",
       "4  cars,industrial design,transportation,inventio...   \n",
       "\n",
       "                                          transcript      WC  \\\n",
       "0  0:14\\r\\r\\rThank you so much, Chris.\\rAnd it's ...  2281.0   \n",
       "1  0:11\\r\\r\\rIn terms of invention,\\rI'd like to ...  2687.0   \n",
       "2  0:12\\r\\r\\rA public, Dewey long ago observed,\\r...  2506.0   \n",
       "3  0:11\\r\\r\\rI want to start off by saying, Houst...  3092.0   \n",
       "4  0:12\\r\\r\\rWhat I want to talk about is, as bac...  3781.0   \n",
       "\n",
       "                                    clean_transcript  \\\n",
       "0  [thank, chris, truly, great, honor, opportunit...   \n",
       "1  [term, invention, like, tell, tale, favorite, ...   \n",
       "2  [public, dewey, long, ago, observe, constitute...   \n",
       "3  [want, start, say, houston, problem, enter, se...   \n",
       "4  [want, talk, background, idea, car, art, actua...   \n",
       "\n",
       "                             clean_transcript_string  \n",
       "0  thank chris truly great honor opportunity come...  \n",
       "1  term invention like tell tale favorite project...  \n",
       "2  public dewey long ago observe constitute discu...  \n",
       "3  want start say houston problem enter second ge...  \n",
       "4  want talk background idea car art actually mea...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet(DATA_DIR + INPUT_FILE_NAME)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = df['tags'].str.replace(', ', ',').str.lower().str.strip()\n",
    "split_tags = tags.str.split(',')\n",
    "tag_counts_per_talk = split_tags.apply(len)\n",
    "\n",
    "joined_tags = tags.str.cat(sep=',').split(',')\n",
    "all_tags_w_dup = pd.Series(joined_tags)\n",
    "\n",
    "tag_counts = all_tags_w_dup.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tag_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_documents = tags.str.cat(sep='_').split('_')\n",
    "def tokenise(documents):\n",
    "    for string in documents:\n",
    "        yield gensim.utils.simple_preprocess(string)\n",
    "tag_documents = list(tokenise(tag_documents))\n",
    "\n",
    "transcript_documents = df['clean_transcript'].map(lambda x: x.tolist())\n",
    "transcript_documents = list(transcript_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_model = gensim.models.Word2Vec(tag_documents,size=150,window=5,min_count=2,workers=4)\n",
    "tag_model.train(tag_documents,total_examples=len(tag_documents),epochs=10)\n",
    "\n",
    "transcript_model = gensim.models.Word2Vec(transcript_documents,size=150,window=5,min_count=2,workers=4)\n",
    "transcript_model.train(transcript_documents,total_examples=len(transcript_documents),epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def tsne_plot(model,squash):\n",
    "    \"Creates and TSNE model and plots it\"\n",
    "    labels = []\n",
    "    tokens = []\n",
    "    \n",
    "    count = 0\n",
    "    for word in model.wv.vocab:\n",
    "        # TODO get the labels\n",
    "        if squash:\n",
    "            if word in squash_list:\n",
    "                tokens.append(model[word])\n",
    "                labels.append(word)    \n",
    "        else:\n",
    "            tokens.append(model[word])\n",
    "            labels.append(word)\n",
    "\n",
    "\n",
    "    # set the t-sne values\n",
    "    tsne_model = TSNE(perplexity=40, n_components=2, init='pca', n_iter=3500, random_state=32)\n",
    "    new_values = tsne_model.fit_transform(tokens)\n",
    "    # TODO fit the t-sne model\n",
    "\n",
    "    x = []\n",
    "    y = []\n",
    "    for value in new_values:\n",
    "        x.append(value[0])\n",
    "        y.append(value[1])\n",
    "        \n",
    "    plt.figure(figsize=(16, 16)) \n",
    "    for i in range(len(x)):\n",
    "        plt.scatter(x[i],y[i])\n",
    "        plt.annotate(labels[i],\n",
    "                     xy=(x[i], y[i]),\n",
    "                     xytext=(5, 2),\n",
    "                     textcoords='offset points',\n",
    "                     ha='right',\n",
    "                     va='bottom')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_cutoff = int(0.01*len(df.index))\n",
    "\n",
    "squashed_tags = pd.DataFrame(tag_counts)\n",
    "squashed_tags = squashed_tags[(squashed_tags[0]>tag_cutoff)]\n",
    "squash_list = list(squashed_tags.index.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     0\n",
      "technology         695\n",
      "science            522\n",
      "global issues      483\n",
      "culture            470\n",
      "design             400\n",
      "tedx               398\n",
      "business           329\n",
      "entertainment      285\n",
      "health             226\n",
      "innovation         212\n",
      "education          206\n",
      "art                204\n",
      "society            202\n",
      "social change      198\n",
      "communication      185\n",
      "politics           183\n",
      "future             181\n",
      "biology            174\n",
      "creativity         174\n",
      "humanity           164\n",
      "collaboration      163\n",
      "environment        155\n",
      "economics          154\n",
      "medicine           154\n",
      "brain              148\n",
      "activism           147\n",
      "community          136\n",
      "invention          136\n",
      "history            135\n",
      "children           135\n",
      "...                ...\n",
      "philanthropy        32\n",
      "sports              31\n",
      "algorithm           30\n",
      "investment          29\n",
      "gaming              29\n",
      "feminism            29\n",
      "disability          29\n",
      "plants              28\n",
      "statistics          28\n",
      "microbiology        28\n",
      "success             28\n",
      "money               28\n",
      "curiosity           28\n",
      "fear                28\n",
      "biomechanics        27\n",
      "gender              27\n",
      "interface design    27\n",
      "fish                27\n",
      "women in business   27\n",
      "ted prize           27\n",
      "industrial design   27\n",
      "urban planning      26\n",
      "empathy             26\n",
      "united states       25\n",
      "code                25\n",
      "asia                25\n",
      "depression          25\n",
      "faith               24\n",
      "planets             24\n",
      "bacteria            24\n",
      "\n",
      "[179 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "print(squashed_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squashing (x):\n",
    "    original_tags = x\n",
    "    tags = original_tags.replace(', ', ',').lower().strip()\n",
    "    split_tags = tags.split(',')\n",
    "    final_tags = []\n",
    "    for tag in split_tags:\n",
    "        if tag in squash_list:\n",
    "            final_tags.append(tag)\n",
    "    final_string = ','.join(final_tags)\n",
    "    return final_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['squash_tags'] = df['tags']\n",
    "df['squash_tags'] = df['squash_tags'].map(lambda x: squashing(x))\n",
    "df.to_parquet(DATA_DIR+OUTPUT_FILE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "squash_tags = df['squash_tags'].str.replace(', ', ',').str.lower().str.strip()\n",
    "squash_tag_documents = squash_tags.str.cat(sep='_').split('_')\n",
    "squash_tag_documents = list(tokenise(squash_tag_documents))\n",
    "\n",
    "squash_tag_model = gensim.models.Word2Vec(squash_tag_documents,size=150,window=5,min_count=2,workers=4)\n",
    "squash_tag_model.train(squash_tag_documents,total_examples=len(tag_documents),epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_plot(tag_model,False)\n",
    "tsne_plot(tag_model,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tsne_plot(squash_tag_model,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[df['tags']=='']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_pickle(\"./squashed_processed_data.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['tags']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = 'alternative'\n",
    "tag_model.wv.most_similar(positive=w,topn=10)\n",
    "# transcript_model.wv.most_similar(positive=w1,topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_list = []\n",
    "for i in range(len(squash_list)):\n",
    "    nlp_list.append(nlp(squash_list[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simlist = []\n",
    "tagsimcount = [0]*len(squash_list)\n",
    "tagsimdict = {el:[] for el in squash_list}\n",
    "for outer in range(len(nlp_list)):\n",
    "    for inner in range(len(nlp_list)):\n",
    "        if inner<outer:\n",
    "            sim = nlp_list[outer].similarity(nlp_list[inner])\n",
    "            if sim > 0.7:\n",
    "                ow = squash_list[outer]\n",
    "                iw = squash_list[inner]      \n",
    "                simlist.append([ow,iw,sim])\n",
    "                tagsimcount[outer] += 1\n",
    "                tagsimcount[inner] += 1\n",
    "                tagsimdict[ow].append(iw)\n",
    "                tagsimdict[iw].append(ow)\n",
    "                \n",
    "                \n",
    "print(simlist)\n",
    "print(tagsimcount)\n",
    "print(tagsimdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace tags\n",
    "# SPLIT UP: 'women in business' -> 'women','business'\n",
    "# GENERALISE: 'education','teaching' -> 'education'\n",
    "# REMAIN: 'africa', 'asia' -> 'africa', 'asia'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagsimdict['teaching']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "longtags = []\n",
    "for t in squash_list:\n",
    "    if ' ' in t:\n",
    "        longtags.append(t)\n",
    "print(longtags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "potential = []\n",
    "for lt in longtags:\n",
    "    split = lt.split()\n",
    "    new = []\n",
    "    for i in range(len(split)):\n",
    "        if split[i] in squash_list:\n",
    "            new.append(split[i])\n",
    "    if new == []:\n",
    "        potential.append(lt)\n",
    "    else:\n",
    "        potential.append(new)\n",
    "print(potential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
