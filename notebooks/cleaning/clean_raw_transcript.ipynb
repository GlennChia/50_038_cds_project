{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install -U spaCy\n",
    "# !python -m spacy download en\n",
    "# !python -m spacy download en_core_web_sm\n",
    "# !pip install contractions\n",
    "# !pip install inflect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import string\n",
    "import re\n",
    "import unicodedata\n",
    "import inflect\n",
    "import contractions\n",
    "\n",
    "from nltk.corpus import stopwords as sw_nltk\n",
    "from nltk.tokenize import ToktokTokenizer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from sklearn.feature_extraction import stop_words as sw_sklearn\n",
    "from spacy.lang.en.stop_words import STOP_WORDS as sw_spacy\n",
    "from gensim.parsing.preprocessing import remove_stopwords as sw_gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')\n",
    "token=ToktokTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"../../data/raw/\"\n",
    "INPUT_FILE_NAME = 'subset_raw.parquet'\n",
    "OUTPUT_FILE_NAME = 'cleaned.parquet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(DATA_DIR + INPUT_FILE_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here is what we need to clean\n",
    "1. Lower case [DONE]\n",
    "2. Abbreviations (unnecessary?)\n",
    "3. Numbers [DONE]\n",
    "4. Contractions (unnecessary?) [DONE]\n",
    "5. All punctuations [DONE]\n",
    "6. Weird symbols (accounted for w/ punctuations)\n",
    "7. Stop words (gensim) [DONE]\n",
    "\n",
    "TOKENISATION\n",
    "\n",
    "\n",
    "7. Stop words (nltk, sklearn, spacy) [DONE]\n",
    "8. Stemming (unnecessary due to Lemmatization)\n",
    "9. Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_whitespaces(input_string):\n",
    "    result = input_string.strip()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_lower(input_string):\n",
    "    return input_string.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_contractions(input_string):\n",
    "    return contractions.fix(input_string)\n",
    "#only replaces common contractions\n",
    "#is it truly necessary considering removal of stopwords?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_non_ascii_token(tokens):\n",
    "    result = []\n",
    "    for word in tokens:\n",
    "        new_word = unicodedata.normalize('NFKD', word).encode('ascii', 'ignore')\n",
    "        result.append(new_word)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_numbers(input_string):\n",
    "    result = re.sub(r'\\d+','',input_string)\n",
    "    return result\n",
    "\n",
    "def replace_numbers_token(tokens): #unnecessary for tagging, better to just remove?\n",
    "    p = inflect.engine()\n",
    "    result = []\n",
    "    for word in tokens:\n",
    "        if word.isdigit():\n",
    "            new_word = p.number_to_words(word)\n",
    "            results.append(new_word)\n",
    "        else:\n",
    "            results.append(word)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuations = string.punctuation\n",
    "def remove_punctuations(input_string):\n",
    "    result = input_string\n",
    "    for i in punctuations:\n",
    "        result = result.replace(i,'')\n",
    "    return result\n",
    "\n",
    "def remove_punctuations_token(tokens):\n",
    "    result = []\n",
    "    for word in tokens:\n",
    "        new_word = re.sub(r'[^\\w\\s])','',word)\n",
    "        result.append(new_word)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_sw_string(input_string):\n",
    "    result = sw_gensim(input_string)\n",
    "    return result\n",
    "\n",
    "def remove_sw_token(tokens):\n",
    "    \n",
    "    #nltk stop words\n",
    "    nltkStopWords=sw_nltk.words('english')\n",
    "\n",
    "    #sklearn stop words\n",
    "    sets=[sw_sklearn.ENGLISH_STOP_WORDS]\n",
    "    sklearnStopWords = [list(x) for x in sets][0]\n",
    "\n",
    "    ##COMBINE NLTK & SKLEARN STOP WORDS\n",
    "    allStopWords = nltkStopWords + sklearnStopWords\n",
    "    allStopWords = list(dict.fromkeys(allStopWords)) #remove repeats\n",
    "\n",
    "    after_nltk_sklearn = [i for i in tokens if not i in allStopWords]\n",
    "    \n",
    "    result = []\n",
    "    for word in after_nltk_sklearn:\n",
    "        lexeme = nlp.vocab[word]\n",
    "        if lexeme.is_stop == False:\n",
    "            result.append(word)\n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#do after removal of stopwords\n",
    "def lemmatize_token(tokens):\n",
    "    lemma = WordNetLemmatizer()\n",
    "    result = []\n",
    "    for w in tokens:\n",
    "        w1 = lemma.lemmatize(w, pos = 'n')\n",
    "        w2 = lemma.lemmatize(w1, pos = 'v')\n",
    "        w3 = lemma.lemmatize(w2, pos = ('a'))\n",
    "        result.append(w3)\n",
    "    return result\n",
    "#spacy can also lemmatize on tokens in doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_specific_cleaning_token(tokens):\n",
    "    result = []\n",
    "    for word in tokens:\n",
    "        if word != 'applause' and word != 'laughter':\n",
    "            result.append(word)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_cleaning(input_string):\n",
    "    text = remove_whitespaces(input_string)\n",
    "    text = convert_lower(text)\n",
    "    text = replace_contractions(text)\n",
    "    text = remove_numbers(text)\n",
    "    text = remove_punctuations(text)\n",
    "    text = remove_sw_string(text)\n",
    "    \n",
    "    tokens = token.tokenize(text)\n",
    "    \n",
    "    tokens = remove_sw_token(tokens)\n",
    "    tokens = lemmatize_token(tokens)\n",
    "    tokens = data_specific_cleaning_token(tokens)\n",
    "    \n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker</th>\n",
       "      <th>headline</th>\n",
       "      <th>description</th>\n",
       "      <th>duration</th>\n",
       "      <th>tags</th>\n",
       "      <th>transcript</th>\n",
       "      <th>WC</th>\n",
       "      <th>clean_transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Al Gore</td>\n",
       "      <td>Averting the climate crisis</td>\n",
       "      <td>With the same humor and humanity he exuded in ...</td>\n",
       "      <td>0:16:17</td>\n",
       "      <td>cars,alternative energy,culture,politics,scien...</td>\n",
       "      <td>0:14\\r\\r\\rThank you so much, Chris.\\rAnd it's ...</td>\n",
       "      <td>2281.0</td>\n",
       "      <td>[thank, chris, truly, great, honor, opportunit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Amy Smith</td>\n",
       "      <td>Simple designs to save a life</td>\n",
       "      <td>Fumes from indoor cooking fires kill more than...</td>\n",
       "      <td>0:15:06</td>\n",
       "      <td>MacArthur grant,simplicity,industrial design,a...</td>\n",
       "      <td>0:11\\r\\r\\rIn terms of invention,\\rI'd like to ...</td>\n",
       "      <td>2687.0</td>\n",
       "      <td>[term, invention, like, tell, tale, favorite, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ashraf Ghani</td>\n",
       "      <td>How to rebuild a broken state</td>\n",
       "      <td>Ashraf Ghani's passionate and powerful 10-minu...</td>\n",
       "      <td>0:18:45</td>\n",
       "      <td>corruption,poverty,economics,investment,milita...</td>\n",
       "      <td>0:12\\r\\r\\rA public, Dewey long ago observed,\\r...</td>\n",
       "      <td>2506.0</td>\n",
       "      <td>[public, dewey, long, ago, observe, constitute...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Burt Rutan</td>\n",
       "      <td>The real future of space exploration</td>\n",
       "      <td>In this passionate talk, legendary spacecraft ...</td>\n",
       "      <td>0:19:37</td>\n",
       "      <td>aircraft,flight,industrial design,NASA,rocket ...</td>\n",
       "      <td>0:11\\r\\r\\rI want to start off by saying, Houst...</td>\n",
       "      <td>3092.0</td>\n",
       "      <td>[want, start, say, houston, problem, enter, se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chris Bangle</td>\n",
       "      <td>Great cars are great art</td>\n",
       "      <td>American designer Chris Bangle explains his ph...</td>\n",
       "      <td>0:20:04</td>\n",
       "      <td>cars,industrial design,transportation,inventio...</td>\n",
       "      <td>0:12\\r\\r\\rWhat I want to talk about is, as bac...</td>\n",
       "      <td>3781.0</td>\n",
       "      <td>[want, talk, background, idea, car, art, actua...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        speaker                              headline  \\\n",
       "0       Al Gore           Averting the climate crisis   \n",
       "1     Amy Smith         Simple designs to save a life   \n",
       "2  Ashraf Ghani         How to rebuild a broken state   \n",
       "3    Burt Rutan  The real future of space exploration   \n",
       "4  Chris Bangle              Great cars are great art   \n",
       "\n",
       "                                         description duration  \\\n",
       "0  With the same humor and humanity he exuded in ...  0:16:17   \n",
       "1  Fumes from indoor cooking fires kill more than...  0:15:06   \n",
       "2  Ashraf Ghani's passionate and powerful 10-minu...  0:18:45   \n",
       "3  In this passionate talk, legendary spacecraft ...  0:19:37   \n",
       "4  American designer Chris Bangle explains his ph...  0:20:04   \n",
       "\n",
       "                                                tags  \\\n",
       "0  cars,alternative energy,culture,politics,scien...   \n",
       "1  MacArthur grant,simplicity,industrial design,a...   \n",
       "2  corruption,poverty,economics,investment,milita...   \n",
       "3  aircraft,flight,industrial design,NASA,rocket ...   \n",
       "4  cars,industrial design,transportation,inventio...   \n",
       "\n",
       "                                          transcript      WC  \\\n",
       "0  0:14\\r\\r\\rThank you so much, Chris.\\rAnd it's ...  2281.0   \n",
       "1  0:11\\r\\r\\rIn terms of invention,\\rI'd like to ...  2687.0   \n",
       "2  0:12\\r\\r\\rA public, Dewey long ago observed,\\r...  2506.0   \n",
       "3  0:11\\r\\r\\rI want to start off by saying, Houst...  3092.0   \n",
       "4  0:12\\r\\r\\rWhat I want to talk about is, as bac...  3781.0   \n",
       "\n",
       "                                    clean_transcript  \n",
       "0  [thank, chris, truly, great, honor, opportunit...  \n",
       "1  [term, invention, like, tell, tale, favorite, ...  \n",
       "2  [public, dewey, long, ago, observe, constitute...  \n",
       "3  [want, start, say, houston, problem, enter, se...  \n",
       "4  [want, talk, background, idea, car, art, actua...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop rows with empty transcripts\n",
    "df = df.dropna(subset=['transcript'])\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "df['clean_transcript'] = df['transcript'].map(lambda x: combined_cleaning(x))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker</th>\n",
       "      <th>headline</th>\n",
       "      <th>description</th>\n",
       "      <th>duration</th>\n",
       "      <th>tags</th>\n",
       "      <th>transcript</th>\n",
       "      <th>WC</th>\n",
       "      <th>clean_transcript</th>\n",
       "      <th>clean_transcript_string</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Al Gore</td>\n",
       "      <td>Averting the climate crisis</td>\n",
       "      <td>With the same humor and humanity he exuded in ...</td>\n",
       "      <td>0:16:17</td>\n",
       "      <td>cars,alternative energy,culture,politics,scien...</td>\n",
       "      <td>0:14\\r\\r\\rThank you so much, Chris.\\rAnd it's ...</td>\n",
       "      <td>2281.0</td>\n",
       "      <td>[thank, chris, truly, great, honor, opportunit...</td>\n",
       "      <td>thank chris truly great honor opportunity come...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Amy Smith</td>\n",
       "      <td>Simple designs to save a life</td>\n",
       "      <td>Fumes from indoor cooking fires kill more than...</td>\n",
       "      <td>0:15:06</td>\n",
       "      <td>MacArthur grant,simplicity,industrial design,a...</td>\n",
       "      <td>0:11\\r\\r\\rIn terms of invention,\\rI'd like to ...</td>\n",
       "      <td>2687.0</td>\n",
       "      <td>[term, invention, like, tell, tale, favorite, ...</td>\n",
       "      <td>term invention like tell tale favorite project...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ashraf Ghani</td>\n",
       "      <td>How to rebuild a broken state</td>\n",
       "      <td>Ashraf Ghani's passionate and powerful 10-minu...</td>\n",
       "      <td>0:18:45</td>\n",
       "      <td>corruption,poverty,economics,investment,milita...</td>\n",
       "      <td>0:12\\r\\r\\rA public, Dewey long ago observed,\\r...</td>\n",
       "      <td>2506.0</td>\n",
       "      <td>[public, dewey, long, ago, observe, constitute...</td>\n",
       "      <td>public dewey long ago observe constitute discu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Burt Rutan</td>\n",
       "      <td>The real future of space exploration</td>\n",
       "      <td>In this passionate talk, legendary spacecraft ...</td>\n",
       "      <td>0:19:37</td>\n",
       "      <td>aircraft,flight,industrial design,NASA,rocket ...</td>\n",
       "      <td>0:11\\r\\r\\rI want to start off by saying, Houst...</td>\n",
       "      <td>3092.0</td>\n",
       "      <td>[want, start, say, houston, problem, enter, se...</td>\n",
       "      <td>want start say houston problem enter second ge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chris Bangle</td>\n",
       "      <td>Great cars are great art</td>\n",
       "      <td>American designer Chris Bangle explains his ph...</td>\n",
       "      <td>0:20:04</td>\n",
       "      <td>cars,industrial design,transportation,inventio...</td>\n",
       "      <td>0:12\\r\\r\\rWhat I want to talk about is, as bac...</td>\n",
       "      <td>3781.0</td>\n",
       "      <td>[want, talk, background, idea, car, art, actua...</td>\n",
       "      <td>want talk background idea car art actually mea...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        speaker                              headline  \\\n",
       "0       Al Gore           Averting the climate crisis   \n",
       "1     Amy Smith         Simple designs to save a life   \n",
       "2  Ashraf Ghani         How to rebuild a broken state   \n",
       "3    Burt Rutan  The real future of space exploration   \n",
       "4  Chris Bangle              Great cars are great art   \n",
       "\n",
       "                                         description duration  \\\n",
       "0  With the same humor and humanity he exuded in ...  0:16:17   \n",
       "1  Fumes from indoor cooking fires kill more than...  0:15:06   \n",
       "2  Ashraf Ghani's passionate and powerful 10-minu...  0:18:45   \n",
       "3  In this passionate talk, legendary spacecraft ...  0:19:37   \n",
       "4  American designer Chris Bangle explains his ph...  0:20:04   \n",
       "\n",
       "                                                tags  \\\n",
       "0  cars,alternative energy,culture,politics,scien...   \n",
       "1  MacArthur grant,simplicity,industrial design,a...   \n",
       "2  corruption,poverty,economics,investment,milita...   \n",
       "3  aircraft,flight,industrial design,NASA,rocket ...   \n",
       "4  cars,industrial design,transportation,inventio...   \n",
       "\n",
       "                                          transcript      WC  \\\n",
       "0  0:14\\r\\r\\rThank you so much, Chris.\\rAnd it's ...  2281.0   \n",
       "1  0:11\\r\\r\\rIn terms of invention,\\rI'd like to ...  2687.0   \n",
       "2  0:12\\r\\r\\rA public, Dewey long ago observed,\\r...  2506.0   \n",
       "3  0:11\\r\\r\\rI want to start off by saying, Houst...  3092.0   \n",
       "4  0:12\\r\\r\\rWhat I want to talk about is, as bac...  3781.0   \n",
       "\n",
       "                                    clean_transcript  \\\n",
       "0  [thank, chris, truly, great, honor, opportunit...   \n",
       "1  [term, invention, like, tell, tale, favorite, ...   \n",
       "2  [public, dewey, long, ago, observe, constitute...   \n",
       "3  [want, start, say, houston, problem, enter, se...   \n",
       "4  [want, talk, background, idea, car, art, actua...   \n",
       "\n",
       "                             clean_transcript_string  \n",
       "0  thank chris truly great honor opportunity come...  \n",
       "1  term invention like tell tale favorite project...  \n",
       "2  public dewey long ago observe constitute discu...  \n",
       "3  want start say houston problem enter second ge...  \n",
       "4  want talk background idea car art actually mea...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['clean_transcript_string'] = df['clean_transcript'].map(lambda x: ' '.join(str(elem) for elem in x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet(DATA_DIR + OUTPUT_FILE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
